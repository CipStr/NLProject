{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "**Credits**: Federico Ruggeri, Eleonora Mancini, Paolo Torroni\n",
    "\n",
    "**Keywords**: Human Value Detection, Multi-label classification, Transformers, BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Corpus\n",
    "\n",
    "Check the official page of the challenge [here](https://touche.webis.de/semeval23/touche23-web/).\n",
    "\n",
    "The challenge offers several corpora for evaluation and testing.\n",
    "\n",
    "You are going to work with the standard training, validation, and test splits.\n",
    "\n",
    "#### Arguments\n",
    "* arguments-training.tsv\n",
    "* arguments-validation.tsv\n",
    "* arguments-test.tsv\n",
    "\n",
    "#### Human values\n",
    "* labels-training.tsv\n",
    "* labels-validation.tsv\n",
    "* labels-test.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* **Download** the specificed training, validation, and test files.\n",
    "* **Encode** split files into a pandas.DataFrame object.\n",
    "* For each split, **merge** the arguments and labels dataframes into a single dataframe.\n",
    "* **Merge** level 2 annotations to level 3 categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 5827: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32md:\\Alessandro\\GitHub\\NLProject\\A2_v1.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Alessandro/GitHub/NLProject/A2_v1.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dataframes \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Alessandro/GitHub/NLProject/A2_v1.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39marguments/arguments-training.tsv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Alessandro/GitHub/NLProject/A2_v1.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     lines \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49mreadlines()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Alessandro/GitHub/NLProject/A2_v1.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     data \u001b[39m=\u001b[39m [line\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Alessandro/GitHub/NLProject/A2_v1.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mArgument ID\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mConclusion\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mStance\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPremise\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39;49mcharmap_decode(\u001b[39minput\u001b[39;49m,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,decoding_table)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 5827: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "# Create documents dataframe\n",
    "dataframes = []\n",
    "\n",
    "with open('arguments/arguments-training.tsv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    data = [line.split('\\t') for line in lines]\n",
    "    df = pd.DataFrame(data, columns=['Argument ID', 'Conclusion', 'Stance', 'Premise'])\n",
    "\n",
    "df_train = pd.DataFrame({'Dataframes': dataframes})\n",
    "print(df_train['Dataframes'][0][0:5])\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "\n",
    "with open('arguments/labels-training.tsv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    data = [line.split('\\t') for line in lines]\n",
    "    df = pd.DataFrame(data, columns=['Argument ID', 'Conclusion', 'Stance', 'Premise'])\n",
    "\n",
    "df_train_label = pd.DataFrame({'Dataframes': dataframes})\n",
    "print(df_train_label['Dataframes'][0][0:5])\n",
    "print(df_train_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create documents dataframe\n",
    "dataframes = []\n",
    "\n",
    "with open('arguments/arguments-validation.tsv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    data = [line.split('\\t') for line in lines]\n",
    "    df = pd.DataFrame(data, columns=['Argument ID', 'Conclusion', 'Stance', 'Premise'])\n",
    "\n",
    "df_val = pd.DataFrame({'Dataframes': dataframes})\n",
    "print(df_val['Dataframes'][0][0:5])\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "\n",
    "with open('arguments/labels-validation.tsv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    data = [line.split('\\t') for line in lines]\n",
    "    df = pd.DataFrame(data, columns=['Argument ID', 'Conclusion', 'Stance', 'Premise'])\n",
    "\n",
    "df_val_label = pd.DataFrame({'Dataframes': dataframes})\n",
    "print(df_val_label['Dataframes'][0][0:5])\n",
    "print(df_val_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create documents dataframe\n",
    "dataframes = []\n",
    "\n",
    "with open('arguments/arguments-test.tsv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    data = [line.split('\\t') for line in lines]\n",
    "    df = pd.DataFrame(data, columns=['Argument ID', 'Conclusion', 'Stance', 'Premise'])\n",
    "\n",
    "df_test = pd.DataFrame({'Dataframes': dataframes})\n",
    "print(df_test['Dataframes'][0][0:5])\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "\n",
    "with open('arguments/labels-test.tsv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    data = [line.split('\\t') for line in lines]\n",
    "    df = pd.DataFrame(data, columns=['Argument ID', 'Conclusion', 'Stance', 'Premise'])\n",
    "\n",
    "df_test_label = pd.DataFrame({'Dataframes': dataframes})\n",
    "print(df_test_label['Dataframes'][0][0:5])\n",
    "print(df_test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Model definition\n",
    "\n",
    "You are tasked to define several neural models for multi-label classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* **Baseline**: implement a random uniform classifier (an individual classifier per category).\n",
    "* **Baseline**: implement a majority classifier (an individual classifier per category).\n",
    "\n",
    "<br/>\n",
    "\n",
    "* **BERT w/ C**: define a BERT-based classifier that receives an argument **conclusion** as input.\n",
    "* **BERT w/ CP**: add argument **premise** as an additional input.\n",
    "* **BERT w/ CPS**: add argument premise-to-conclusion **stance** as an additional input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a random uniform classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random uniform classifier using Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=X_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a majority classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the majority class\n",
    "majority_class = np.argmax(np.bincount(y_train))\n",
    "\n",
    "# Majority classifier using Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=X_train.shape[1], activation='sigmoid', kernel_initializer='zeros', bias_initializer='zeros'))\n",
    "\n",
    "# Set the weights to predict the majority class\n",
    "model.layers[0].set_weights([np.array([[0.0]]), np.array([float(majority_class)])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Metrics\n",
    "\n",
    "Before training the models, you are tasked to define the evaluation metrics for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* Evaluate your models using per-category binary F1-score.\n",
    "* Compute the average binary F1-score over all categories (macro F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Training and Evaluation\n",
    "\n",
    "You are now tasked to train and evaluate **all** defined models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* Train **all** models on the train set.\n",
    "* Evaluate **all** models on the validation set.\n",
    "* Pick **at least** three seeds for robust estimation.\n",
    "* Compute metrics on the validation set.\n",
    "* Report **per-category** and **macro** F1-score for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Error Analysis\n",
    "\n",
    "You are tasked to discuss your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* **Compare** classification performance of BERT-based models with respect to baselines.\n",
    "* Discuss **difference in prediction** between the best performing BERT-based model and its variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6: Report\n",
    "\n",
    "Wrap up your experiment in a short report (up to 2 pages)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* Use the NLP course report template.\n",
    "* Summarize each task in the report following the provided template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
