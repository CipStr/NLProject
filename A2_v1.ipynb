{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "**Credits**: Federico Ruggeri, Eleonora Mancini, Paolo Torroni\n",
    "\n",
    "**Keywords**: Human Value Detection, Multi-label classification, Transformers, BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Corpus:\n",
    "\n",
    "We address a multi-label classification problem. We consider only level 3 categories which are the following:\n",
    "- Openness to change\n",
    "- Self-enhancement\n",
    "- Conservation\n",
    "- Self-transcendence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're gonna merge annotations of level 2 categories belonging to the same level 3 category. For example, we merge the annotations of the level 2 categories \"Stimulation\" and \"Hedonism\" into the level 3 category \"Openness to change\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding to pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Argument ID                   Conclusion       Stance  \\\n",
      "0      A01002  We should ban human cloning  in favor of   \n",
      "\n",
      "                                             Premise  \n",
      "0  we should ban human cloning as it will only ca...  \n",
      "Shape of the training data: (5393, 4)\n",
      "Shape of the validation data: (1896, 4)\n",
      "Shape of the test data: (1576, 4)\n"
     ]
    }
   ],
   "source": [
    "arg_train = pd.read_csv('arguments/arguments-training.tsv', sep='\\t')\n",
    "print(arg_train.head(1))\n",
    "print(f\"Shape of the training data: {arg_train.shape}\")\n",
    "arg_val = pd.read_csv('arguments/arguments-validation.tsv', sep='\\t')\n",
    "print(f\"Shape of the validation data: {arg_val.shape}\")\n",
    "arg_test = pd.read_csv('arguments/arguments-test.tsv', sep='\\t')\n",
    "print(f\"Shape of the test data: {arg_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Argument ID  Self-direction: thought  Self-direction: action  Stimulation  \\\n",
      "0      A01002                        0                       0            0   \n",
      "\n",
      "   Hedonism  Achievement  Power: dominance  Power: resources  Face  \\\n",
      "0         0            0                 0                 0     0   \n",
      "\n",
      "   Security: personal  ...  Tradition  Conformity: rules  \\\n",
      "0                   0  ...          0                  0   \n",
      "\n",
      "   Conformity: interpersonal  Humility  Benevolence: caring  \\\n",
      "0                          0         0                    0   \n",
      "\n",
      "   Benevolence: dependability  Universalism: concern  Universalism: nature  \\\n",
      "0                           0                      0                     0   \n",
      "\n",
      "   Universalism: tolerance  Universalism: objectivity  \n",
      "0                        0                          0  \n",
      "\n",
      "[1 rows x 21 columns]\n",
      "Shape of the training data: (5393, 21)\n",
      "Shape of the validation data: (1896, 21)\n",
      "Shape of the test data: (1576, 21)\n"
     ]
    }
   ],
   "source": [
    "lab_train = pd.read_csv('arguments/labels-training.tsv', sep='\\t')\n",
    "print(lab_train.head(1))\n",
    "print(f\"Shape of the training data: {lab_train.shape}\")\n",
    "lab_val = pd.read_csv('arguments/labels-validation.tsv', sep='\\t')\n",
    "print(f\"Shape of the validation data: {lab_val.shape}\")\n",
    "lab_test = pd.read_csv('arguments/labels-test.tsv', sep='\\t')\n",
    "print(f\"Shape of the test data: {lab_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each split we merge arguments and labels into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data: (5393, 24)\n",
      "Shape of the validation data: (1896, 24)\n",
      "Shape of the test data: (1576, 24)\n",
      "  Argument ID                   Conclusion       Stance  \\\n",
      "0      A01002  We should ban human cloning  in favor of   \n",
      "\n",
      "                                             Premise  Self-direction: thought  \\\n",
      "0  we should ban human cloning as it will only ca...                        0   \n",
      "\n",
      "   Self-direction: action  Stimulation  Hedonism  Achievement  \\\n",
      "0                       0            0         0            0   \n",
      "\n",
      "   Power: dominance  ...  Tradition  Conformity: rules  \\\n",
      "0                 0  ...          0                  0   \n",
      "\n",
      "   Conformity: interpersonal  Humility  Benevolence: caring  \\\n",
      "0                          0         0                    0   \n",
      "\n",
      "   Benevolence: dependability  Universalism: concern  Universalism: nature  \\\n",
      "0                           0                      0                     0   \n",
      "\n",
      "   Universalism: tolerance  Universalism: objectivity  \n",
      "0                        0                          0  \n",
      "\n",
      "[1 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train = arg_train.merge(lab_train, on='Argument ID')\n",
    "df_val = arg_val.merge(lab_val, on='Argument ID')\n",
    "df_test = arg_test.merge(lab_test, on='Argument ID')\n",
    "print(f\"Shape of the training data: {df_train.shape}\")\n",
    "print(f\"Shape of the validation data: {df_val.shape}\")\n",
    "print(f\"Shape of the test data: {df_test.shape}\")\n",
    "print(df_train.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge level 2 categories into level 3 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Argument ID                   Conclusion       Stance  \\\n",
      "0      A01002  We should ban human cloning  in favor of   \n",
      "\n",
      "                                             Premise  Openness to change  \\\n",
      "0  we should ban human cloning as it will only ca...                   0   \n",
      "\n",
      "   Conservation  Self-enhancement  Self-transcendence  \n",
      "0             0                 1                   0  \n",
      "Shape of the training data: (5393, 8)\n",
      "Shape of the validation data: (1896, 8)\n",
      "Shape of the test data: (1576, 8)\n"
     ]
    }
   ],
   "source": [
    "# Merge the level 2 categories to level 3\n",
    "# They start from column 4 so we can just add 4 to the level 2 category\n",
    "# Openness to change: 4 columns\n",
    "# Conservation: columns 4 columns\n",
    "# Self-enhancement: 6 columns\n",
    "# Self-transcendence: 6 columns\n",
    "\n",
    "def merge_categories(df):\n",
    "    df['Openness to change'] = df[df.columns[4:8]].sum(axis=1)\n",
    "    df['Conservation'] = df[df.columns[8:12]].sum(axis=1)\n",
    "    df['Self-enhancement'] = df[df.columns[12:18]].sum(axis=1)\n",
    "    df['Self-transcendence'] = df[df.columns[18:24]].sum(axis=1)\n",
    "    df = df.drop(df.columns[4:24], axis=1)\n",
    "    return df\n",
    "# get column names\n",
    "df_train = merge_categories(df_train)\n",
    "df_val = merge_categories(df_val)\n",
    "df_test = merge_categories(df_test)\n",
    "print(df_train.head(1))\n",
    "print(f\"Shape of the training data: {df_train.shape}\")\n",
    "print(f\"Shape of the validation data: {df_val.shape}\")\n",
    "print(f\"Shape of the test data: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Model definition\n",
    "\n",
    "You are tasked to define several neural models for multi-label classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* **Baseline**: implement a random uniform classifier (an individual classifier per category).\n",
    "* **Baseline**: implement a majority classifier (an individual classifier per category).\n",
    "\n",
    "<br/>\n",
    "\n",
    "* **BERT w/ C**: define a BERT-based classifier that receives an argument **conclusion** as input.\n",
    "* **BERT w/ CP**: add argument **premise** as an additional input.\n",
    "* **BERT w/ CPS**: add argument premise-to-conclusion **stance** as an additional input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a random uniform classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random uniform classifier using Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=X_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a majority classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the majority class\n",
    "majority_class = np.argmax(np.bincount(y_train))\n",
    "\n",
    "# Majority classifier using Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=X_train.shape[1], activation='sigmoid', kernel_initializer='zeros', bias_initializer='zeros'))\n",
    "\n",
    "# Set the weights to predict the majority class\n",
    "model.layers[0].set_weights([np.array([[0.0]]), np.array([float(majority_class)])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Metrics\n",
    "\n",
    "Before training the models, you are tasked to define the evaluation metrics for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* Evaluate your models using per-category binary F1-score.\n",
    "* Compute the average binary F1-score over all categories (macro F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Training and Evaluation\n",
    "\n",
    "You are now tasked to train and evaluate **all** defined models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* Train **all** models on the train set.\n",
    "* Evaluate **all** models on the validation set.\n",
    "* Pick **at least** three seeds for robust estimation.\n",
    "* Compute metrics on the validation set.\n",
    "* Report **per-category** and **macro** F1-score for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Error Analysis\n",
    "\n",
    "You are tasked to discuss your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* **Compare** classification performance of BERT-based models with respect to baselines.\n",
    "* Discuss **difference in prediction** between the best performing BERT-based model and its variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6: Report\n",
    "\n",
    "Wrap up your experiment in a short report (up to 2 pages)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* Use the NLP course report template.\n",
    "* Summarize each task in the report following the provided template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
