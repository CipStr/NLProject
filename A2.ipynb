{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "**Credits**: Federico Ruggeri, Eleonora Mancini, Paolo Torroni\n",
    "\n",
    "**Keywords**: Human Value Detection, Multi-label classification, Transformers, BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook document is our implementation of Assignment 2. \n",
    "\n",
    "Group members:\n",
    "- Stricescu Razvan Ciprian\n",
    "- Matteo Belletti\n",
    "- Alessandro Pasi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas\n",
    "#%pip install numpy\n",
    "#%pip install nltk\n",
    "#%pip install scikit-learn\n",
    "#%pip install transformers\n",
    "#%pip install matplotlib\n",
    "#%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "from torch import cuda\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, ConcatDataset\n",
    "from transformers import AutoModel, AutoTokenizer, get_linear_schedule_with_warmup, RobertaConfig\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Corpus:\n",
    "\n",
    "We address a multi-label classification problem. We consider only level 3 categories which are the following:\n",
    "- Openness to change\n",
    "- Self-enhancement\n",
    "- Conservation\n",
    "- Self-transcendence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're gonna merge annotations of level 2 categories belonging to the same level 3 category. For example, we merge the annotations of the level 2 categories \"Stimulation\" and \"Hedonism\" into the level 3 category \"Openness to change\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding to pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Argument ID                   Conclusion       Stance  \\\n",
      "0      A01002  We should ban human cloning  in favor of   \n",
      "\n",
      "                                             Premise  \n",
      "0  we should ban human cloning as it will only ca...  \n",
      "Shape of the training data: (5393, 4)\n",
      "Shape of the validation data: (1896, 4)\n",
      "Shape of the test data: (1576, 4)\n"
     ]
    }
   ],
   "source": [
    "arg_train = pd.read_csv('arguments/arguments-training.tsv', sep='\\t')\n",
    "print(arg_train.head(1))\n",
    "print(f\"Shape of the training data: {arg_train.shape}\")\n",
    "arg_val = pd.read_csv('arguments/arguments-validation.tsv', sep='\\t')\n",
    "print(f\"Shape of the validation data: {arg_val.shape}\")\n",
    "arg_test = pd.read_csv('arguments/arguments-test.tsv', sep='\\t')\n",
    "print(f\"Shape of the test data: {arg_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Argument ID  Self-direction: thought  Self-direction: action  Stimulation  \\\n",
      "0      A01002                        0                       0            0   \n",
      "\n",
      "   Hedonism  Achievement  Power: dominance  Power: resources  Face  \\\n",
      "0         0            0                 0                 0     0   \n",
      "\n",
      "   Security: personal  ...  Tradition  Conformity: rules  \\\n",
      "0                   0  ...          0                  0   \n",
      "\n",
      "   Conformity: interpersonal  Humility  Benevolence: caring  \\\n",
      "0                          0         0                    0   \n",
      "\n",
      "   Benevolence: dependability  Universalism: concern  Universalism: nature  \\\n",
      "0                           0                      0                     0   \n",
      "\n",
      "   Universalism: tolerance  Universalism: objectivity  \n",
      "0                        0                          0  \n",
      "\n",
      "[1 rows x 21 columns]\n",
      "Shape of the training data: (5393, 21)\n",
      "Shape of the validation data: (1896, 21)\n",
      "Shape of the test data: (1576, 21)\n"
     ]
    }
   ],
   "source": [
    "lab_train = pd.read_csv('arguments/labels-training.tsv', sep='\\t')\n",
    "print(lab_train.head(1))\n",
    "print(f\"Shape of the training data: {lab_train.shape}\")\n",
    "lab_val = pd.read_csv('arguments/labels-validation.tsv', sep='\\t')\n",
    "print(f\"Shape of the validation data: {lab_val.shape}\")\n",
    "lab_test = pd.read_csv('arguments/labels-test.tsv', sep='\\t')\n",
    "print(f\"Shape of the test data: {lab_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each split we merge arguments and labels into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data: (5393, 24)\n",
      "Shape of the validation data: (1896, 24)\n",
      "Shape of the test data: (1576, 24)\n"
     ]
    }
   ],
   "source": [
    "df_train = arg_train.merge(lab_train, on='Argument ID')\n",
    "df_val = arg_val.merge(lab_val, on='Argument ID')\n",
    "df_test = arg_test.merge(lab_test, on='Argument ID')\n",
    "print(f\"Shape of the training data: {df_train.shape}\")\n",
    "print(f\"Shape of the validation data: {df_val.shape}\")\n",
    "print(f\"Shape of the test data: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge level 2 categories into level 3 categories. We also create new dataframes for the cp and cps tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data: (5393, 8)\n",
      "Shape of the validation data: (1896, 8)\n",
      "Shape of the test data: (1576, 8)\n",
      "Shape of the training data for the cp task: (5393, 9)\n",
      "Shape of the training data for the cps task: (5393, 9)\n"
     ]
    }
   ],
   "source": [
    "# Merge the level 2 categories to level 3\n",
    "# They start from column 4 so we can just add 4 to the level 2 category\n",
    "# Openness to change: 4 columns\n",
    "# Conservation: columns 4 columns\n",
    "# Self-enhancement: 6 columns\n",
    "# Self-transcendence: 6 columns\n",
    "\n",
    "def merge_categories(df):\n",
    "    # Logical or \n",
    "    df['Openness to change'] = df[df.columns[4:8]].any(axis=1).astype(int)\n",
    "    df['Conservation'] = df[df.columns[7:12]].any(axis=1).astype(int)\n",
    "    df['Self-enhancement'] = df[df.columns[11:18]].any(axis=1).astype(int)\n",
    "    df['Self-transcendence'] = df[df.columns[17:24]].any(axis=1).astype(int)\n",
    "    df = df.drop(df.columns[4:24], axis=1)\n",
    "    return df\n",
    "\n",
    "# get column names\n",
    "df_train = merge_categories(df_train)\n",
    "df_val = merge_categories(df_val)\n",
    "df_test = merge_categories(df_test)\n",
    "print(f\"Shape of the training data: {df_train.shape}\")\n",
    "print(f\"Shape of the validation data: {df_val.shape}\")\n",
    "print(f\"Shape of the test data: {df_test.shape}\")\n",
    "\n",
    "# Create the dataframes for the cp task\n",
    "df_traincp = df_train.copy()\n",
    "df_valcp = df_val.copy()\n",
    "df_testcp = df_test.copy()\n",
    "df_traincp[\"text\"] = df_traincp[\"Conclusion\"] + \" \" + df_traincp[\"Premise\"]\n",
    "df_valcp[\"text\"] = df_valcp[\"Conclusion\"] + \" \" + df_valcp[\"Premise\"]\n",
    "df_testcp[\"text\"] = df_testcp[\"Conclusion\"] + \" \" + df_testcp[\"Premise\"]\n",
    "print(f\"Shape of the training data for the cp task: {df_traincp.shape}\")\n",
    "\n",
    "# Create the dataframes for the cps task\n",
    "df_traincps = df_train.copy()\n",
    "df_valcps = df_val.copy()\n",
    "df_testcps = df_test.copy()\n",
    "df_traincps[\"Stance\"] = df_traincps[\"Stance\"].replace(\"against\", \"0\")\n",
    "df_valcps[\"Stance\"] = df_valcps[\"Stance\"].replace(\"against\", \"0\")\n",
    "df_testcps[\"Stance\"] = df_testcps[\"Stance\"].replace(\"against\", \"0\")\n",
    "df_valcps[\"Stance\"] = df_valcps[\"Stance\"].replace(\"in favor of\", \"1\")\n",
    "df_traincps[\"Stance\"] = df_traincps[\"Stance\"].replace(\"in favor of\", \"1\")\n",
    "df_testcps[\"Stance\"] = df_testcps[\"Stance\"].replace(\"in favor of\", \"1\")\n",
    "df_traincps[\"text\"] = df_traincp[\"Conclusion\"] + \" \" + df_traincp[\"Premise\"] + \" \" + df_traincps[\"Stance\"]\n",
    "df_valcps[\"text\"] = df_valcp[\"Conclusion\"] + \" \" + df_valcp[\"Premise\"] + \" \" + df_valcps[\"Stance\"]\n",
    "df_testcps[\"text\"] = df_testcp[\"Conclusion\"] + \" \" + df_testcp[\"Premise\"] + \" \" + df_testcps[\"Stance\"]\n",
    "print(f\"Shape of the training data for the cps task: {df_traincps.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text encoding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encode the Premise column in order to check the sentence length distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\39328\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "  0%|          | 0/5393 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5393/5393 [00:01<00:00, 4599.27it/s]\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "train_text = df_train['Premise'].tolist()\n",
    "train_lengths = [len(word_tokenize(x)) for x in tqdm(train_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the distribution of the number of words per argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_lengths, color='blue', edgecolor='black')\n",
    "plt.xlabel('Length of text')\n",
    "plt.ylabel('Number of texts')\n",
    "plt.title('Distribution of Premise sentence length in training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text preproccesing with nltk: \n",
    "\n",
    "We use nltk to remove stopwords and punctuation from the arguments and we also lemmitize the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\39328\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\39328\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\39328\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "punct = string.punctuation\n",
    "bad_symbols = re.compile('[^a-z ]')\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = bad_symbols.sub('', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in punct)\n",
    "    text = ' '.join(word for word in text.split() if word not in stopwords)\n",
    "    text = ' '.join(lemmatizer.lemmatize(word) for word in text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataframe after preprocessing:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Openness to change</th>\n",
       "      <th>Conservation</th>\n",
       "      <th>Self-enhancement</th>\n",
       "      <th>Self-transcendence</th>\n",
       "      <th>Preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ban human cloning cause huge issue bunch human...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID  Openness to change  Conservation  Self-enhancement  \\\n",
       "0      A01002                   0             0                 1   \n",
       "\n",
       "   Self-transcendence                                       Preprocessed  \n",
       "0                   0  ban human cloning cause huge issue bunch human...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df_train.copy()\n",
    "train['Preprocessed'] = train['Premise'].apply(preprocess)\n",
    "train = train.drop(columns=train.columns[1:4])\n",
    "val = df_val.copy()\n",
    "val['Preprocessed'] = val['Premise'].apply(preprocess)\n",
    "val = val.drop(columns=val.columns[1:4])\n",
    "test = df_test.copy()\n",
    "test['Preprocessed'] = test['Premise'].apply(preprocess)\n",
    "test = test.drop(columns=test.columns[1:4])\n",
    "print(f\"Train dataframe after preprocessing:\\n\")\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tokenize the the data using TF-IDF vectorizer. We do the same for the validation and test sets which we will use later for the baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data: (5393, 6836)\n",
      "Shape of the validation data: (1896, 6836)\n",
      "Shape of the test data: (1576, 6836)\n",
      "Size of the vocabulary: 6836\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train['Preprocessed'])\n",
    "X_val = vectorizer.transform(val['Preprocessed'])\n",
    "X_test = vectorizer.transform(test['Preprocessed'])\n",
    "\n",
    "print(f\"Shape of the training data: {X_train.shape}\")\n",
    "print(f\"Shape of the validation data: {X_val.shape}\")\n",
    "print(f\"Shape of the test data: {X_test.shape}\")\n",
    "print(f\"Size of the vocabulary: {len(vectorizer.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Model definition\n",
    "\n",
    "You are tasked to define several neural models for multi-label classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* **Baseline**: implement a random uniform classifier (an individual classifier per category).\n",
    "* **Baseline**: implement a majority classifier (an individual classifier per category).\n",
    "\n",
    "<br/>\n",
    "\n",
    "* **BERT w/ C**: define a BERT-based classifier that receives an argument **conclusion** as input.\n",
    "* **BERT w/ CP**: add argument **premise** as an additional input.\n",
    "* **BERT w/ CPS**: add argument premise-to-conclusion **stance** as an additional input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation report for baseline models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(Y_test, Y_pred):\n",
    "    report = classification_report(Y_test, Y_pred)\n",
    "    print(report)\n",
    "\n",
    "Y_test = test.iloc[:, 1:5].values # get as array the labels of the test set [oppenness, conservation, self-enhancement, self-transcendence]\n",
    "Y_val = val.iloc[:, 1:5].values # get as array the labels of the validation set [oppenness, conservation, self-enhancement, self-transcendence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As baseline models we implemented a random uniform classifier and a majority classifier using the sklearn library which already has these models implemented.\n",
    "\n",
    "We implment a classifier for each category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a random uniform classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "uniform_classifier_openness = DummyClassifier(strategy='uniform')\n",
    "uniform_classifier_conserv = DummyClassifier(strategy='uniform')\n",
    "uniform_classifier_self_enh = DummyClassifier(strategy='uniform')\n",
    "uniform_classifier_self_trans = DummyClassifier(strategy='uniform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a majority classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_classifier_openness = DummyClassifier(strategy='most_frequent')\n",
    "majority_classifier_conserv = DummyClassifier(strategy='most_frequent')\n",
    "majority_classifier_self_enh = DummyClassifier(strategy='most_frequent')\n",
    "majority_classifier_self_trans = DummyClassifier(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoBERTa model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a BERT-based classifier we used the RoBERTa model. We used the HuggingFace library to load the model and the tokenizer. We chose the RoBERTa model because it is a more recent model than BERT and it is generally considered to be more versatile and robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-base'\n",
    "max_len = 100\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "learning_rate = 2e-5\n",
    "output_channels = 768\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Token generation for RoBERTa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training labels: (5393, 4)\n",
      "Shape of the validation labels: (1896, 4)\n",
      "Shape of the test labels: (1576, 4)\n"
     ]
    }
   ],
   "source": [
    "class RobertaDataset(Dataset):\n",
    "    def __init__(self, data, labels, tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.targets = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.data[index])\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Create the dataset for the neural network\n",
    "train_targets = df_train.iloc[:, 4:8].values\n",
    "val_targets = df_val.iloc[:, 4:8].values\n",
    "test_targets = df_test.iloc[:, 4:8].values\n",
    "\n",
    "print(f\"Shape of the training labels: {train_targets.shape}\")\n",
    "print(f\"Shape of the validation labels: {val_targets.shape}\")\n",
    "print(f\"Shape of the test labels: {test_targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RoBERTa model definition: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class roBERTa(torch.nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(roBERTa, self).__init__()\n",
    "        self.roberta = AutoModel.from_pretrained(model_name, return_dict=False)\n",
    "        self.dropout = torch.nn.Dropout(p=0.3)\n",
    "        self.classifier = torch.nn.Linear(output_channels, 4)\n",
    "        \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, output = self.roberta(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
    "        output = self.dropout(output)\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RoBERTa w/C data preparation:\n",
    "\n",
    "For each model we create different datasets and dataloaders based on the task we are performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training dataset: 5393\n",
      "Shape of the validation dataset: 1896\n",
      "Shape of the test dataset: 1576\n"
     ]
    }
   ],
   "source": [
    "train_datasetc = RobertaDataset(df_train.iloc[:, 1], train_targets, tokenizer, max_len)\n",
    "val_datasetc = RobertaDataset(df_val.iloc[:, 1], val_targets, tokenizer, max_len)\n",
    "test_datasetc = RobertaDataset(df_test.iloc[:, 1], test_targets, tokenizer, max_len)\n",
    "\n",
    "print(f\"Shape of the training dataset: {len(train_datasetc)}\")\n",
    "print(f\"Shape of the validation dataset: {len(val_datasetc)}\")\n",
    "print(f\"Shape of the test dataset: {len(test_datasetc)}\")\n",
    "\n",
    "train_dataloaderc = DataLoader(train_datasetc, batch_size=batch_size)\n",
    "val_dataloaderc = DataLoader(val_datasetc, batch_size=batch_size)\n",
    "test_dataloaderc = DataLoader(test_datasetc, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model initialization and optional gpu usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "roBERTa(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_c = roBERTa(model_name)\n",
    "model_c.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RoBERTa w/CP data preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training dataset: 5393\n",
      "Shape of the validation dataset: 1896\n",
      "Shape of the test dataset: 1576\n"
     ]
    }
   ],
   "source": [
    "train_datasetcp = RobertaDataset(df_traincp.iloc[:, 8], train_targets, tokenizer, max_len)\n",
    "val_datasetcp = RobertaDataset(df_valcp.iloc[:, 8], val_targets, tokenizer, max_len)\n",
    "test_datasetcp = RobertaDataset(df_testcp.iloc[:, 8], test_targets, tokenizer, max_len)\n",
    "\n",
    "\n",
    "print(f\"Shape of the training dataset: {len(train_datasetcp)}\")\n",
    "print(f\"Shape of the validation dataset: {len(val_datasetcp)}\")\n",
    "print(f\"Shape of the test dataset: {len(test_datasetcp)}\")\n",
    "\n",
    "train_dataloadercp = DataLoader(train_datasetcp, batch_size=batch_size)\n",
    "val_dataloadercp = DataLoader(val_datasetcp, batch_size=batch_size)\n",
    "test_dataloadercp = DataLoader(test_datasetcp, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0, 170, 197,  ...,   1,   1,   1],\n",
      "        [  0, 170, 197,  ...,   1,   1,   1],\n",
      "        [  0, 170, 197,  ...,   1,   1,   1],\n",
      "        ...,\n",
      "        [  0, 170, 197,  ...,   1,   1,   1],\n",
      "        [  0, 170, 197,  ...,   1,   1,   1],\n",
      "        [  0, 170, 197,  ...,   1,   1,   1]])\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>We should ban human cloning we should ban human cloning as it will only cause huge issues when you have a bunch of the same humans running around all acting the same.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(train_dataloadercp))\n",
    "print(data['ids'])\n",
    "print(data['mask'])\n",
    "tokenizer.decode(data['ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model initialization and optional gpu usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "roBERTa(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cp = roBERTa(model_name)\n",
    "model_cp.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RoBERTa w/CPS data preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training dataset: 5393\n",
      "Shape of the validation dataset: 1896\n",
      "Shape of the test dataset: 1576\n"
     ]
    }
   ],
   "source": [
    "train_datasetcps = RobertaDataset(df_traincps.iloc[:, 8], train_targets, tokenizer, max_len)\n",
    "val_datasetcps = RobertaDataset(df_valcps.iloc[:, 8], val_targets, tokenizer, max_len)\n",
    "test_datasetcps = RobertaDataset(df_testcps.iloc[:, 8], test_targets, tokenizer, max_len)\n",
    "\n",
    "\n",
    "print(f\"Shape of the training dataset: {len(train_datasetcps)}\")\n",
    "print(f\"Shape of the validation dataset: {len(val_datasetcps)}\")\n",
    "print(f\"Shape of the test dataset: {len(test_datasetcps)}\")\n",
    "\n",
    "train_dataloadercps = DataLoader(train_datasetcps, batch_size=batch_size)\n",
    "val_dataloadercps = DataLoader(val_datasetcps, batch_size=batch_size)\n",
    "test_dataloadercps = DataLoader(test_datasetcps, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0, 170, 197,  ...,   1,   1,   1],\n",
      "        [  0, 170, 197,  ...,   1,   1,   1],\n",
      "        [  0, 170, 197,  ...,   1,   1,   1],\n",
      "        ...,\n",
      "        [  0, 170, 197,  ...,   1,   1,   1],\n",
      "        [  0, 170, 197,  ...,   1,   1,   1],\n",
      "        [  0, 170, 197,  ...,   1,   1,   1]])\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>We should ban human cloning we should ban human cloning as it will only cause huge issues when you have a bunch of the same humans running around all acting the same. 1</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(train_dataloadercps))\n",
    "print(data['ids'])\n",
    "print(data['mask'])\n",
    "tokenizer.decode(data['ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model initialization and optional gpu usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "roBERTa(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cps = roBERTa(model_name)\n",
    "model_cps.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function for RoBERTa models:\n",
    "\n",
    "Since we have 3 different models we created a function that trains a model given the model and the training dataloader. The training loop is quite standard. We use the AdamW optimizer and the BCEWithLogitsLoss loss function. We also use the scheduler to decrease the learning rate during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBert(model, dataloader):\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader)*epochs)\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, data in enumerate(dataloader, 0):\n",
    "        ids = data['ids'].to(device, dtype=torch.long)\n",
    "        mask = data['mask'].to(device, dtype=torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "        targets = data['targets'].to(device, dtype=torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(ids)\n",
    "            print(f\"Train loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation function for RoBERTa models:\n",
    "\n",
    "We also created a function that evaluates a model given the model and the validation dataloader. Again, the validation loop is quite standard. We compute the loss for each batch and then we average it while also saving the model in case the validation loss is lower than the previous one, like a checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch, val_loss_min_input, model, dataloader):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(dataloader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            val_loss += loss_fn(outputs, targets).item()\n",
    "        \n",
    "        val_loss /= num_batches\n",
    "        #outputs, targets = fin_outputs, fin_targets\n",
    "        print(f\"\\nValidation loss: {val_loss:>8f}.\")\n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if val_loss <= val_loss_min_input:\n",
    "            #create checkpoint variable and add important data\n",
    "            if epoch > 0: \n",
    "                print('Validation loss decreased ({:.8f} --> {:.8f}).  Saving model ...'.format(val_loss_min_input, val_loss))\n",
    "            else: print('Saving model ...')   \n",
    "            # save best moel\n",
    "            torch.save(model.state_dict(), \"model.pth\")\n",
    "            print(\"Saved PyTorch Model State to model.pth\\n\")\n",
    "            val_loss_min_input = val_loss\n",
    "    \n",
    "    return val_loss_min_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Metrics\n",
    "\n",
    "Before training the models, you are tasked to define the evaluation metrics for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* Evaluate your models using per-category binary F1-score.\n",
    "* Compute the average binary F1-score over all categories (macro F1-score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make heavy use of the sklearn library to compute the metrics, especially the f1 score, for each model as it is already implemented and it is quite easy to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random uniform classifier metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1scoreRandom(X_val, Y_val):\n",
    "    Y_pred_openness_unif = uniform_classifier_openness.predict(X_val)\n",
    "    Y_pred_conserv_unif = uniform_classifier_conserv.predict(X_val)\n",
    "    Y_pred_self_enh_unif = uniform_classifier_self_enh.predict(X_val)\n",
    "    Y_pred_self_trans_unif = uniform_classifier_self_trans.predict(X_val)\n",
    "    \n",
    "    Y_pred = []\n",
    "    for i in range(len(Y_pred_openness_unif)):\n",
    "        temp = []\n",
    "        temp.append(Y_pred_openness_unif[i])\n",
    "        temp.append(Y_pred_conserv_unif[i])\n",
    "        temp.append(Y_pred_self_enh_unif[i])\n",
    "        temp.append(Y_pred_self_trans_unif[i])\n",
    "        Y_pred.append(temp)\n",
    "        \n",
    "    return evaluate(Y_val, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority classifier metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1scoreMajority(X_val, Y_val):\n",
    "    Y_pred_openness_maj = majority_classifier_openness.predict(X_val)\n",
    "    Y_pred_conserv_maj = majority_classifier_conserv.predict(X_val)\n",
    "    Y_pred_self_enh_maj = majority_classifier_self_enh.predict(X_val)\n",
    "    Y_pred_self_trans_maj = majority_classifier_self_trans.predict(X_val)\n",
    "\n",
    "    Y_pred = []\n",
    "    for i in range(len(Y_pred_openness_maj)):\n",
    "        temp = []\n",
    "        temp.append(Y_pred_openness_maj[i])\n",
    "        temp.append(Y_pred_conserv_maj[i])\n",
    "        temp.append(Y_pred_self_enh_maj[i])\n",
    "        temp.append(Y_pred_self_trans_maj[i])\n",
    "        Y_pred.append(temp)\n",
    "        \n",
    "    return evaluate(Y_val, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa model metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testing_loader):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad(): # no need to calculate the gradients\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Training and Evaluation\n",
    "\n",
    "You are now tasked to train and evaluate **all** defined models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* Train **all** models on the train set.\n",
    "* Evaluate **all** models on the validation set.\n",
    "* Pick **at least** three seeds for robust estimation.\n",
    "* Compute metrics on the validation set.\n",
    "* Report **per-category** and **macro** F1-score for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed definition\n",
    "#seed = 42\n",
    "#seed = 69\n",
    "seed = 420\n",
    "\n",
    "# Set the seed for numpy to have reproducible experiments\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the random uniform classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.49      0.42       698\n",
      "           1       0.47      0.51      0.49       885\n",
      "           2       0.75      0.50      0.60      1426\n",
      "           3       0.79      0.52      0.62      1506\n",
      "\n",
      "   micro avg       0.60      0.50      0.55      4515\n",
      "   macro avg       0.59      0.50      0.53      4515\n",
      "weighted avg       0.65      0.50      0.56      4515\n",
      " samples avg       0.56      0.51      0.49      4515\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\39328\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Y_train_openness = train['Openness to change']\n",
    "Y_train_conserv = train['Conservation']\n",
    "Y_train_self_enh = train['Self-enhancement']\n",
    "Y_train_self_trans = train['Self-transcendence']\n",
    "uniform_classifier_openness.fit(X_train, Y_train_openness)\n",
    "uniform_classifier_conserv.fit(X_train, Y_train_conserv)\n",
    "uniform_classifier_self_enh.fit(X_train, Y_train_self_enh)\n",
    "uniform_classifier_self_trans.fit(X_train, Y_train_self_trans)\n",
    "f1scoreRandom(X_val, Y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the majority classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majority_classifier_openness.fit(X_train, Y_train_openness)\n",
    "majority_classifier_conserv.fit(X_train, Y_train_conserv)\n",
    "majority_classifier_self_enh.fit(X_train, Y_train_self_enh)\n",
    "majority_classifier_self_trans.fit(X_train, Y_train_self_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       698\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.75      1.00      0.86      1426\n",
      "           3       0.79      1.00      0.89      1506\n",
      "\n",
      "   micro avg       0.77      0.65      0.71      4515\n",
      "   macro avg       0.39      0.50      0.44      4515\n",
      "weighted avg       0.50      0.65      0.57      4515\n",
      " samples avg       0.77      0.68      0.70      4515\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\39328\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "f1scoreMajority(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training RoBERTa w/C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_min = np.Inf\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "    trainBert(model_c, train_dataloaderc)\n",
    "    val_loss_min = validation(epoch, val_loss_min, model_c, train_dataloaderc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa w/C evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold \n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "outputs_c, targets_c = test(model_c, val_dataloaderc)\n",
    "results_c = {}\n",
    "for tr in np.arange(0.1, 0.9, 0.1):\n",
    "    tr = round(tr, 2)\n",
    "    predictions_c = np.array(outputs_c) >= tr\n",
    "    f1_c = f1_score(targets_c, predictions_c, average='macro', zero_division=1)\n",
    "    results_c[tr] = f1_c\n",
    "\n",
    "for k, v in results_c.items():\n",
    "    print(f\"Threshold: {k}, F1-score: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = max(results_c, key=results_c.get)\n",
    "print(f\"Best threshold: {th}, F1-score: {results_c[th]}\")\n",
    "predictions_c = np.array(outputs_c) >= th\n",
    "labels = ['Openness to change', 'Conservation', 'Self-enhancement', 'Self-transcendence']\n",
    "print(classification_report(targets_c, predictions_c, target_names=labels ,zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training RoBERTa w/CP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.703765  [    0/ 5393]\n",
      "Train loss: 0.583361  [ 1600/ 5393]\n",
      "Train loss: 0.528497  [ 3200/ 5393]\n",
      "Train loss: 0.531994  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.462537.\n",
      "Saving model ...\n",
      "Saved PyTorch Model State to model.pth\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.571636  [    0/ 5393]\n",
      "Train loss: 0.351225  [ 1600/ 5393]\n",
      "Train loss: 0.554982  [ 3200/ 5393]\n",
      "Train loss: 0.365206  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.393426.\n",
      "Validation loss decreased (0.46253744 --> 0.39342580).  Saving model ...\n",
      "Saved PyTorch Model State to model.pth\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.464953  [    0/ 5393]\n",
      "Train loss: 0.298749  [ 1600/ 5393]\n",
      "Train loss: 0.488705  [ 3200/ 5393]\n",
      "Train loss: 0.282428  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.337891.\n",
      "Validation loss decreased (0.39342580 --> 0.33789086).  Saving model ...\n",
      "Saved PyTorch Model State to model.pth\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.312650  [    0/ 5393]\n",
      "Train loss: 0.249999  [ 1600/ 5393]\n",
      "Train loss: 0.385601  [ 3200/ 5393]\n",
      "Train loss: 0.186010  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.280475.\n",
      "Validation loss decreased (0.33789086 --> 0.28047495).  Saving model ...\n",
      "Saved PyTorch Model State to model.pth\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.230729  [    0/ 5393]\n",
      "Train loss: 0.203276  [ 1600/ 5393]\n",
      "Train loss: 0.238281  [ 3200/ 5393]\n",
      "Train loss: 0.166196  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.226032.\n",
      "Validation loss decreased (0.28047495 --> 0.22603230).  Saving model ...\n",
      "Saved PyTorch Model State to model.pth\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.140500  [    0/ 5393]\n",
      "Train loss: 0.134190  [ 1600/ 5393]\n",
      "Train loss: 0.237313  [ 3200/ 5393]\n",
      "Train loss: 0.127992  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.208094.\n",
      "Validation loss decreased (0.22603230 --> 0.20809412).  Saving model ...\n",
      "Saved PyTorch Model State to model.pth\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.118452  [    0/ 5393]\n",
      "Train loss: 0.133277  [ 1600/ 5393]\n",
      "Train loss: 0.170576  [ 3200/ 5393]\n",
      "Train loss: 0.067602  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.196087.\n",
      "Validation loss decreased (0.20809412 --> 0.19608685).  Saving model ...\n",
      "Saved PyTorch Model State to model.pth\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.054502  [    0/ 5393]\n",
      "Train loss: 0.069364  [ 1600/ 5393]\n",
      "Train loss: 0.125105  [ 3200/ 5393]\n",
      "Train loss: 0.080505  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.220526.\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.094883  [    0/ 5393]\n",
      "Train loss: 0.072296  [ 1600/ 5393]\n",
      "Train loss: 0.105217  [ 3200/ 5393]\n",
      "Train loss: 0.082120  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.156515.\n",
      "Validation loss decreased (0.19608685 --> 0.15651457).  Saving model ...\n",
      "Saved PyTorch Model State to model.pth\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.026083  [    0/ 5393]\n",
      "Train loss: 0.059119  [ 1600/ 5393]\n",
      "Train loss: 0.043245  [ 3200/ 5393]\n",
      "Train loss: 0.064476  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.136321.\n",
      "Validation loss decreased (0.15651457 --> 0.13632126).  Saving model ...\n",
      "Saved PyTorch Model State to model.pth\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_loss_min = np.Inf\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "    trainBert(model_cp, train_dataloadercp)\n",
    "    val_loss_min = validation(epoch, val_loss_min, model_cp, train_dataloadercp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1, F1-score: 0.7664998271281073\n",
      "Threshold: 0.2, F1-score: 0.7598361214162657\n",
      "Threshold: 0.3, F1-score: 0.752378444116399\n",
      "Threshold: 0.4, F1-score: 0.7460465322682589\n",
      "Threshold: 0.5, F1-score: 0.7383949924639484\n",
      "Threshold: 0.6, F1-score: 0.7311342424612522\n",
      "Threshold: 0.7, F1-score: 0.7236938681282479\n",
      "Threshold: 0.8, F1-score: 0.7110596139396325\n"
     ]
    }
   ],
   "source": [
    "# Threshold \n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "outputs_cp, targets_cp = test(model_cp, val_dataloadercp)\n",
    "results_cp = {}\n",
    "for tr in np.arange(0.1, 0.9, 0.1):\n",
    "    tr = round(tr, 2)\n",
    "    predictions_cp = np.array(outputs_cp) >= tr\n",
    "    f1_cp = f1_score(targets_cp, predictions_cp, average='macro', zero_division=1)\n",
    "    results_cp[tr] = f1_cp\n",
    "\n",
    "for k, v in results_cp.items():\n",
    "    print(f\"Threshold: {k}, F1-score: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.1, F1-score: 0.7664998271281073\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Openness to change       0.63      0.67      0.65       698\n",
      "      Conservation       0.66      0.73      0.69       885\n",
      "  Self-enhancement       0.76      0.99      0.86      1426\n",
      "Self-transcendence       0.83      0.91      0.87      1506\n",
      "\n",
      "         micro avg       0.74      0.86      0.80      4515\n",
      "         macro avg       0.72      0.82      0.77      4515\n",
      "      weighted avg       0.74      0.86      0.80      4515\n",
      "       samples avg       0.77      0.88      0.79      4515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "th = max(results_cp, key=results_cp.get)\n",
    "print(f\"Best threshold: {th}, F1-score: {results_cp[th]}\")\n",
    "predictions_cp = np.array(outputs_cp) >= th\n",
    "labels = ['Openness to change', 'Conservation', 'Self-enhancement', 'Self-transcendence']\n",
    "print(classification_report(targets_cp, predictions_cp, target_names=labels ,zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training RoBERTa w/CPS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.703765  [    0/ 5393]\n",
      "Train loss: 0.583361  [ 1600/ 5393]\n",
      "Train loss: 0.528497  [ 3200/ 5393]\n",
      "Train loss: 0.531994  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.462537.\n",
      "Saving model ...\n",
      "Saved PyTorch Model State to model.pth\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.571636  [    0/ 5393]\n",
      "Train loss: 0.351225  [ 1600/ 5393]\n",
      "Train loss: 0.554982  [ 3200/ 5393]\n",
      "Train loss: 0.365206  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.393426.\n",
      "Validation loss decreased (0.46253744 --> 0.39342580).  Saving model ...\n",
      "Saved PyTorch Model State to model.pth\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.464953  [    0/ 5393]\n",
      "Train loss: 0.298749  [ 1600/ 5393]\n",
      "Train loss: 0.488705  [ 3200/ 5393]\n",
      "Train loss: 0.282428  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.337891.\n",
      "Validation loss decreased (0.39342580 --> 0.33789086).  Saving model ...\n",
      "Saved PyTorch Model State to model.pth\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.312650  [    0/ 5393]\n",
      "Train loss: 0.249999  [ 1600/ 5393]\n",
      "Train loss: 0.385601  [ 3200/ 5393]\n",
      "Train loss: 0.186010  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.280475.\n",
      "Validation loss decreased (0.33789086 --> 0.28047495).  Saving model ...\n",
      "Saved PyTorch Model State to model.pth\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.230729  [    0/ 5393]\n",
      "Train loss: 0.203276  [ 1600/ 5393]\n",
      "Train loss: 0.238281  [ 3200/ 5393]\n",
      "Train loss: 0.166196  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.226032.\n",
      "Validation loss decreased (0.28047495 --> 0.22603230).  Saving model ...\n",
      "Saved PyTorch Model State to model.pth\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.140500  [    0/ 5393]\n",
      "Train loss: 0.134190  [ 1600/ 5393]\n",
      "Train loss: 0.237313  [ 3200/ 5393]\n",
      "Train loss: 0.127992  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.208094.\n",
      "Validation loss decreased (0.22603230 --> 0.20809412).  Saving model ...\n",
      "Saved PyTorch Model State to model.pth\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.118452  [    0/ 5393]\n",
      "Train loss: 0.133277  [ 1600/ 5393]\n",
      "Train loss: 0.170576  [ 3200/ 5393]\n",
      "Train loss: 0.067602  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.196087.\n",
      "Validation loss decreased (0.20809412 --> 0.19608685).  Saving model ...\n",
      "Saved PyTorch Model State to model.pth\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.054502  [    0/ 5393]\n",
      "Train loss: 0.069364  [ 1600/ 5393]\n",
      "Train loss: 0.125105  [ 3200/ 5393]\n",
      "Train loss: 0.080505  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.220526.\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.094883  [    0/ 5393]\n",
      "Train loss: 0.072296  [ 1600/ 5393]\n",
      "Train loss: 0.105217  [ 3200/ 5393]\n",
      "Train loss: 0.082120  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.156515.\n",
      "Validation loss decreased (0.19608685 --> 0.15651457).  Saving model ...\n",
      "Saved PyTorch Model State to model.pth\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.026083  [    0/ 5393]\n",
      "Train loss: 0.059119  [ 1600/ 5393]\n",
      "Train loss: 0.043245  [ 3200/ 5393]\n",
      "Train loss: 0.064476  [ 4800/ 5393]\n",
      "\n",
      "Validation loss: 0.136321.\n",
      "Validation loss decreased (0.15651457 --> 0.13632126).  Saving model ...\n",
      "Saved PyTorch Model State to model.pth\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_loss_min = np.Inf\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "    trainBert(model_cps, train_dataloadercp)\n",
    "    val_loss_min = validation(epoch, val_loss_min, model_cps, train_dataloadercp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1, F1-score: 0.7664998271281073\n",
      "Threshold: 0.2, F1-score: 0.7598361214162657\n",
      "Threshold: 0.3, F1-score: 0.752378444116399\n",
      "Threshold: 0.4, F1-score: 0.7460465322682589\n",
      "Threshold: 0.5, F1-score: 0.7383949924639484\n",
      "Threshold: 0.6, F1-score: 0.7311342424612522\n",
      "Threshold: 0.7, F1-score: 0.7236938681282479\n",
      "Threshold: 0.8, F1-score: 0.7110596139396325\n"
     ]
    }
   ],
   "source": [
    "# Threshold \n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "outputs_cps, targets_cps = test(model_cps, val_dataloadercps)\n",
    "results_cps = {}\n",
    "for tr in np.arange(0.1, 0.9, 0.1):\n",
    "    tr = round(tr, 2)\n",
    "    predictions_cps = np.array(outputs_cps) >= tr\n",
    "    f1_cps = f1_score(targets_cps, predictions_cps, average='macro', zero_division=1)\n",
    "    results_cps[tr] = f1_cps\n",
    "\n",
    "for k, v in results_cps.items():\n",
    "    print(f\"Threshold: {k}, F1-score: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.1, F1-score: 0.7664998271281073\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Openness to change       0.63      0.67      0.65       698\n",
      "      Conservation       0.66      0.73      0.69       885\n",
      "  Self-enhancement       0.76      0.99      0.86      1426\n",
      "Self-transcendence       0.83      0.91      0.87      1506\n",
      "\n",
      "         micro avg       0.74      0.86      0.80      4515\n",
      "         macro avg       0.72      0.82      0.77      4515\n",
      "      weighted avg       0.74      0.86      0.80      4515\n",
      "       samples avg       0.77      0.88      0.79      4515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "th = max(results_cps, key=results_cps.get)\n",
    "print(f\"Best threshold: {th}, F1-score: {results_cps[th]}\")\n",
    "predictions_cps = np.array(outputs_cps) >= th\n",
    "labels = ['Openness to change', 'Conservation', 'Self-enhancement', 'Self-transcendence']\n",
    "print(classification_report(targets_cps, predictions_cps, target_names=labels ,zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Error Analysis\n",
    "\n",
    "You are tasked to discuss your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* **Compare** classification performance of BERT-based models with respect to baselines.\n",
    "* Discuss **difference in prediction** between the best performing BERT-based model and its variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the models:\n",
    "model_c.load_state_dict(torch.load(f'seed_{seed}/model_c_{seed}.pth', map_location=torch.device('cpu')))\n",
    "model_cp.load_state_dict(torch.load(f'seed_{seed}/model_cp_{seed}.pth', map_location=torch.device('cpu')))\n",
    "model_cps.load_state_dict(torch.load(f'seed_{seed}/model_cps_{seed}.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the random uniform classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.50      0.38       474\n",
      "           1       0.42      0.50      0.45       647\n",
      "           2       0.70      0.51      0.59      1119\n",
      "           3       0.79      0.48      0.60      1268\n",
      "\n",
      "   micro avg       0.55      0.49      0.52      3508\n",
      "   macro avg       0.55      0.50      0.50      3508\n",
      "weighted avg       0.63      0.49      0.54      3508\n",
      " samples avg       0.52      0.49      0.46      3508\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\39328\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "f1scoreRandom(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the majority classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       474\n",
      "           1       0.00      0.00      0.00       647\n",
      "           2       0.71      1.00      0.83      1119\n",
      "           3       0.80      1.00      0.89      1268\n",
      "\n",
      "   micro avg       0.76      0.68      0.72      3508\n",
      "   macro avg       0.38      0.50      0.43      3508\n",
      "weighted avg       0.52      0.68      0.59      3508\n",
      " samples avg       0.76      0.72      0.71      3508\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\39328\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "f1scoreMajority(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing RoBERTa w/C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1, F1-score: 0.7021041069062377\n",
      "Threshold: 0.2, F1-score: 0.7032014069869715\n",
      "Threshold: 0.3, F1-score: 0.6922775573369017\n",
      "Threshold: 0.4, F1-score: 0.6581717847544282\n",
      "Threshold: 0.5, F1-score: 0.5990586778298223\n",
      "Threshold: 0.6, F1-score: 0.519960347889965\n",
      "Threshold: 0.7, F1-score: 0.4932170195675176\n",
      "Threshold: 0.8, F1-score: 0.40054647697399653\n"
     ]
    }
   ],
   "source": [
    "# Threshold \n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "outputs_c, targets_c = test(model_c, test_dataloaderc)\n",
    "results_c = {}\n",
    "for tr in np.arange(0.1, 0.9, 0.1):\n",
    "    tr = round(tr, 2)\n",
    "    predictions_c = np.array(outputs_c) >= tr\n",
    "    f1_c = f1_score(targets_c, predictions_c, average='macro', zero_division=1)\n",
    "    results_c[tr] = f1_c\n",
    "\n",
    "for k, v in results_c.items():\n",
    "    print(f\"Threshold: {k}, F1-score: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.2, F1-score: 0.7032014069869715\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Openness to change       0.35      0.83      0.50       474\n",
      "      Conservation       0.43      0.96      0.59       647\n",
      "  Self-enhancement       0.71      1.00      0.83      1119\n",
      "Self-transcendence       0.80      1.00      0.89      1268\n",
      "\n",
      "         micro avg       0.60      0.97      0.74      3508\n",
      "         macro avg       0.57      0.95      0.70      3508\n",
      "      weighted avg       0.64      0.97      0.76      3508\n",
      "       samples avg       0.60      0.98      0.72      3508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "th = max(results_c, key=results_c.get)\n",
    "print(f\"Best threshold: {th}, F1-score: {results_c[th]}\")\n",
    "predictions_c = np.array(outputs_c) >= th\n",
    "labels = ['Openness to change', 'Conservation', 'Self-enhancement', 'Self-transcendence']\n",
    "print(classification_report(targets_c, predictions_c, target_names=labels ,zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing RoBERTa w/CP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1, F1-score: 0.7392718940125877\n",
      "Threshold: 0.2, F1-score: 0.7298134936066797\n",
      "Threshold: 0.3, F1-score: 0.7190667335932064\n",
      "Threshold: 0.4, F1-score: 0.7121845833254248\n",
      "Threshold: 0.5, F1-score: 0.704612748059367\n",
      "Threshold: 0.6, F1-score: 0.6956746813749931\n",
      "Threshold: 0.7, F1-score: 0.683073747221489\n",
      "Threshold: 0.8, F1-score: 0.665428965827218\n"
     ]
    }
   ],
   "source": [
    "# # Threshold \n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "outputs_cp, targets_cp = test(model_cp, test_dataloadercp)\n",
    "results_cp = {}\n",
    "for tr in np.arange(0.1, 0.9, 0.1):\n",
    "    tr = round(tr, 2)\n",
    "    predictions_cp = np.array(outputs_cp) >= tr\n",
    "    f1_cp = f1_score(targets_cp, predictions_cp, average='macro', zero_division=1)\n",
    "    results_cp[tr] = f1_cp\n",
    "\n",
    "for k, v in results_cp.items():\n",
    "    print(f\"Threshold: {k}, F1-score: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.1, F1-score: 0.7392718940125877\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Openness to change       0.65      0.57      0.61       474\n",
      "      Conservation       0.53      0.83      0.65       647\n",
      "  Self-enhancement       0.72      0.99      0.83      1119\n",
      "Self-transcendence       0.84      0.90      0.87      1268\n",
      "\n",
      "         micro avg       0.71      0.87      0.78      3508\n",
      "         macro avg       0.68      0.82      0.74      3508\n",
      "      weighted avg       0.72      0.87      0.78      3508\n",
      "       samples avg       0.72      0.90      0.76      3508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "th = max(results_cp, key=results_cp.get)\n",
    "print(f\"Best threshold: {th}, F1-score: {results_cp[th]}\")\n",
    "predictions_cp = np.array(outputs_cp) >= th\n",
    "labels = ['Openness to change', 'Conservation', 'Self-enhancement', 'Self-transcendence']\n",
    "print(classification_report(targets_cp, predictions_cp, target_names=labels ,zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing RoBERTa w/CPS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1, F1-score: 0.7459630187009028\n",
      "Threshold: 0.2, F1-score: 0.7477209770869597\n",
      "Threshold: 0.3, F1-score: 0.746951541983534\n",
      "Threshold: 0.4, F1-score: 0.7428531315596946\n",
      "Threshold: 0.5, F1-score: 0.7362050718941726\n",
      "Threshold: 0.6, F1-score: 0.7326646072836327\n",
      "Threshold: 0.7, F1-score: 0.7195525217299543\n",
      "Threshold: 0.8, F1-score: 0.7069670564544206\n"
     ]
    }
   ],
   "source": [
    "# Threshold \n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "outputs_cps, targets_cps = test(model_cps, test_dataloadercps)\n",
    "results_cps = {}\n",
    "for tr in np.arange(0.1, 0.9, 0.1):\n",
    "    tr = round(tr, 2)\n",
    "    predictions_cps = np.array(outputs_cps) >= tr\n",
    "    f1_cps = f1_score(targets_cps, predictions_cps, average='macro', zero_division=1)\n",
    "    results_cps[tr] = f1_cps\n",
    "\n",
    "for k, v in results_cps.items():\n",
    "    print(f\"Threshold: {k}, F1-score: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.2, F1-score: 0.7477209770869597\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Openness to change       0.61      0.63      0.62       474\n",
      "      Conservation       0.57      0.79      0.66       647\n",
      "  Self-enhancement       0.73      0.97      0.83      1119\n",
      "Self-transcendence       0.82      0.95      0.88      1268\n",
      "\n",
      "         micro avg       0.71      0.88      0.79      3508\n",
      "         macro avg       0.68      0.83      0.75      3508\n",
      "      weighted avg       0.72      0.88      0.79      3508\n",
      "       samples avg       0.73      0.91      0.77      3508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "th = max(results_cps, key=results_cps.get)\n",
    "print(f\"Best threshold: {th}, F1-score: {results_cps[th]}\")\n",
    "predictions_cps = np.array(outputs_cps) >= th\n",
    "labels = ['Openness to change', 'Conservation', 'Self-enhancement', 'Self-transcendence']\n",
    "print(classification_report(targets_cps, predictions_cps, target_names=labels ,zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_color(number_of_colors):\n",
    "    # return a random color to be used for the plot\n",
    "    color_list = []\n",
    "    for i in range(number_of_colors):\n",
    "        color_list.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n",
    "    return color_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABr0AAAJPCAYAAADBpx9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABZYklEQVR4nO39e7xsd10f/r/eSYggck/gJ7kgYAQTf1DgCLS1lUutCdhG8RYEuVSaxoJKq/2C6FcBldZ6KaDgIWJM0EpUpDRgJLRIoS1EkwgGEwyeBkgOwSYBBAEVAu/vHzNHdzZ7n7Mvs87MWvv5fDzW48y6zJr37E/WvDLznrWmujsAAAAAAAAwZscsuwAAAAAAAADYLU0vAAAAAAAARk/TCwAAAAAAgNHT9AIAAAAAAGD0NL0AAAAAAAAYPU0vAAAAAAAARk/TC/aIqvpgVf2TZdcBADtRVS+oqlcvuw4AFququqq+cn77TlX1xqr6RFX99oIf58Kq+slF7hOAve1oZdhYyFpWhaYXK6mqnlFV762qz1TVn1fVL1XV3Zdd19Cq6jFVdXDZdQAwDlX1XVV1ZVV9qqo+UlW/V1Vft+y6dmujPOzul3T3s5ZVEwCHV1VfV1XvnH/Y97Gq+t9V9bXb3M23JblPknt197cPUOae5H0mwOEdjQzTEIKjR9OLlVNVP5jkp5P8uyR3S/LoJPdL8t+q6vhl1gYAq6Kq/m2SlyZ5SWZvrk5N8sokZy+xrCRJVR237BoAOHqq6q5J3pTkF5LcM8lJSV6U5G+2uav7JXl/d9+22AoBYGOrkmHeQ8HiaHqxUuZB86Ik39fdb+7uz3X3B5N8R2bh8dT5di+sqtdV1W9W1V9W1R9V1UPX7Oe+VfU7VXVLVX2gqr5/zboXVtVvVdVr5ve9pqr2rVn/war6oaq6ev4Nj9+sqjuuWf9NVfWeqvqL+bdAHrJm3fOq6sPz/V5XVY+fL3/k/Jv4n6yq/1tVP7/Bc79zkt9Lct/5N/Y/NX8eX1JVL62qm+bTS6vqSw7zN/yXVfW+eQ3XVtXD16z+exs9r6q6R1W9af73+vj89slr9vk/quon5t90+cuqektVnbBm/dOq6kNV9dGq+n9rzaUUq+qYqnp+Vf2f+frfqqp7HuY/AwCOoKruluTFSZ7d3a/v7k/PM/ON3f3vDpcdh77tXVU/WFU3z88Qe+aafT9hnh9/Oc+0H1qz7nAZ+MF5Dl6d5NNV9aNV9bp1db+sql4+v/3MNXl1fVX9q/nyzfLwhVX162v29c/nGf4X85z66nW1bJrlACzcVyVJd7+2uz/f3X/V3W/p7quTpKr+xfw1/+NVdVlV3W/9DqrqRUl+LMl3zl/7v2eDbb6kqn62qm6Yv6/aX1V3mq87bL7N3aOqfneePX9QVQ9cs++XVdWNNXvPdlVV/aM16470HvKUqnr9/P3UR6vqF9es2/S51+yyWP+6qv5svt+fqKoHVtW75nX8Vq354ucWcviLsm+zXN3SqALsDYNnWFWdm+QpSf6f+fo3zpevfw91XP3dZ2iHPtf7ljX7eUZV/a95Fn68Zp95nrVu/fXz+36gqp6yZt2GnxfW7j5DfVjNPpP9y6r6zSS3e8+1k9xas/7s+X0/Of97nDlffreq+pV5zn+4qn6yqo7d2lCzZ3S3ybQyU5Izk9yW5LgN1l2U5LXz2y9M8rnMTh2+Q5IfSvKB+e1jklyVWdgcn+QBSa5P8o1r7vvXSZ6Q5Ngk/z7J5Wse54NJ/jDJfTP7hsf7kpw3X/fwJDcnedT8vk+fb/8lSR6U5MYk951v+xVJHji//a4k3z2//WVJHr3J839MkoPrlr04yeVJ7p3kxCTvTPITm9z/25N8OMnXJqkkX5nkflt4XvdK8q1JvjTJXZL8dpI3rNnv/0jyfzL7H4E7zef/w3zd6Uk+leTr5n/vn52PzT+Zr3/uvP6T53+nVx0aR5PJZDLtbDpcXs7Xb5od86y5bb7NHeZ5+Jkk95iv/0iSfzS/fY8kD5/f3jQD5+s/mOQ9SU6ZZ8X95vu963z9sfN9P3o+/8QkD5zn1dfPt334mhrX5+ELk/z6/PZXJfl0km+YP4f/J8mBJMevqWXDzDOZTCbT4qckd03y0czes511KFPm6755/hr91UmOS/KjSd65Zn0n+cr57b99rd/kcV6a5JL5a/tdkrwxyb+frztSvl2Y5GNJHjmv4z8nuXjNvp+a2fui45L8YJI/T3LHNXVt+B5yPv/HSf5Tkjtn9oHf123juV8y//udkdlZBW/N7D3s3ZJcm+Tp8223ksObvd/7olw1mUwm02w6ihl2YZKfXLfsg1nzHmq+7Nvnr+XHJPnOzN73fPl83TMy+8ztX86z4HuT3JTZe6o7J/lkkgfNt/3yJGes2ecXfV6YXXyGOt/+Q0n+TWa5+23z2n5yvn43ufXIJJ/I7P3eMZmdfffg+bo3ZPbZ4p0ze7/7h0n+1bL/OzKt1uRML1bNCUlu7Y1PBf7IfP0hV3X367r7c0l+PrM3F4/O7AX8xO5+cXd/truvT/LLSc5Zc9//1d2Xdvfnk/xakofm9l7e3Td198cyeyP19+bL/2WSV3X3H/Ts2x8XZfbG5NFJPp9ZU+f0qrpDd3+wu//P/H6fS/KVVXVCd3+quy/fxt/kKUle3N03d/ctmZ0J992bbPusJP+xu6/omQPd/aEjPa/u/mh3/053f6a7/zLJT2X2AeRav9rd7+/uv0ryW2v+Jt+W5I3d/b+6+7OZBWWvud+/SvIj3X2wu/8ms8D8tnLaNsBu3Cub52Vy5Oz43Hz957r70sy+vPCgNetOr6q7dvfHu/uP5ssPl4GHvLy7b+zZtyM/lOSPMnujmCSPS/KZQxnY3b/b3f9nnldvT/KWJP8oW/OdSX63u//b/P8DfjazRts/WFfLRlkOwIJ19ycz+xJcZ/be65aquqSq7pPZ+4F/393vm+fWSzK7AsUXfVP+cKqqMsuif9PdH5u/b3lJbv8+73D5liSv7+4/nNfxn7MmG7r71+fvi27r7p/L332x8ZDN3kM+MrMP7P5dz868/uvu/l/zdVt57j/d3Z/s7muS/EmSt3T39d39iczO0HrYfLut5rDsA9iGo5FhR/C376Hm9fz2/LX8C939m0n+LLOsOeRD3f3L8zy6KLPm1n3m676Q5Guq6k7d/ZF5tiSbf164m89QH51Zs+ul89x9XZIr1txvN7n1PUkumL/f+0J3f7i7/3Q+Jmclee48c2/O7Esna+sFTS9Wzq1JTtikIfLl8/WH3HjoRnd/IcnBzN5s3C+zSzf8xaEpyQvydwGQzL61d8hnktxx3WOuX/9l89v3S/KD6/Z9SmZndx3I7KymFya5uaouXnPZiO/J7Fvpf1pVV1TVNx3+z3A7983smxOHfGi+bCOnZHZG1mY2fF5V9aVV9aqaXaLwk0nekeTu604P3uxvct/cfiw+k9k3ZA65X5L/subv9b7MGoRrxwOA7floNs/L5MjZ8dF1DbO1r+vfmtk3+T5UVW+vqr8/X75pBq7Zz425vd9I8uT57e+azydJquqsqrq8Zj8U/RfzxzwhW3O75zf//4AbM/sG4CGb5RYAA5h/IPiM7j45yddk9lr90szy42VrsuNjmX3L/KTN9pUkVfWC+rvL8e3P7MzlL01y1Zp9vXm+/JDD5VtymGyo2WUR3ze/xNJfZHam1QmHue+h95CnZPYB5EZfRNnKc/+/a27/1QbzR3wvupXnB8DmjkKGHc7t3kPV7CdE3rPmMb8mm+TR/DO4JPmy7v50Zl8OPC/JR2p2Od8Hz9dv9nnhbj5DvW+SD3f32i++r30PupvcOly9d5g/v0P7fFVmZ3zB39L0YtW8K7Ou/5PWLqzZdcjPyuxSD4ecsmb9MZldPu+mzMLiA9199zXTXbr7CQuo78YkP7Vu31/a3a9Nku7+je7+usxehDvJT8+X/1l3PzmzF+GfTvK6+XNarzdYdtN8f4ecOl+2WX0P3GTd4fxgZt9ifFR33zXJP54vry3c9yOZ/e1nd5hdU/9e62o6a93f7I7d/eEd1AnAzLsyu8zEN2+yfjvZcTvzb/+dnVlmvSGzs3uTI2Tgobuv291vJ3lMzX4n8lsyb3rV7PfFfiezM7Tu0913T3Jp/i53NsrDTZ/f/Nv/p2R2yQ4Alqy7/zSzyzh9TWb58a/W5ceduvudR9jHS7r7y+bTeZl9AfKvMrtU06H93K27d93Yqdnvdz0vs9+Svsc8lz6Rrb0fujHJqZt8EWVHz/0wj3OkHN7MkXIVgLmBMizZ/LX4b5fPzyD75STPSXKveR79SbaWR+nuy7r7GzI7ceBP5/tKNv+8cDefoX4kyUnz92KHnLpu3zvNrcPV+zdJTlizz7t29xlb2Cd7iKYXK6Vnl3B4UZJfqKozq+oOVfUVmX1odjCz02gPeURVPWn+5uK5mb3oXZ7ZtVw/WbMfgrxTVR1bVV9TVV+7gBJ/Ocl5VfWomrlzVT2xqu5SVQ+qqsfNP8j768zekH0+SarqqVV14vyb6H8x39fnN9j//01yr6q625plr03yo1V1YlWdkNnlA399k/peneSHquoR8/q+counXN9lXu9fVNU9k/z4Fu5zyOuS/LOq+gc1+5HlF+X2Ybw/yU8dqmP+PM7exv4BWGeelz+W5BVV9c3zM3bvMD976j9me9nxt6rq+Kp6SlXdrWeXDfxk/i6vNs3Aw9R5S2a/A/mrmb2Zet981fGZXTbqliS31ezHl//pmrtulIdr/VaSJ1bV46vqDpl9eeNvMvvtMgCOsqp68PxMqZPn86dkdqbv5Zm9H/jhqjpjvu5uVfXt232M+XupX07yn6rq3vN9nVRV37iAp3CXzH4P7JYkx1XVj2X2Gy9b8YeZffD3H+bZeMeq+ofzdQt57nPbzuE1jpSrAHvW0ciwuf+b2W9mHc6dM2uC3TJ/vGdm1nw7oqq6T1X98/mX7P8ms0v8Hnovt9nnhbv5DPVdmWXn91fVcVX1pNz+Moy7ya1fSfLM+fu9Y+Z5/+Du/khml8X/uaq663zdA6tq/U+0sMdperFyuvs/ZnYq7c9m9mHbH2TWyX98z34T6pD/mtlpux/P7HdKnjS/huznk/yzzK4D+4HMvhH46swuT7Hb2q7M7Jq0vzh/3AOZ/YhkMvvw7j/MH+/PM/uG/Avm685Mck1VfSrJy5Kc091/vcH+/zSzDyqvr9lpuvdN8pNJrkxydZL3Zvb7KD+5SX2/ndnvcf1Gkr/M7Bv699zCU3tpZr+Fcmtmof7mLdzn0GNek+T7klyc2Zu9v8zshyoPjdXLMvtx5rdU1V/O9/+ore4fgI11988n+beZ/ZjyLZll5XMye+3fcnZs4LuTfLBml7s9L8lT5493uAw8nN9I8k+y5tKGPfsdlu/PrHn18cwufXjJmvUb5eHa537dvK5fyCy7/lmSf9az35YE4Oj7y8z+H/8PqurTmf0//58k+cHu/i+ZXe3i4nm2/ElmV/HYiedllj+Xz/f133P7393aqcsy+/2s92d2aaa/zhdfsndDa95/fmWSGzL7suZ3ztct7LnvIoePmKsAe9zRyrBfyey3k/+iqt6w0QbdfW2Sn8usofR/k/z/k/zvLe7/mMy+DHhTZpdh/Pok/3q+3w0/L9zNZ6jz915PyiyLPp5Z9r1+zfrd5NYfJnlmZr/X9Ykkb8/fXenjaZl9ifLa+X5fl9mZbfC36vaX3YRxqKoXJvnK7n7qsmvh9qrqyzI7m+207v7AkssBAAAAAGCPcKYXsGtV9c/ml9a6c2Zn6L03yQeXWxUAAAAAAHvJYE2vqrqgqm6uqj/ZZH1V1cur6kBVXV1VDx+qFmBwZ2d2+vRNSU7L7PKNTiNlMmQaAFMh0wCYAnkGwGaGPNPrwsx+x2gzZ2X24fhpSc5N8ksD1sLEdPcLXdpwdXT3s7r77t19t+5+/Py3VmBKLoxMA2AaLoxMA2D8Low8A2ADgzW9uvsdmf1o3mbOTvKanrk8yd2ryo/OAbByZBoAUyHTAJgCeQbAZo5b4mOflOTGNfMH58s+sn7Dqjo3s29l5M53vvMjHvzgBx+VAgHYuauuuurW7j5x2XUcJTINYMJkmkwDmIo9lGnyDGDCDpdny2x61QbLNvwNoO4+P8n5SbJv376+8sorh6wLgAWoqg8tu4ajSKYBTJhMk2kAU7GHMk2eAUzY4fJsyN/0OpKDSU5ZM39ykpuWVAsA7IZMA2AqZBoAUyDPAPaoZTa9LknytJp5dJJPdPcXnWIMACMg0wCYCpkGwBTIM4A9arDLG1bVa5M8JskJVXUwyY8nuUOSdPf+JJcmeUKSA0k+k+SZQ9UCALsh0wCYCpkGwBTIMwA2M1jTq7uffIT1neTZQz0+ACyKTANgKmQaAFMgzwDYzDIvbwgAAAAAAAALoekFAAAAAADA6Gl6AQAAAAAAMHqaXgAAAAAAAIyephcAAAAAAACjp+kFAAAAAADA6Gl6AQAAAAAAMHqaXgAAAAAAAIyephcAAAAAAACjp+kFAAAAAADA6Gl6AQAAAAAAMHqaXgAAAAAAAIzeccsuAAAAAAAAVtUNT3/3skvYs0696GHLLoGRcaYXAAAAAAAAo6fpBQAAAAAAwOhpegEAAAAAADB6ml4AAAAAAACMnqYXAAAAAAAAo6fpBQAAAAAAwOhpegEAAAAAADB6ml4AAAAAAACMnqYXAAAAAAAAo6fpBQAAAAAAwOgdN+TOq+rMJC9LcmySV3f3f1i3/m5Jfj3JqfNafra7f3XImgBgJ2QaAFMgzwCYCpkG7NZL9t+87BL2rBecd+/B9j3YmV5VdWySVyQ5K8npSZ5cVaev2+zZSa7t7ocmeUySn6uq44eqCQB2QqYBMAXyDICpkGkAbGbIM70emeRAd1+fJFV1cZKzk1y7ZptOcpeqqiRfluRjSW4bsCYm7Ianv3vZJexJp170sGWXAEeDTANgCuQZAFMh0wDY0JBNr5OS3Lhm/mCSR63b5heTXJLkpiR3SfKd3f2F9TuqqnOTnJskp5566iDFAsBhyDQApmBheZbINACWamXfo53z2DN2vQ+27+K3XbPsEoAVMdjlDZPUBst63fw3JnlPkvsm+XtJfrGq7vpFd+o+v7v3dfe+E088cdF1AsCRyDQApmBheZbINACWyns0ADY0ZNPrYJJT1syfnNk3K9Z6ZpLX98yBJB9I8uABawKAnZBpAEyBPANgKmQaABsasul1RZLTqur+8x+JPCezU4rXuiHJ45Okqu6T5EFJrh+wJgDYCZkGwBTIMwCmQqYBsKHBftOru2+rquckuSzJsUku6O5rquq8+fr9SX4iyYVV9d7MTkt+XnffOlRNALATMg2AKZBnAEyFTANgM4M1vZKkuy9Ncum6ZfvX3L4pyT8dsgYAWASZBsAUyDMApkKmAbCRIS9vCAAAAAAAAEeFphcAAAAAAACjp+kFAAAAAADA6Gl6AQAAAAAAMHqaXgAAAAAAAIzeccsuAAAAAJieG57+7mWXsGedetHDll0CAMBSaHoBAAAAsCUv2X/zskvYs15w3r2XXQIArDyXNwQAAAAAAGD0NL0AAAAAAAAYPZc3BAAAYKnOeewZyy5hz7r4bdcsuwQAAFgYZ3oBAAAAAAAweppeAAAAAAAAjJ7LGwIArJgbnv7uZZewJ5160cOWXQIAAACwC870AgAAAAAAYPQ0vQAAAAAAABg9TS8AAAAAAABGT9MLAAAAAACA0dP0AgAAAAAAYPQ0vQAAAAAAABg9TS8AAAAAAABGT9MLAAAAAACA0dP0AgAAAAAAYPQ0vQAAAAAAABi9LTe9quqkqvoHVfWPD01buM+ZVXVdVR2oqudvss1jquo9VXVNVb19O8UDwE7INACmQJ4BMBUyDYBFOW4rG1XVTyf5ziTXJvn8fHEnecdh7nNsklck+YYkB5NcUVWXdPe1a7a5e5JXJjmzu2+oqnvv5EkA0/WS/Tcvu4Q96wXnTfMlWaYBMAXyDICpkGkALNKWml5JvjnJg7r7b7ax70cmOdDd1ydJVV2c5OzMAuyQ70ry+u6+IUm626fbAAztmyPTABi/b448A2AavjkyDYAF2erlDa9Pcodt7vukJDeumT84X7bWVyW5R1X9j6q6qqqettGOqurcqrqyqq685ZZbtlkGANyOTANgCpaaZ4lMA2BhvEcDYGG2eqbXZ5K8p6remuRvv3XR3d9/mPvUBst6g8d/RJLHJ7lTkndV1eXd/f7b3an7/CTnJ8m+ffvW7wMAtkOmATAFS82z+WPJNAAWwXs0ABZmq02vS+bTdhxMcsqa+ZOT3LTBNrd296eTfLqq3pHkoUm+6A0VACyITANgCuQZAFMh0wBYmC01vbr7oqo6PrPTgpPkuu7+3BHudkWS06rq/kk+nOSczK6lu9Z/TfKLVXVckuOTPCrJf9pq8QCwXTINgCmQZwBMhUwDYJG21PSqqsckuSjJBzM7ffiUqnp6d79js/t0921V9ZwklyU5NskF3X1NVZ03X7+/u99XVW9OcnWSLyR5dXf/yS6eDwAclkwDYArkGQBTIdMAWKStXt7w55L80+6+Lkmq6quSvDaz6+JuqrsvTXLpumX7183/TJKf2WrBALBLMg1Yipfsv3nZJexJLzjv3ssuYSjyDICpkGkALMwxW9zuDoeCJ0nmP/h4h2FKAoBByTQApkCeATAVMg2AhdnqmV5XVtWvJPm1+fxTklw1TEkAMCiZBsAUyDMApkKmAbAwW216fW+SZyf5/syurfuOJK8cqigAGJBMA2AK5BkAUyHTAFiYLTW9uvtvkvz8fAKA0ZJpAEyBPANgKmQaAIt02KZXVf1Wd39HVb03Sa9f390PGawyAFggmQbAFMgzAKZCpgEwhCOd6fUD83+/aehCAGBgMg2AKZBnAEyFTANg4Y453Mru/sj85q1JbuzuDyX5kiQPTXLTwLUBwMLINACmQJ4BMBUyDYAhHLbptcY7ktyxqk5K8tYkz0xy4VBFAcCAZBoAUyDPAJgKmQbAwmy16VXd/ZkkT0ryC939LUlOH64sABiMTANgCuQZAFMh0wBYmC03varq7yd5SpLfnS870u+BAcAqkmkATIE8A2AqZBoAC7PVptdzk/xwkv/S3ddU1QOSvG2wqgBgOM+NTANg/J4beQbANDw3Mg2ABdnStya6++1J3r5m/vok3z9UUQAwFJkGwBTIMwCmQqYBsEiHbXpV1Uu7+7lV9cYkvX59d//zwSoDgAWSaQBMgTwDYCpkGgBDONKZXr82//dnhy4EAAYm0wCYAnkGwFTINAAW7rBNr+6+an7zyiR/1d1fSJKqOjbJlwxcGwAsjEwDYArkGQBTIdMAGMIxW9zurUm+dM38nZL898WXAwCDk2kATIE8A2AqZBoAC7PVptcdu/tTh2bmt7/0MNsDwKqSaQBMgTwDYCpkGgALs9Wm16er6uGHZqrqEUn+apiSAGBQMg2AKZBnAEyFTANgYQ77m15rPDfJb1fVTfP5L0/ynYNUBADDem5kGgDj99zIMwCm4bmRaQAsyJaaXt19RVU9OMmDklSSP+3uzw1aGQAMQKYBMAXyDICpkGkALNKWLm9YVV+a5HlJfqC735vkK6rqmwatDAAGINMAmAJ5BsBUyDQAFmmrlzf81SRXJfn78/mDSX47yZuGKAoABjSZTDvnsWcsu4Q96+K3XbPsEgAmk2cA7HkyDYCF2dKZXkke2N3/McnnkqS7/yqz040BYGxkGgBTIM8AmAqZBsDCbLXp9dmqulOSTpKqemCSvznSnarqzKq6rqoOVNXzD7Pd11bV56vq27ZYDwDslEwDYArkGQBTIdMAWJitXt7wx5O8OckpVfWfk/zDJM843B2q6tgkr0jyDZmdlnxFVV3S3ddusN1PJ7lse6UDwI7INACmQJ4BMBUyDYCFOWLTq6qOSXKPJE9K8ujMTi/+ge6+9Qh3fWSSA919/Xw/Fyc5O8m167b7viS/k+Rrt1c6AGyPTANgCuQZAFMh0wBYtCNe3rC7v5DkOd390e7+3e5+0xaCJ0lOSnLjmvmD82V/q6pOSvItSfYfbkdVdW5VXVlVV95yyy1beGgA+GIyDYApWIU8m28r0wDYlVXINHkGMC1b/U2v/1ZVP1RVp1TVPQ9NR7jPRj842evmX5rked39+cPtqLvP7+593b3vxBNP3GLJALAhmQbAFCw1zxKZBsDCeI8GwMJs9Te9/kVmwfGv1y1/wGHuczDJKWvmT05y07pt9iW5uKqS5IQkT6iq27r7DVusCwC2S6YBMAXyDICpkGkALMxWm16nZxY8X5dZCP3PHPlyF1ckOa2q7p/kw0nOSfJdazfo7vsful1VFyZ5k+ABYGAyDYApkGcATIVMA2Bhttr0uijJJ5O8fD7/5Pmy79jsDt19W1U9J8llSY5NckF3X1NV583XH/Ea8QAwAJkGwBTIMwCmQqYBsDBbbXo9qLsfumb+bVX1x0e6U3dfmuTSdcs2DJ3ufsYWawGA3ZBpAEyBPANgKmQaAAtzzBa3e3dVPfrQTFU9Ksn/HqYkABiUTANgCuQZAFMh0wBYmK2e6fWoJE+rqhvm86cmeV9VvTdJd/dDBqluIOc89oxll7AnXfy2a5ZdAkAysUwDYM+SZwBMhUwDYGG22vQ6c9AqAODokWkATIE8A2AqZBoAC7Olpld3f2joQgDgaJBpAEyBPANgKmQaAIu01d/0AgAAAAAAgJWl6QUAAAAAAMDoaXoBAAAAAAAweppeAAAAAAAAjJ6mFwAAAAAAAKOn6QUAAAAAAMDoaXoBAAAAAAAweppeAAAAAAAAjJ6mFwAAAAAAAKOn6QUAAAAAAMDoaXoBAAAAAAAweppeAAAAAAAAjJ6mFwAAAAAAAKOn6QUAAAAAAMDoaXoBAAAAAAAweppeAAAAAAAAjJ6mFwAAAAAAAKOn6QUAAAAAAMDoaXoBAAAAAAAweoM2varqzKq6rqoOVNXzN1j/lKq6ej69s6oeOmQ9ALBTMg2AKZBnAEyFTANgI4M1varq2CSvSHJWktOTPLmqTl+32QeSfH13PyTJTyQ5f6h6AGCnZBoAUyDPAJgKmQbAZoY80+uRSQ509/Xd/dkkFyc5e+0G3f3O7v74fPbyJCcPWA8A7JRMA2AK5BkAUyHTANjQkE2vk5LcuGb+4HzZZr4nye9ttKKqzq2qK6vqyltuuWWBJQLAlsg0AKZgYXmWyDQAlsp7NAA2NGTTqzZY1htuWPXYzMLneRut7+7zu3tfd+878cQTF1giAGyJTANgChaWZ4lMA2CpvEcDYEPHDbjvg0lOWTN/cpKb1m9UVQ9J8uokZ3X3RwesBwB2SqYBMAXyDICpkGkAbGjIM72uSHJaVd2/qo5Pck6SS9ZuUFWnJnl9ku/u7vcPWAsA7IZMA2AK5BkAUyHTANjQYGd6dfdtVfWcJJclOTbJBd19TVWdN1+/P8mPJblXkldWVZLc1t37hqoJAHZCpgEwBfIMgKmQaQBsZsjLG6a7L01y6bpl+9fcflaSZw1ZAwAsgkwDYArkGQBTIdMA2MiQlzcEAAAAAACAo0LTCwAAAAAAgNHT9AIAAAAAAGD0NL0AAAAAAAAYPU0vAAAAAAAARk/TCwAAAAAAgNHT9AIAAAAAAGD0NL0AAAAAAAAYPU0vAAAAAAAARk/TCwAAAAAAgNHT9AIAAAAAAGD0NL0AAAAAAAAYPU0vAAAAAAAARk/TCwAAAAAAgNHT9AIAAAAAAGD0NL0AAAAAAAAYPU0vAAAAAAAARk/TCwAAAAAAgNHT9AIAAAAAAGD0NL0AAAAAAAAYPU0vAAAAAAAARk/TCwAAAAAAgNHT9AIAAAAAAGD0Bm16VdWZVXVdVR2oqudvsL6q6uXz9VdX1cOHrAcAdkqmATAF8gyAqZBpAGxksKZXVR2b5BVJzkpyepInV9Xp6zY7K8lp8+ncJL80VD0AsFMyDYApkGcATIVMA2AzQ57p9cgkB7r7+u7+bJKLk5y9bpuzk7ymZy5Pcveq+vIBawKAnZBpAEyBPANgKmQaABs6bsB9n5TkxjXzB5M8agvbnJTkI2s3qqpzM/tGRpJ8qqquW2ypo3JCkluXXcRO/GbVsktYZaMd17xm2QWstPGOa5If+d5d7+J+CyhjVci0YYz2GJFphzXacZVphzXacV1AniXTybSF5Vki09YY7fGRyLQjGO/YyrTDGe24yrTb8R5tGKM9PuTZYY12XJPItM2NelyH/NxxyKbXRq80vYNt0t3nJzl/EUWNXVVd2d37ll0Hi2Vcp8m4TopMG4BjZJqM6zQZ18lYWJ4lMu0Qx8d0GdtpMq6T4T3aABwf02Rcp8m4bm7IyxseTHLKmvmTk9y0g20AYNlkGgBTIM8AmAqZBsCGhmx6XZHktKq6f1Udn+ScJJes2+aSJE+rmUcn+UR3f9FlMwBgyWQaAFMgzwCYCpkGwIYGu7xhd99WVc9JclmSY5Nc0N3XVNV58/X7k1ya5AlJDiT5TJJnDlXPhDjdepqM6zQZ14mQaYNxjEyTcZ0m4zoB8mwwjo/pMrbTZFwnQKYNxvExTcZ1mozrJqp7w8uzAwAAAAAAwGgMeXlDAAAAAAAAOCo0vQAAAAAAABg9TS8AAAAAAABGT9PrKKiqrqpfWzN/XFXdUlVv2uZ+PlhVJ+x2G3bOWE6HsYTtc9xMh7GcFuMJ2+e4mQ5jOS3GE7bPcTMdxnI6jOVyaXodHZ9O8jVVdaf5/Dck+fAS62HnjOV0GEvYPsfNdBjLaTGesH2Om+kwltNiPGH7HDfTYSynw1gukabX0fN7SZ44v/3kJK89tKKq7llVb6iqq6vq8qp6yHz5varqLVX17qp6VZJac5+nVtUfVtV7qupVVXXsVoqoqqfNH+eP13ab2ZaVHcuqurCq9lfV/6yq91fVNy3qSU/U6Mayqs5Y8xhXV9Vpi/lTwJat7HHDtq3sWMqzHRndeMo0VsDKHjds28qOpUzbkdGNp0xjBazsccO2rexYyrRtG91YTibPuts08JTkU0kekuR1Se6Y5D1JHpPkTfP1v5Dkx+e3H5fkPfPbL0/yY/PbT0zSSU5I8tVJ3pjkDvN1r0zytPntDyY5YZM6zkhy3aH1Se657L/N2KZVH8skFyZ5c2YN7dOSHExyx2X/3VZxGutYzut6ynyb45Pcadl/S9PemVb9uDFNZyw3ew1c9t9tVaexjmdkmmmJ06ofN6bpjOVmr4HL/rut6jTW8YxMMy1xWvXjxjSdsdzsNXDZf7dVnMY6lplInh0XjoruvrqqviKzru6l61Z/XZJvnW/3+/OO7t2S/OMkT5ov/92q+vh8+8cneUSSK6oqSe6U5OYtlPG4JK/r7lvn+/zYrp7UHjWCsfyt7v5Ckj+rquuTPDizF1bWGelYvivJj1TVyUle391/ts2nDbsyguOGLRrBWMqzbRjpeMo0lmoExw1bNIKxlGnbMNLxlGks1QiOG7ZoBGMp07ZopGM5iTzT9Dq6Lknys5l1de+1ZnltsG2v+3etSnJRd//wNh+/Ntkf27fKY7l+uTE/vFGNZXf/RlX9QWbf9risqp7V3b+/zceE3Vrl44btWeWxlGfbN6rxlGmsiFU+btieVR5LmbZ9oxpPmcaKWOXjhu1Z5bGUadszqrGcSp75Ta+j64IkL+7u965b/o4kT0mSqnpMklu7+5Prlp+V5B7z7d+a5Nuq6t7zdfesqvtt4fHfmuQ7qupeh+63q2ezt63yWH57VR1TVQ9M8oDMTmFlc6May6p6QJLru/vlmQXnQ7b5fGERVvm4YXtWeSzl2faNajxlGitilY8btmeVx1Kmbd+oxlOmsSJW+bhhe1Z5LGXa9oxqLKeSZ870Ooq6+2CSl22w6oVJfrWqrk7ymSRPny9/UZLXVtUfJXl7khvm+7m2qn40yVuq6pgkn0vy7CQfOsLjX1NVP5Xk7VX1+STvTvKM3T6vvWjFx/K6+WPcJ8l53f3XO32ee8HYxrKqvjPJU6vqc0n+PMmLd/TEYRdW/LhhG1Z8LOXZNo1tPGUaq2DFjxu2YcXHUqZt09jGU6axClb8uGEbVnwsZdo2jG0sp5Jn1e0MRJiKqrowsx9EfN2ya2F3jCWwl3kNnBbjCexlXgOnxXgCe5nXwOmY+li6vCEAAAAAAACj50yvCZpfo/OtG6x6fHd/9GjXw84Zy+kwlrB9jpvpMJbTYjxh+xw302Esp8V4wvY5bqbDWE6Hsbw9TS8AAAAAAABGz+UNAQAAAAAAGD1NLwAAAAAAAEZP0wsAAAAAAIDR0/QCAAAAAABg9DS9AAAAAAAAGD1NLwAAAAAAAEZP0wsAAAAAAIDR0/QCAAAAAABg9AZrelXVBVV1c1X9ySbrq6peXlUHqurqqnr4ULUAwG7INACmQqYBMAXyDIDNDHmm14VJzjzM+rOSnDafzk3ySwPWAgC7cWFkGgDTcGFkGgDjd2HkGQAbGKzp1d3vSPKxw2xydpLX9MzlSe5eVV8+VD0AsFMyDYCpkGkATIE8A2Azxy3xsU9KcuOa+YPzZR9Zv2FVnZvZtzJy5zvf+REPfvCDj0qBAOzcVVdddWt3n7jsOo4SmQYwYTJt+Ey7/rprdnxfducBDzpj2SUAR9EeyrSlvUeTacshz2BvOVyeLbPpVRss64027O7zk5yfJPv27esrr7xyyLoAWICq+tCyaziKZBrAhMm04TPtnMf6oGpZLn6b/xeBvWQPZdrS3qPJtOWQZ7C3HC7PhvxNryM5mOSUNfMnJ7lpSbUAwG7INACmQqYBMAXyDGCPWmbT65IkT6uZRyf5RHd/0SnGADACMg2AqZBpAEyBPAPYowa7vGFVvTbJY5KcUFUHk/x4kjskSXfvT3JpkickOZDkM0meOVQtALAbMg2AqZBpAEyBPANgM4M1vbr7yUdY30mePdTjA8CiyDQApkKmAbv1kv03L7uEPesF59172SWsDHkGwGaWeXlDAAAAAAAAWIjBzvQCAIZ1zmPPWHYJe9bFb7tm2SUAAAAAsI6mFwAAAAAAsKe4ZO/yDHnJXk0vAAAAYOFuePq7l13CnnXqRQ9bdgkAAEvhN70AAAAAAAAYPU0vAAAAAAAARk/TCwAAAAAAgNHT9AIAAAAAAGD0NL0AAAAAAAAYPU0vAAAAAAAARk/TCwAAAAAAgNHT9AIAAAAAAGD0NL0AAAAAAAAYPU0vAAAAAAAARk/TCwAAAAAAgNHT9AIAAAAAAGD0NL0AAAAAAAAYPU0vAAAAAAAARk/TCwAAAAAAgNHT9AIAAAAAAGD0NL0AAAAAAAAYveOWXcAynPPYM5Zdwp508duuWXYJAAAAAADARDnTCwAAAAAAgNEbtOlVVWdW1XVVdaCqnr/B+rtV1Rur6o+r6pqqeuaQ9QDATsk0AKZAngEwFTINgI0M1vSqqmOTvCLJWUlOT/Lkqjp93WbPTnJtdz80yWOS/FxVHT9UTQCwEzINgCmQZwBMhUwDYDNDnun1yCQHuvv67v5skouTnL1um05yl6qqJF+W5GNJbhuwJgDYCZkGwBTIMwCmQqYBsKEhm14nJblxzfzB+bK1fjHJVye5Kcl7k/xAd39h/Y6q6tyqurKqrrzllluGqhcANiPTAJiCheVZItMAWCrv0QDY0JBNr9pgWa+b/8Yk70ly3yR/L8kvVtVdv+hO3ed3977u3nfiiScuuk4AOBKZBsAULCzPEpkGwFJ5jwbAhoZseh1Mcsqa+ZMz+2bFWs9M8vqeOZDkA0kePGBNALATMg2AKZBnAEyFTANgQ8cNuO8rkpxWVfdP8uEk5yT5rnXb3JDk8Un+Z1XdJ8mDklw/YE0AsBMyDdi1l+y/edkl7EkvOO/eyy5hlcgzAKZCpgGwocGaXt19W1U9J8llSY5NckF3X1NV583X70/yE0kurKr3ZnZa8vO6+9ahagKAnZBpAEyBPANgKmQaAJsZ8kyvdPelSS5dt2z/mts3JfmnQ9YAAIsg0wCYAnkGwFTINAA2MuRvegEAAAAAAMBRoekFAAAAAADA6Gl6AQAAAAAAMHqaXgAAAAAAAIyephcAAAAAAACjp+kFAAAAAADA6Gl6AQAAAAAAMHqaXgAAAAAAAIyephcAAAAAAACjp+kFAAAAAADA6Gl6AQAAAAAAMHqaXgAAAAAAAIyephcAAAAAAACjp+kFAAAAAADA6Gl6AQAAAAAAMHqaXgAAAAAAAIyephcAAAAAAACjp+kFAAAAAADA6Gl6AQAAAAAAMHrHLbsAAAAAAABYVTc8/d3LLmHPOvWihy27BEbGmV4AAAAAAACMnqYXAAAAAAAAo+fyhsBKe8n+m5ddwp71gvPuvewSAAAAAAC2bNAzvarqzKq6rqoOVNXzN9nmMVX1nqq6pqrePmQ9ALBTMg2AKZBnAEyFTANgI4Od6VVVxyZ5RZJvSHIwyRVVdUl3X7tmm7sneWWSM7v7hqpyWgEAK0emATAF8gyAqZBpAGxmyDO9HpnkQHdf392fTXJxkrPXbfNdSV7f3TckSXe7jhkAq0imATAF8gyAqZBpAGxoyKbXSUluXDN/cL5sra9Kco+q+h9VdVVVPW2jHVXVuVV1ZVVdecsttwxULgBsSqYBMAULy7NEpgGwVN6jAbChIZtetcGyXjd/XJJHJHlikm9M8v9W1Vd90Z26z+/ufd2978QTT1x8pQBweDINgClYWJ4lMg2ApfIeDYANDfabXpl9w+KUNfMnJ7lpg21u7e5PJ/l0Vb0jyUOTvH/AugBgu2QaAFMgzwCYCpkGwIaGPNPriiSnVdX9q+r4JOckuWTdNv81yT+qquOq6kuTPCrJ+wasCQB2QqYBMAXyDICpkGkAbGiwM726+7aqek6Sy5Icm+SC7r6mqs6br9/f3e+rqjcnuTrJF5K8urv/ZKiaAGAnZBoAUyDPAJgKmQbAZoa8vGG6+9Ikl65btn/d/M8k+Zkh6wCA3ZJpAEyBPANgKmQaABs5bNOrqv7t4dZ3988vthwAGIZMA2AK5BkAUyHTABjCkc70ustRqQIAhifTAJgCeQbAVMg0ABbusE2v7n7R0SoEAIYk0wCYAnkGwFTINACGcKTLG778cOu7+/sXWw4ADEOmATAF8gyAqZBpAAzhSJc3vOqoVAEAw5NpAEyBPANgKmQaAAt3pMsbXnS0CgGAIck0xuSGp7972SXsSade9LBllwBHJM8AmAqZBsAQjnSmV5Kkqk5M8rwkpye546Hl3f24geoCgEHINACmQJ4BMBUyDYBFOmaL2/3nJO9Lcv8kL0rywSRXDFQTAAxJpgEwBfIMgKmQaQAszFabXvfq7l9J8rnufnt3/4skjx6wLgAYikwDYArkGQBTIdMAWJgtXd4wyefm/36kqp6Y5KYkJw9TEgAMSqYBMAXyDICpkGkALMxWm14/WVV3S/KDSX4hyV2T/JvBqgKA4cg0AKZAngEwFTINgIXZUtOru980v/mJJI8drhwAGJZMA2AK5BkAUyHTAFikLf2mV1VdVFV3XzN/j6q6YLCqAGAgMg2AKZBnAEyFTANgkbbU9ErykO7+i0Mz3f3xJA8bpCIAGJZMA2AK5BkAUyHTAFiYrTa9jqmqexyaqap7Zuu/BwYAq0SmATAF8gyAqZBpACzMVgPk55K8s6pel6STfEeSnxqsKgAYjkwDYArkGQBTIdMAWJgtNb26+zVVdWWSxyWpJE/q7msHrQwABiDTAJgCeQbAVMg0ABZpq5c3TJJ7Jvl0d/9Ckluq6v4D1QQAQ5NpAEyBPANgKmQaAAuxpaZXVf14kucl+eH5ojsk+fWhigKAocg0AKZAngEwFTINgEXa6ple35Lknyf5dJJ0901J7jJUUQAwIJkGwBTIMwCmQqYBsDBbbXp9trs7sx+TTFXdebiSAGBQMg2AKZBnAEyFTANgYY7Y9KqqSvKmqnpVkrtX1b9M8t+T/PLQxQHAIsk0AKZAngEwFTINgEU77kgbdHdX1Tdndm3dTyZ5UJIf6+7/NnBtALBQMg2AKZBnAEyFTANg0bZ6ecN3JfmL7v533f1DWw2eqjqzqq6rqgNV9fzDbPe1VfX5qvq2LdYDADsl0wCYAnkGwFTINAAW5ohnes09Nsm/qqoPZf6jkknS3Q/Z7A5VdWySVyT5hiQHk1xRVZd097UbbPfTSS7bZu0AsBMyDYApkGcATIVMA2Bhttr0OmsH+35kkgPdfX2SVNXFSc5Ocu267b4vye8k+dodPAYAbJdMA2AK5BkAUyHTAFiYLTW9uvtDO9j3SUluXDN/MMmj1m5QVScl+ZYkj8thwqeqzk1ybpKceuqpOygFAGZkGgBTsOw8m28r0wDYtWVnmjwDmJat/qbXTtQGy3rd/EuTPK+7P3+4HXX3+d29r7v3nXjiiYuqDwC2SqYBMAULy7NEpgGwVN6jAbChrV7ecCcOJjllzfzJSW5at82+JBdXVZKckOQJVXVbd79hwLoAYLtkGgBTIM8AmAqZBsCGhmx6XZHktKq6f5IPJzknyXet3aC773/odlVdmORNggeAFSTTAJgCeQbAVMg0ADY0WNOru2+rquckuSzJsUku6O5rquq8+fr9Qz02ACySTANgCuQZAFMh0wDYzJBneqW7L01y6bplG4ZOdz9jyFoAYDdkGgBTIM8AmAqZBsBGjll2AQAAAAAAALBbml4AAAAAAACM3qCXN4Sj6Yanv3vZJexJp170sGWXAAAAAAAAzvQCAAAAAABg/DS9AAAAAAAAGD1NLwAAAAAAAEZP0wsAAAAAAIDR0/QCAAAAAABg9DS9AAAAAAAAGD1NLwAAAAAAAEZP0wsAAAAAAIDR0/QCAAAAAABg9DS9AAAAAAAAGD1NLwAAAAAAAEZP0wsAAAAAAIDR0/QCAAAAAABg9DS9AAAAAAAAGD1NLwAAAAAAAEZP0wsAAAAAAIDR0/QCAAAAAABg9DS9AAAAAAAAGD1NLwAAAAAAAEZP0wsAAAAAAIDRG7TpVVVnVtV1VXWgqp6/wfqnVNXV8+mdVfXQIesBgJ2SaQBMgTwDYCpkGgAbGazpVVXHJnlFkrOSnJ7kyVV1+rrNPpDk67v7IUl+Isn5Q9UDADsl0wCYAnkGwFTINAA2M+SZXo9McqC7r+/uzya5OMnZazfo7nd298fns5cnOXnAegBgp2QaAFMgzwCYCpkGwIaGbHqdlOTGNfMH58s28z1Jfm+jFVV1blVdWVVX3nLLLQssEQC2RKYBMAULy7NEpgGwVN6jAbChIZtetcGy3nDDqsdmFj7P22h9d5/f3fu6e9+JJ564wBIBYEtkGgBTsLA8S2QaAEvlPRoAGzpuwH0fTHLKmvmTk9y0fqOqekiSVyc5q7s/OmA9ALBTMg2AKZBnAEyFTANgQ0Oe6XVFktOq6v5VdXySc5JcsnaDqjo1yeuTfHd3v3/AWgBgN2QaAFMgzwCYCpkGwIYGO9Oru2+rquckuSzJsUku6O5rquq8+fr9SX4syb2SvLKqkuS27t43VE0AsBMyDYApkGcATIVMA2AzQ17eMN19aZJL1y3bv+b2s5I8a8gaAGARZBoAUyDPAJgKmQbARoa8vCEAAAAAAAAcFZpeAAAAAAAAjJ6mFwAAAAAAAKOn6QUAAAAAAMDoaXoBAAAAAAAweppeAAAAAAAAjJ6mFwAAAAAAAKOn6QUAAAAAAMDoaXoBAAAAAAAweppeAAAAAAAAjJ6mFwAAAAAAAKOn6QUAAAAAAMDoaXoBAAAAAAAweppeAAAAAAAAjJ6mFwAAAAAAAKOn6QUAAAAAAMDoaXoBAAAAAAAweppeAAAAAAAAjJ6mFwAAAAAAAKOn6QUAAAAAAMDoaXoBAAAAAAAweppeAAAAAAAAjJ6mFwAAAAAAAKM3aNOrqs6squuq6kBVPX+D9VVVL5+vv7qqHj5kPQCwUzINgCmQZwBMhUwDYCODNb2q6tgkr0hyVpLTkzy5qk5ft9lZSU6bT+cm+aWh6gGAnZJpAEyBPANgKmQaAJsZ8kyvRyY50N3Xd/dnk1yc5Ox125yd5DU9c3mSu1fVlw9YEwDshEwDYArkGQBTIdMA2NBxA+77pCQ3rpk/mORRW9jmpCQfWbtRVZ2b2TcykuRTVXXdYksdlROS3LrsInbiN6uWXcIqG+245jXLLmCljXdck/zI9+56F/dbQBmrQqYNY7THiEw7rNGOq0w7rNGO6wLyLJlOpi0szxKZtsZoj49Eph3BeMdWph3OaMdVpt2O92jDGO3xIc8Oa7TjmkSmbW7U4zrk545DNr02eqXpHWyT7j4/yfmLKGrsqurK7t637DpYLOM6TcZ1UmTaABwj02Rcp8m4TsbC8iyRaYc4PqbL2E6TcZ0M79EG4PiYJuM6TcZ1c0Ne3vBgklPWzJ+c5KYdbAMAyybTAJgCeQbAVMg0ADY0ZNPriiSnVdX9q+r4JOckuWTdNpckeVrNPDrJJ7r7iy6bAQBLJtMAmAJ5BsBUyDQANjTY5Q27+7aqek6Sy5Icm+SC7r6mqs6br9+f5NIkT0hyIMlnkjxzqHomxOnW02Rcp8m4ToRMG4xjZJqM6zQZ1wmQZ4NxfEyXsZ0m4zoBMm0wjo9pMq7TZFw3Ud0bXp4dAAAAAAAARmPIyxsCAAAAAADAUaHpBQAAAAAAwOhpegEAAAAAADB6ml5HQVV1Vf3amvnjquqWqnrTNvfzwao6YbfbsHPGcjqMJWyf42Y6jOW0GE/YPsfNdBjLaTGesH2Om+kwltNhLJdL0+vo+HSSr6mqO83nvyHJh5dYDztnLKfDWML2OW6mw1hOi/GE7XPcTIexnBbjCdvnuJkOYzkdxnKJNL2Ont9L8sT57Scnee2hFVV1z6p6Q1VdXVWXV9VD5svvVVVvqap3V9WrktSa+zy1qv6wqt5TVa+qqmO3UkRVPW3+OH+8ttvMtqzsWFbVhVW1v6r+Z1W9v6q+aVFPeqJGN5ZVdcaax7i6qk5bzJ8Ctmxljxu2bWXHUp7tyOjGU6axAlb2uGHbVnYsZdqOjG48ZRorYGWPG7ZtZcdSpm3b6MZyMnnW3aaBpySfSvKQJK9Lcsck70nymCRvmq//hSQ/Pr/9uCTvmd9+eZIfm99+YpJOckKSr07yxiR3mK97ZZKnzW9/MMkJm9RxRpLrDq1Pcs9l/23GNq36WCa5MMmbM2ton5bkYJI7LvvvtorTWMdyXtdT5tscn+ROy/5bmvbOtOrHjWk6Y7nZa+Cy/26rOo11PCPTTEucVv24MU1nLDd7DVz2321Vp7GOZ2SaaYnTqh83pumM5Wavgcv+u63iNNaxzETy7LhwVHT31VX1FZl1dS9dt/rrknzrfLvfn3d075bkHyd50nz571bVx+fbPz7JI5JcUVVJcqckN2+hjMcleV133zrf58d29aT2qBGM5W919xeS/FlVXZ/kwZm9sLLOSMfyXUl+pKpOTvL67v6zbT5t2JURHDds0QjGUp5tw0jHU6axVCM4btiiEYylTNuGkY6nTGOpRnDcsEUjGEuZtkUjHctJ5Jmm19F1SZKfzayre681y2uDbXvdv2tVkou6+4e3+fi1yf7YvlUey/XLjfnhjWosu/s3quoPMvu2x2VV9azu/v1tPibs1iofN2zPKo+lPNu+UY2nTGNFrPJxw/as8ljKtO0b1XjKNFbEKh83bM8qj6VM255RjeVU8sxveh1dFyR5cXe/d93ydyR5SpJU1WOS3Nrdn1y3/Kwk95hv/9Yk31ZV956vu2dV3W8Lj//WJN9RVfc6dL9dPZu9bZXH8tur6piqemCSB2R2CiubG9VYVtUDklzf3S/PLDgfss3nC4uwyscN27PKYynPtm9U4ynTWBGrfNywPas8ljJt+0Y1njKNFbHKxw3bs8pjKdO2Z1RjOZU8c6bXUdTdB5O8bINVL0zyq1V1dZLPJHn6fPmLkry2qv4oyduT3DDfz7VV9aNJ3lJVxyT5XJJnJ/nQER7/mqr6qSRvr6rPJ3l3kmfs9nntRSs+ltfNH+M+Sc7r7r/e6fPcC8Y2llX1nUmeWlWfS/LnSV68oycOu7Dixw3bsOJjKc+2aWzjKdNYBSt+3LANKz6WMm2bxjaeMo1VsOLHDduw4mMp07ZhbGM5lTyrbmcgwlRU1YWZ/SDi65ZdC7tjLIG9zGvgtBhPYC/zGjgtxhPYy7wGTsfUx9LlDQEAAAAAABg9Z3pN0PwanW/dYNXju/ujR7seds5YToexhO1z3EyHsZwW4wnb57iZDmM5LcYTts9xMx3GcjqM5e1pegEAAAAAADB6Lm8IAAAAAADA6Gl6AQAAAAAAMHqaXgAAAAAAAIyephcAAAAAAACjp+kFAAAAAADA6Gl6AQAAAAAAMHqaXgAAAAAAAIyephcAAAAAAACjN1jTq6ouqKqbq+pPNllfVfXyqjpQVVdX1cOHqgUAdkOmATAVMg2AKZBnAGxmyDO9Lkxy5mHWn5XktPl0bpJfGrAWANiNCyPTAJiGCyPTABi/CyPPANjAYE2v7n5Hko8dZpOzk7ymZy5Pcveq+vKh6gGAnZJpAEyFTANgCuQZAJs5bomPfVKSG9fMH5wv+8j6Davq3My+lZE73/nOj3jwgx98VAoEYOeuuuqqW7v7xGXXcZTINIAJk2kyDWAq9lCmyTOACTtcni2z6VUbLOuNNuzu85OcnyT79u3rK6+8csi6AFiAqvrQsms4imQawITJNJkGMBV7KNPkGcCEHS7PhvxNryM5mOSUNfMnJ7lpSbUAwG7INACmQqYBMAXyDGCPWmbT65IkT6uZRyf5RHd/0SnGADACMg2AqZBpAEyBPAPYowa7vGFVvTbJY5KcUFUHk/x4kjskSXfvT3JpkickOZDkM0meOVQtALAbMg2AqZBpAEyBPANgM4M1vbr7yUdY30mePdTjA8CiyDQApkKmATAF8gyAzSzz8oYAAAAAAACwEJpeAAAAAAAAjJ6mFwAAAAAAAKOn6QUAAAAAAMDoaXoBAAAAAAAweppeAAAAAAAAjJ6mFwAAAAAAAKOn6QUAAAAAAMDoaXoBAAAAAAAweppeAAAAAAAAjJ6mFwAAAAAAAKN33LILAAAAAACYgnMee8ayS9iTLn7bNcsuAVgRzvQCAAAAAABg9JzpBQAAAAAA7Ckv2X/zskvYs15w3r0H27czvQAAAAAAABg9TS8AAAAAAABGT9MLAAAAAACA0dP0AgAAAAAAYPQ0vQAAAAAAABg9TS8AAAAAAABGT9MLAAAAAACA0Ttu2QUAAACwt53z2DOWXcKedfHbrll2CYzMS/bfvOwS9qwXnHfvZZcAACtP0wsAAABYuBue/u5ll7BnnXrRw5ZdAgDAUgx6ecOqOrOqrquqA1X1/A3W362q3lhVf1xV11TVM4esBwB2SqYBMAXyDICpkGkAbGSwpldVHZvkFUnOSnJ6kidX1enrNnt2kmu7+6FJHpPk56rq+KFqAoCdkGkATIE8A2AqZBoAmxnyTK9HJjnQ3dd392eTXJzk7HXbdJK7VFUl+bIkH0ty24A1AcBOyDQApkCeATAVMg2ADQ3Z9DopyY1r5g/Ol631i0m+OslNSd6b5Ae6+wvrd1RV51bVlVV15S233DJUvQCwGZkGwBQsLM8SmQbAUnmPBsCGhmx61QbLet38NyZ5T5L7Jvl7SX6xqu76RXfqPr+793X3vhNPPHHRdQLAkcg0AKZgYXmWyDQAlsp7NAA2NGTT62CSU9bMn5zZNyvWemaS1/fMgSQfSPLgAWsCgJ2QaQBMgTwDYCpkGgAbGrLpdUWS06rq/vMfiTwnySXrtrkhyeOTpKruk+RBSa4fsCYA2AmZBsAUyDMApkKmAbCh44bacXffVlXPSXJZkmOTXNDd11TVefP1+5P8RJILq+q9mZ2W/LzuvnWomgBgJ2QaAFMgzwCYCpkGwGYGa3olSXdfmuTSdcv2r7l9U5J/OmQNALAIMg2AKZBnAEyFTANgI0Ne3hAAAAAAAACOCk0vAAAAAAAARm/QyxsCAAAAAMCY3fD0dy+7hD3r1IsetuwSGBlnegEAAAAAADB6ml4AAAAAAACMnqYXAAAAAAAAo6fpBQAAAAAAwOhpegEAAAAAADB6ml4AAAAAAACMnqYXAAAAAAAAo6fpBQAAAAAAwOhpegEAAAAAADB6ml4AAAAAAACMnqYXAAAAAAAAo6fpBQAAAAAAwOhpegEAAAAAADB6xy27AAAA2Atesv/mZZewJ73gvHsvuwQAAACOEmd6AQAAAAAAMHqaXgAAAAAAAIyephcAAAAAAACjp+kFAAAAAADA6Gl6AQAAAAAAMHqaXgAAAAAAAIzecUPuvKrOTPKyJMcmeXV3/4cNtnlMkpcmuUOSW7v764esCRiXl+y/edkl7FkvOO/eyy5hpcg0AKZAngEwFTINgI0M1vSqqmOTvCLJNyQ5mOSKqrqku69ds83dk7wyyZndfUNV+YQVgJUj0wCYAnkGwFTINAA2c8TLG1bVfarqV6rq9+bzp1fV92xh349McqC7r+/uzya5OMnZ67b5riSv7+4bkqS7ndIBwGBkGgBTscNMk2cArByZBsAibeVMrwuT/GqSH5nPvz/Jbyb5lSPc76QkN66ZP5jkUeu2+aokd6iq/5HkLkle1t2vWb+jqjo3yblJcuqpp26hZADY0IWRaYzADU9/97JL2JNOvehhyy4BtuPCbD/TFpZniUwDYGEuzBIzTZ4BTMtWml4ndPdvVdUPJ0l331ZVn9/C/WqDZb3B4z8iyeOT3CnJu6rq8u5+/+3u1H1+kvOTZN++fev3AQBbNalMO+exZ+zm7uzCxW+7ZtklAOwk0xaWZ/PH9D4NgEVYaqbJM4Bp2UrT69NVda/Mg6OqHp3kE1u438Ekp6yZPznJTRtsc2t3f3r+OO9I8tDMvtEBAIsm0wCYip1kmjwDYBXJNAAW5oi/6ZXk3ya5JMkDq+p/J3lNku/bwv2uSHJaVd2/qo5Pcs58P2v91yT/qKqOq6ovzew05PdtuXoA2B6ZBsBU7CTT5BkAq0imAbAwhz3Tq6qOTfL18+lBmZ06fF13f+5IO56fivycJJclOTbJBd19TVWdN1+/v7vfV1VvTnJ1ki8keXV3/8munhEAbECmATAVO800eQbAqpFpACzaYZte3f35qjq7u/9Tkm3/eEV3X5rk0nXL9q+b/5kkP7PdfQPAdsg0AKZiN5kmzwBYJTINgEXbym96/e+q+sUkv5nk04cWdvcfDVYVAAxDpgEwFTINgKmQaQAszFaaXv9g/u+L1yzrJI9bfDkAMCiZBsBUyDQApkKmAbAwR2x6dfdjj0YhADA0mQbAVMg0AKZCpgGwSMccaYOqultV/XxVXTmffq6q7nY0igOARZJpAEyFTANgKmQaAIt0xKZXkguS/GWS75hPn0zyq0MWBQADkWkATIVMA2AqZBoAC7OV3/R6YHd/65r5F1XVewaqBwCGJNMAmAqZBsBUyDQAFmYrZ3r9VVV93aGZqvqHSf5quJIAYDAyDYCpkGkATIVMA2BhtnKm1/cmuWjNtXQ/nuQZg1UEAMORaQBMhUwDYCpkGgALc8SmV3e/J8lDq+qu8/lPDl0UAAxBpgEwFTINgKmQaQAs0hEvb1hVL6mqu3f3J7v7k1V1j6r6yaNRHAAskkwDYCpkGgBTIdMAWKStXN7wrO5+waGZ7v54VT0hyY8OV9awznnsGcsuYU+6+G3XLLsEgMllGgB7lkwDYCpkGgALc8QzvZIcW1Vfcmimqu6U5EsOsz0ArCqZBsBUyDQApkKmAbAwWznT69eTvLWqfjVJJ/kXSS4atCrYgRue/u5ll7AnnXrRw5ZdAmyHTANgKmQaAFMh0wBYmCM2vbr7P1bV1Un+SZJK8hPdfdnglQHAgsk0AKZCpgEwFTINgEU6YtOrqu6c5C3d/eaqelCSB1XVHbr7c8OXBwCLI9MAmAqZBsBUyDQAFmkrv+n1jiR3rKqTkvz3JM9McuGQRQHAQGQaAFMh0wCYCpkGwMJspelV3f2ZJE9K8gvd/S1JTh+2LAAYhEwDYCpkGgBTIdMAWJgtNb2q6u8neUqS350vO+JlEQFgBck0AKZCpgEwFTINgIXZStPrB5L8cJL/0t3XVNUDkrxt2LIAYBAyDYCpkGkATIVMA2Bhjvitie5+R2bX1k1V/f+6+/ok3z90YQCwaDINgKmQaQBMhUwDYJG2cqbXWpcOUgUAHH0yDYCpkGkATIVMA2BXttv0qkGqAICjT6YBMBUyDYCpkGkA7Mp2m16/PEgVAHD0yTQApkKmATAVMg2AXdlW06u7X5kkVfVlW9m+qs6squuq6kBVPf8w231tVX2+qr5tO/UAwE7JNACmYjuZJs8AWGUyDYDd2u6ZXodce6QNqurYJK9IclaS05M8uapO32S7n05y2Q5rAYDdkGkATMVhM02eATAiMg2AHTlusxVV9W83W5VkK9+Kf2SSA919/Xx/Fyc5O18cWt+X5HeSfO0W9gkA2ybTAJiKXWaaPANgZcg0AIZwuDO9XpLkHknusm76siPc75CTkty4Zv7gfNnfqqqTknxLkv2H21FVnVtVV1bVlbfccssWHhoAbkemATAVu8m0heXZfFuZBsBurESmyTOAadn0TK8kf5TkDd191foVVfWsLey7NljW6+ZfmuR53f35qo02n9+p+/wk5yfJvn371u8DAI5EpgEwFbvJtIXlWSLTANi1lcg0eQYwLYdren04yYeq6ge6+2Xr1u3bwr4PJjllzfzJSW7aYD8Xz4PnhCRPqKrbuvsNW9g/AGyVTANgKnaTafIMgFUi0wBYuMM1vU5Pcuck/6KqXpPbf4Pic1vY9xVJTquq+2cWYuck+a61G3T3/Q/drqoLk7xJ8AAwAJkGwFTsJtPkGQCrRKYBsHCHa3q9KsmbkzwgyVW5ffD0fPmmuvu2qnpOksuSHJvkgu6+pqrOm68/4jXiAWBBZBoAU7HjTJNnAKwYmQbAwm3a9Orulyd5eVX9Und/70523t2XJrl03bINQ6e7n7GTxwCAI5FpAEzFbjNNngGwKmQaAEM45kgb7PTDQQBYNTINgKmQaQBMhUwDYJGO2PQCAAAAAACAVafpBQAAAAAAwOhpegEAAAAAADB6ml4AAAAAAACMnqYXAAAAAAAAo6fpBQAAAAAAwOhpegEAAAAAADB6ml4AAAAAAACMnqYXAAAAAAAAo6fpBQAAAAAAwOhpegEAAAAAADB6ml4AAAAAAACMnqYXAAAAAAAAo6fpBQAAAAAAwOhpegEAAAAAADB6ml4AAAAAAACMnqYXAAAAAAAAo6fpBQAAAAAAwOhpegEAAAAAADB6ml4AAAAAAACMnqYXAAAAAAAAo6fpBQAAAAAAwOgN2vSqqjOr6rqqOlBVz99g/VOq6ur59M6qeuiQ9QDATsk0AKZAngEwFTINgI0M1vSqqmOTvCLJWUlOT/Lkqjp93WYfSPL13f2QJD+R5Pyh6gGAnZJpAEyBPANgKmQaAJsZ8kyvRyY50N3Xd/dnk1yc5Oy1G3T3O7v74/PZy5OcPGA9ALBTMg2AKZBnAEyFTANgQ0M2vU5KcuOa+YPzZZv5niS/t9GKqjq3qq6sqitvueWWBZYIAFsi0wCYgoXlWSLTAFgq79EA2NCQTa/aYFlvuGHVYzMLn+dttL67z+/ufd2978QTT1xgiQCwJTINgClYWJ4lMg2ApfIeDYANHTfgvg8mOWXN/MlJblq/UVU9JMmrk5zV3R8dsB4A2CmZBsAUyDMApkKmAbChIc/0uiLJaVV1/6o6Psk5SS5Zu0FVnZrk9Um+u7vfP2AtALAbMg2AKZBnAEyFTANgQ4Od6dXdt1XVc5JcluTYJBd09zVVdd58/f4kP5bkXkleWVVJclt37xuqJgDYCZkGwBTIMwCmQqYBsJkhL2+Y7r40yaXrlu1fc/tZSZ41ZA0AsAgyDYApkGcATIVMA2AjQ17eEAAAAAAAAI4KTS8AAAAAAABGT9MLAAAAAACA0dP0AgAAAAAAYPQ0vQAAAAAAABg9TS8AAAAAAABGT9MLAAAAAACA0dP0AgAAAAAAYPQ0vQAAAAAAABg9TS8AAAAAAABGT9MLAAAAAACA0dP0AgAAAAAAYPQ0vQAAAAAAABg9TS8AAAAAAABGT9MLAAAAAACA0dP0AgAAAAAAYPQ0vQAAAAAAABg9TS8AAAAAAABGT9MLAAAAAACA0dP0AgAAAAAAYPQ0vQAAAAAAABg9TS8AAAAAAABGT9MLAAAAAACA0Ru06VVVZ1bVdVV1oKqev8H6qqqXz9dfXVUPH7IeANgpmQbAFMgzAKZCpgGwkcGaXlV1bJJXJDkryelJnlxVp6/b7Kwkp82nc5P80lD1AMBOyTQApkCeATAVMg2AzQx5ptcjkxzo7uu7+7NJLk5y9rptzk7ymp65PMndq+rLB6wJAHZCpgEwBfIMgKmQaQBs6LgB931SkhvXzB9M8qgtbHNSko+s3aiqzs3sGxlJ8qmqum6xpY7KCUluXXYRO/GbVcsuYZWNdlzzmmUXsNLGO65JfuR7d72L+y2gjFUh04Yx2mNEph3WaMdVph3WaMd1AXmWTCfTFpZniUxbY7THRyLTjmC8YyvTDme04yrTbsd7tGGM9viQZ4c12nFNItM2N+pxHfJzxyGbXhu90vQOtkl3n5/k/EUUNXZVdWV371t2HSyWcZ0m4zopMm0AjpFpMq7TZFwnY2F5lsi0Qxwf02Vsp8m4Tob3aANwfEyTcZ0m47q5IS9veDDJKWvmT05y0w62AYBlk2kATIE8A2AqZBoAGxqy6XVFktOq6v5VdXySc5Jcsm6bS5I8rWYeneQT3f1Fl80AgCWTaQBMgTwDYCpkGgAbGuzyht19W1U9J8llSY5NckF3X1NV583X709yaZInJDmQ5DNJnjlUPRPidOtpMq7TZFwnQqYNxjEyTcZ1mozrBMizwTg+psvYTpNxnQCZNhjHxzQZ12kyrpuo7g0vzw4AAAAAAACjMeTlDQEAAAAAAOCo0PQCAAAAAABg9DS9AAAAAAAAGD1Nr6Ogqrqqfm3N/HFVdUtVvWmb+/lgVZ2w223YOWM5HcYSts9xMx3GclqMJ2yf42Y6jOW0GE/YPsfNdBjL6TCWy6XpdXR8OsnXVNWd5vPfkOTDS6yHnTOW02EsYfscN9NhLKfFeML2OW6mw1hOi/GE7XPcTIexnA5juUSaXkfP7yV54vz2k5O89tCKqrpnVb2hqq6uqsur6iHz5feqqrdU1bur6lVJas19nlpVf1hV76mqV1XVsVspoqqeNn+cP17bbWZbVnYsq+rCqtpfVf+zqt5fVd+0qCc9UaMby6o6Y81jXF1Vpy3mTwFbtrLHDdu2smMpz3ZkdOMp01gBK3vcsG0rO5YybUdGN54yjRWwsscN27ayYynTtm10YzmZPOtu08BTkk8leUiS1yW5Y5L3JHlMkjfN1/9Ckh+f335ckvfMb788yY/Nbz8xSSc5IclXJ3ljkjvM170yydPmtz+Y5IRN6jgjyXWH1ie557L/NmObVn0sk1yY5M2ZNbRPS3IwyR2X/XdbxWmsYzmv6ynzbY5Pcqdl/y1Ne2da9ePGNJ2x3Ow1cNl/t1WdxjqekWmmJU6rftyYpjOWm70GLvvvtqrTWMczMs20xGnVjxvTdMZys9fAZf/dVnEa61hmInl2XDgquvvqqvqKzLq6l65b/XVJvnW+3e/PO7p3S/KPkzxpvvx3q+rj8+0fn+QRSa6oqiS5U5Kbt1DG45K8rrtvne/zY7t6UnvUCMbyt7r7C0n+rKquT/LgzF5YWWekY/muJD9SVScneX13/9k2nzbsygiOG7ZoBGMpz7ZhpOMp01iqERw3bNEIxlKmbcNIx1OmsVQjOG7YohGMpUzbopGO5STyTNPr6Lokyc9m1tW915rltcG2ve7ftSrJRd39w9t8/Npkf2zfKo/l+uXG/PBGNZbd/RtV9QeZfdvjsqp6Vnf//jYfE3ZrlY8btmeVx1Kebd+oxlOmsSJW+bhhe1Z5LGXa9o1qPGUaK2KVjxu2Z5XHUqZtz6jGcip55je9jq4Lkry4u9+7bvk7kjwlSarqMUlu7e5Prlt+VpJ7zLd/a5Jvq6p7z9fds6rut4XHf2uS76iqex26366ezd62ymP57VV1TFU9MMkDMjuFlc2Naiyr6gFJru/ul2cWnA/Z5vOFRVjl44btWeWxlGfbN6rxlGmsiFU+btieVR5LmbZ9oxpPmcaKWOXjhu1Z5bGUadszqrGcSp450+so6u6DSV62waoXJvnVqro6yWeSPH2+/EVJXltVf5Tk7UlumO/n2qr60SRvqapjknwuybOTfOgIj39NVf1UkrdX1eeTvDvJM3b7vPaiFR/L6+aPcZ8k53X3X+/0ee4FYxvLqvrOJE+tqs8l+fMkL97RE4ddWPHjhm1Y8bGUZ9s0tvGUaayCFT9u2IYVH0uZtk1jG0+ZxipY8eOGbVjxsZRp2zC2sZxKnlW3MxBhKqrqwsx+EPF1y66F3TGWwF7mNXBajCewl3kNnBbjCexlXgOnY+pj6fKGAAAAAAAAjJ4zvSZofo3Ot26w6vHd/dGjXQ87Zyynw1jC9jlupsNYTovxhO1z3EyHsZwW4wnb57iZDmM5Hcby9jS9AAAAAAAAGD2XNwQAAAAAAGD0NL0AAAAAAAAYPU0vAAAAAAAARk/TCwAAAAAAgNH7/wDTlZSqdmVqHgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2160x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_c results:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Openness to change       0.35      0.83      0.50       474\n",
      "      Conservation       0.43      0.96      0.59       647\n",
      "  Self-enhancement       0.71      1.00      0.83      1119\n",
      "Self-transcendence       0.80      1.00      0.89      1268\n",
      "\n",
      "         micro avg       0.60      0.97      0.74      3508\n",
      "         macro avg       0.57      0.95      0.70      3508\n",
      "      weighted avg       0.64      0.97      0.76      3508\n",
      "       samples avg       0.60      0.98      0.72      3508\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Openness to change       0.81      0.35      0.49       474\n",
      "      Conservation       0.69      0.53      0.60       647\n",
      "  Self-enhancement       0.74      0.94      0.83      1119\n",
      "Self-transcendence       0.89      0.65      0.75      1268\n",
      "\n",
      "         micro avg       0.78      0.68      0.73      3508\n",
      "         macro avg       0.78      0.62      0.67      3508\n",
      "      weighted avg       0.79      0.68      0.71      3508\n",
      "       samples avg       0.81      0.73      0.72      3508\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Openness to change       0.61      0.63      0.62       474\n",
      "      Conservation       0.57      0.79      0.66       647\n",
      "  Self-enhancement       0.73      0.97      0.83      1119\n",
      "Self-transcendence       0.82      0.95      0.88      1268\n",
      "\n",
      "         micro avg       0.71      0.88      0.79      3508\n",
      "         macro avg       0.68      0.83      0.75      3508\n",
      "      weighted avg       0.72      0.88      0.79      3508\n",
      "       samples avg       0.73      0.91      0.77      3508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each model I plot the f1-score of each category for the test set using classification_report\n",
    "\n",
    "report_results_c = classification_report(targets_c, predictions_c, target_names=labels ,zero_division=1, output_dict=True)\n",
    "report_results_cp = classification_report(targets_cp, predictions_cp, target_names=labels ,zero_division=1, output_dict=True)\n",
    "report_results_cps = classification_report(targets_cps, predictions_cps, target_names=labels ,zero_division=1, output_dict=True)\n",
    "all_reports = [report_results_c, report_results_cp, report_results_cps]\n",
    "\n",
    "plot_colors = set_color(len(all_reports))\n",
    "\n",
    "# I plot the precision, recall and f1-score for each category for each model.\n",
    "fig, axs = plt.subplots(3, len(labels), figsize=(30, 10))\n",
    "\n",
    "for i, metric in enumerate(['precision', 'recall', 'f1-score']):\n",
    "    for j, label in enumerate(labels):\n",
    "        for k, report in enumerate(all_reports):\n",
    "            axs[i, j].bar(k, report[label][metric], color=plot_colors[k])\n",
    "            if k == 0 : axs[k, j].set_title(label)\n",
    "            axs[k, j].set_xticks([0, 1, 2])\n",
    "            axs[k, j].set_xticklabels(['Model_c', 'Model_cp', 'Model_cps'])\n",
    "            axs[k, j].set_ylim([0, 1])\n",
    "            axs[i, j].set_ylabel(metric)\n",
    "\n",
    "            \n",
    "plt.show()\n",
    "# i print model_c results\n",
    "print(\"Model_c results:\")\n",
    "print(classification_report(targets_c, predictions_c, target_names=labels ,zero_division=1))\n",
    "print(classification_report(targets_cp, predictions_cp, target_names=labels ,zero_division=1))\n",
    "print(classification_report(targets_cps, predictions_cps, target_names=labels ,zero_division=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
