{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "This Jupyter Notebook document is our implementation of Assignment 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas \n",
    "!pip install numpy\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data Loading and Splitting\n",
    "* **Download** the corpus.\n",
    "* **Encode** the corpus into a pandas.DataFrame object.\n",
    "* **Split** it in training, validation, and test sets.\n",
    "\n",
    "[Penn TreeBank corpus](https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data from Penn TreeBank corpus \n",
    "\n",
    "address = 'https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip'\n",
    "urllib.request.urlretrieve(address, 'dependency_treebank.zip')\n",
    "# Unzip the data\n",
    "with zipfile.ZipFile('dependency_treebank.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49219\n",
      "32432\n",
      "16148\n",
      "[['Pierre', 'NNP'], ['Vinken', 'NNP'], [',', ','], ['61', 'CD'], ['years', 'NNS'], ['old', 'JJ'], [',', ','], ['will', 'MD'], ['join', 'VB'], ['the', 'DT'], ['board', 'NN'], ['as', 'IN'], ['a', 'DT'], ['nonexecutive', 'JJ'], ['director', 'NN'], ['Nov.', 'NNP'], ['29', 'CD'], ['.', '.'], [], ['Mr.', 'NNP']]\n",
      "(49219, 2)\n",
      "(32432, 2)\n",
      "(16148, 2)\n",
      "        0    1\n",
      "0  Pierre  NNP\n",
      "1  Vinken  NNP\n",
      "2       ,    ,\n",
      "3      61   CD\n",
      "4   years  NNS\n",
      "              0    1\n",
      "0             A   DT\n",
      "1  House-Senate  NNP\n",
      "2    conference   NN\n",
      "3      approved  VBD\n",
      "4         major   JJ\n",
      "           0    1\n",
      "0  Intelogic  NNP\n",
      "1      Trace  NNP\n",
      "2       Inc.  NNP\n",
      "3          ,    ,\n",
      "4        San  NNP\n"
     ]
    }
   ],
   "source": [
    "# Encode the corpus in a dataframe object\n",
    "list_train = [] # documents 1-100\n",
    "list_test = [] # documents 101-150\n",
    "list_val = [] # documents 151-199\n",
    "for filename in os.listdir('dependency_treebank/'):\n",
    "    if filename.endswith('.dp'):\n",
    "        with open('dependency_treebank/' + filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if int(filename[4:8]) <= 100:\n",
    "                    list_train.append(line.split()[:-1])\n",
    "                elif int(filename[4:8]) <= 150:\n",
    "                    list_test.append(line.split()[:-1])\n",
    "                elif int(filename[4:8]) <= 199:\n",
    "                    list_val.append(line.split()[:-1])\n",
    "         \n",
    "print(len(list_train))\n",
    "print(len(list_test))\n",
    "print(len(list_val))\n",
    "\n",
    "print(list_train[0:20])\n",
    "\n",
    "# create a dataframe object\n",
    "df_train = pd.DataFrame(list_train)\n",
    "df_test = pd.DataFrame(list_test)\n",
    "df_val = pd.DataFrame(list_val)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print(df_val.shape)\n",
    "\n",
    "print(df_train.head(5))\n",
    "print(df_test.head(5))\n",
    "print(df_val.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
