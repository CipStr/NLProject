Threshold: 0.1
Report for triggers: 

              precision    recall  f1-score   support

           0       0.83      1.00      0.91      2940
           1       0.18      0.94      0.30       588

   micro avg       0.53      0.99      0.69      3528
   macro avg       0.51      0.97      0.61      3528
weighted avg       0.72      0.99      0.81      3528
 samples avg       0.56      0.99      0.70      3528

-------------------------------------------------------
Report for emotions: 

              precision    recall  f1-score   support

     neutral       0.79      0.80      0.79      1487
         joy       0.56      0.85      0.67       680
    surprise       0.54      0.88      0.67       470
     sadness       0.68      0.17      0.27       282
       anger       0.00      0.00      0.00       373
     disgust       0.33      0.45      0.38       105
        fear       0.17      0.01      0.01       131

    accuracy                           0.64      3528
   macro avg       0.44      0.45      0.40      3528
weighted avg       0.58      0.64      0.59      3528


RMSE for triggers: 0.6284583576276843
RMSE for emotions: 1.6411309081229235


Average F1 score for emotions per dialogue: 0.4874768440566554
Average F1 score for triggers per dialogue: 0.5987847957360858


RMSE for emotions per dialogue: 0.19345733840851576
RMSE for triggers per dialogue: 0.05255912032427986


Epoch 1
-------------------------------
Train loss: 8.784235  [    0/27988]
<ipython-input-154-feffb237d296>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  loss_fct_emo = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights_emotions).to(device))
<ipython-input-154-feffb237d296>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  loss_fct_targ = torch.nn.BCEWithLogitsLoss(weight=torch.tensor(class_weights_triggers).to(device))
Train loss: 6.775538  [ 5000/27988]
Train loss: 1.558511  [10000/27988]
Train loss: 1.582567  [15000/27988]
Train loss: 8.363847  [20000/27988]
Train loss: 1.538459  [25000/27988]

Validation loss: 2.826226.
Saving model ...
Saved PyTorch Model State to model.pth

Epoch 2
-------------------------------
Train loss: 0.798214  [    0/27988]
Train loss: 1.151577  [ 5000/27988]
Train loss: 1.280928  [10000/27988]
Train loss: 1.958405  [15000/27988]
Train loss: 5.472655  [20000/27988]
Train loss: 1.439651  [25000/27988]

Validation loss: 2.525451.
Validation loss decreased (2.82622606 --> 2.52545096).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 3
-------------------------------
Train loss: 0.960670  [    0/27988]
Train loss: 0.989734  [ 5000/27988]
Train loss: 1.511533  [10000/27988]
Train loss: 2.001282  [15000/27988]
Train loss: 6.578076  [20000/27988]
Train loss: 1.316099  [25000/27988]

Validation loss: 2.344474.
Validation loss decreased (2.52545096 --> 2.34447436).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 4
-------------------------------
Train loss: 0.684235  [    0/27988]
Train loss: 0.455769  [ 5000/27988]
Train loss: 1.639512  [10000/27988]
Train loss: 1.619524  [15000/27988]
Train loss: 2.885721  [20000/27988]
Train loss: 1.442919  [25000/27988]

Validation loss: 2.208230.
Validation loss decreased (2.34447436 --> 2.20822957).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 5
-------------------------------
Train loss: 1.326569  [    0/27988]
Train loss: 0.925928  [ 5000/27988]
Train loss: 2.176936  [10000/27988]
Train loss: 1.561577  [15000/27988]
Train loss: 2.607304  [20000/27988]
Train loss: 1.536982  [25000/27988]

Validation loss: 2.164366.
Validation loss decreased (2.20822957 --> 2.16436563).  Saving model ...
Saved PyTorch Model State to model.pth
