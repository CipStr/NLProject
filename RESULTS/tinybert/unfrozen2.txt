Threshold: 0.1
Report for triggers: 

              precision    recall  f1-score   support

           0       0.84      1.00      0.91      2907
           1       0.17      0.92      0.28       542

   micro avg       0.53      0.99      0.69      3449
   macro avg       0.50      0.96      0.60      3449
weighted avg       0.74      0.99      0.82      3449
 samples avg       0.55      0.99      0.70      3449

-------------------------------------------------------
Report for emotions: 

              precision    recall  f1-score   support

     neutral       0.78      0.81      0.79      1499
         joy       0.57      0.89      0.69       599
    surprise       0.56      0.91      0.69       458
     sadness       0.61      0.13      0.22       269
       anger       0.00      0.00      0.00       410
     disgust       0.32      0.44      0.37        93
        fear       0.59      0.08      0.14       121

    accuracy                           0.65      3449
   macro avg       0.49      0.47      0.42      3449
weighted avg       0.59      0.65      0.59      3449


RMSE for triggers: 0.6271218603503614
RMSE for emotions: 1.7002037979252838


Average F1 score for emotions per dialogue: 0.5005140730488536
Average F1 score for triggers per dialogue: 0.5977983097780014


RMSE for emotions per dialogue: 0.2136340695503132
RMSE for triggers per dialogue: 0.05446157863861953

Epoch 1
-------------------------------
Train loss: 3.729967  [    0/28046]
<ipython-input-99-feffb237d296>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  loss_fct_emo = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights_emotions).to(device))
<ipython-input-99-feffb237d296>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  loss_fct_targ = torch.nn.BCEWithLogitsLoss(weight=torch.tensor(class_weights_triggers).to(device))
Train loss: 8.772755  [ 5000/28046]
Train loss: 1.290773  [10000/28046]
Train loss: 2.752586  [15000/28046]
Train loss: 1.242146  [20000/28046]
Train loss: 3.340790  [25000/28046]

Validation loss: 2.913836.
Saving model ...
Saved PyTorch Model State to model.pth

Epoch 2
-------------------------------
Train loss: 1.858063  [    0/28046]
Train loss: 19.008749  [ 5000/28046]
Train loss: 0.403099  [10000/28046]
Train loss: 1.871855  [15000/28046]
Train loss: 0.781632  [20000/28046]
Train loss: 3.469851  [25000/28046]

Validation loss: 2.460290.
Validation loss decreased (2.91383621 --> 2.46029023).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 3
-------------------------------
Train loss: 0.581993  [    0/28046]
Train loss: 9.924115  [ 5000/28046]
Train loss: 0.510780  [10000/28046]
Train loss: 0.909161  [15000/28046]
Train loss: 0.339315  [20000/28046]
Train loss: 4.530611  [25000/28046]

Validation loss: 2.258178.
Validation loss decreased (2.46029023 --> 2.25817810).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 4
-------------------------------
Train loss: 0.560865  [    0/28046]
Train loss: 12.043908  [ 5000/28046]
Train loss: 0.419030  [10000/28046]
Train loss: 0.857786  [15000/28046]
Train loss: 0.828605  [20000/28046]
Train loss: 3.684303  [25000/28046]

Validation loss: 2.130087.
Validation loss decreased (2.25817810 --> 2.13008728).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 5
-------------------------------
Train loss: 0.574598  [    0/28046]
Train loss: 13.999949  [ 5000/28046]
Train loss: 0.364898  [10000/28046]
Train loss: 0.869092  [15000/28046]
Train loss: 0.388067  [20000/28046]
Train loss: 2.680078  [25000/28046]

Validation loss: 2.088388.
Validation loss decreased (2.13008728 --> 2.08838841).  Saving model ...
Saved PyTorch Model State to model.pth
