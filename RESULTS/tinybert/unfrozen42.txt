Threshold: 0.1
Report for triggers: 

              precision    recall  f1-score   support

           0       0.85      1.00      0.92      3027
           1       0.16      0.95      0.27       531

   micro avg       0.52      0.99      0.68      3558
   macro avg       0.50      0.97      0.59      3558
weighted avg       0.75      0.99      0.82      3558
 samples avg       0.54      0.99      0.69      3558

-------------------------------------------------------
Report for emotions: 

              precision    recall  f1-score   support

     neutral       0.82      0.82      0.82      1572
         joy       0.57      0.88      0.69       663
    surprise       0.57      0.88      0.69       486
     sadness       0.57      0.16      0.25       258
       anger       0.88      0.02      0.04       369
     disgust       0.50      0.52      0.51       101
        fear       0.35      0.08      0.13       109

    accuracy                           0.68      3558
   macro avg       0.61      0.48      0.45      3558
weighted avg       0.70      0.68      0.63      3558



RMSE for triggers: 0.6316137610100816
RMSE for emotions: 1.567660813826223

verage F1 score for emotions per dialogue: 0.5197020221616304
Average F1 score for triggers per dialogue: 0.5929365577000777

RMSE for emotions per dialogue: 0.19916191392695096
RMSE for triggers per dialogue: 0.04982261170381963

Epoch 1
-------------------------------
<ipython-input-39-feffb237d296>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  loss_fct_emo = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights_emotions).to(device))
<ipython-input-39-feffb237d296>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  loss_fct_targ = torch.nn.BCEWithLogitsLoss(weight=torch.tensor(class_weights_triggers).to(device))
Train loss: 2.874265  [    0/27764]
Train loss: 2.959498  [ 5000/27764]
Train loss: 8.784478  [10000/27764]
Train loss: 1.219363  [15000/27764]
Train loss: 1.038820  [20000/27764]
Train loss: 1.091075  [25000/27764]

Validation loss: 2.855450.
Saving model ...
Saved PyTorch Model State to model.pth

Epoch 2
-------------------------------
Train loss: 0.290773  [    0/27764]
Train loss: 2.899396  [ 5000/27764]
Train loss: 9.245199  [10000/27764]
Train loss: 0.847318  [15000/27764]
Train loss: 0.689096  [20000/27764]
Train loss: 0.675121  [25000/27764]

Validation loss: 2.424424.
Validation loss decreased (2.85545000 --> 2.42442388).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 3
-------------------------------
Train loss: 0.450662  [    0/27764]
Train loss: 1.379237  [ 5000/27764]
Train loss: 11.104229  [10000/27764]
Train loss: 1.494998  [15000/27764]
Train loss: 1.015199  [20000/27764]
Train loss: 0.661208  [25000/27764]

Validation loss: 2.196581.
Validation loss decreased (2.42442388 --> 2.19658092).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 4
-------------------------------
Train loss: 0.220453  [    0/27764]
Train loss: 1.182897  [ 5000/27764]
Train loss: 11.158583  [10000/27764]
Train loss: 1.616842  [15000/27764]
Train loss: 1.338882  [20000/27764]
Train loss: 0.424812  [25000/27764]

Validation loss: 2.078856.
Validation loss decreased (2.19658092 --> 2.07885609).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 5
-------------------------------
Train loss: 0.244477  [    0/27764]
Train loss: 0.657417  [ 5000/27764]
Train loss: 9.454966  [10000/27764]
Train loss: 1.522449  [15000/27764]
Train loss: 0.552096  [20000/27764]
Train loss: 0.601289  [25000/27764]

Validation loss: 2.026699.
Validation loss decreased (2.07885609 --> 2.02669902).  Saving model ...
Saved PyTorch Model State to model.pth


