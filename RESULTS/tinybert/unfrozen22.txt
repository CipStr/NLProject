Threshold: 0.1
Report for triggers: 

              precision    recall  f1-score   support

           0       0.83      1.00      0.91      3047
           1       0.18      0.95      0.30       606

   micro avg       0.52      0.99      0.68      3653
   macro avg       0.50      0.97      0.60      3653
weighted avg       0.72      0.99      0.81      3653
 samples avg       0.54      0.99      0.69      3653

-------------------------------------------------------
Report for emotions: 

              precision    recall  f1-score   support

     neutral       0.82      0.79      0.80      1570
         joy       0.54      0.90      0.67       680
    surprise       0.59      0.87      0.70       516
     sadness       0.58      0.17      0.26       262
       anger       0.50      0.00      0.01       391
     disgust       0.41      0.50      0.45       113
        fear       0.40      0.05      0.09       121

    accuracy                           0.66      3653
   macro avg       0.55      0.47      0.43      3653
weighted avg       0.65      0.66      0.61      3653


RMSE for triggers: 0.6355733775486845
RMSE for emotions: 1.6105999820617642


Average F1 score for emotions per dialogue: 0.4922706816239676
Average F1 score for triggers per dialogue: 0.5982256575128312


RMSE for emotions per dialogue: 0.1893167373660114
RMSE for triggers per dialogue: 0.04945631268268763


Epoch 1
-------------------------------
Train loss: 8.436362  [    0/27919]
<ipython-input-211-feffb237d296>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  loss_fct_emo = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights_emotions).to(device))
<ipython-input-211-feffb237d296>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  loss_fct_targ = torch.nn.BCEWithLogitsLoss(weight=torch.tensor(class_weights_triggers).to(device))
Train loss: 2.415524  [ 5000/27919]
Train loss: 3.859960  [10000/27919]
Train loss: 1.461188  [15000/27919]
Train loss: 3.123278  [20000/27919]
Train loss: 7.936864  [25000/27919]

Validation loss: 2.921656.
Saving model ...
Saved PyTorch Model State to model.pth

Epoch 2
-------------------------------
Train loss: 8.346395  [    0/27919]
Train loss: 0.984670  [ 5000/27919]
Train loss: 4.827385  [10000/27919]
Train loss: 0.900286  [15000/27919]
Train loss: 2.177821  [20000/27919]
Train loss: 7.894917  [25000/27919]

Validation loss: 2.572348.
Validation loss decreased (2.92165553 --> 2.57234822).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 3
-------------------------------
Train loss: 4.878245  [    0/27919]
Train loss: 0.399289  [ 5000/27919]
Train loss: 4.326990  [10000/27919]
Train loss: 0.889714  [15000/27919]
Train loss: 1.323017  [20000/27919]
Train loss: 6.108808  [25000/27919]

Validation loss: 2.349307.
Validation loss decreased (2.57234822 --> 2.34930682).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 4
-------------------------------
Train loss: 1.131122  [    0/27919]
Train loss: 0.413468  [ 5000/27919]
Train loss: 5.136590  [10000/27919]
Train loss: 0.621960  [15000/27919]
Train loss: 1.303841  [20000/27919]
Train loss: 7.967329  [25000/27919]

Validation loss: 2.225953.
Validation loss decreased (2.34930682 --> 2.22595282).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 5
-------------------------------
Train loss: 6.636832  [    0/27919]
Train loss: 0.376737  [ 5000/27919]
Train loss: 4.464300  [10000/27919]
Train loss: 1.192921  [15000/27919]
Train loss: 2.333127  [20000/27919]
Train loss: 7.581229  [25000/27919]

Validation loss: 2.179390.
Validation loss decreased (2.22595282 --> 2.17938992).  Saving model ...
Saved PyTorch Model State to model.pth
