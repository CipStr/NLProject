Threshold: 0.1
Report for triggers: 

              precision    recall  f1-score   support

           0       0.85      1.00      0.92      3027
           1       0.16      0.96      0.27       531

   micro avg       0.52      0.99      0.69      3558
   macro avg       0.51      0.98      0.60      3558
weighted avg       0.75      0.99      0.82      3558
 samples avg       0.54      0.99      0.69      3558

-------------------------------------------------------
Report for emotions: 

              precision    recall  f1-score   support

     neutral       0.82      0.81      0.82      1572
         joy       0.56      0.89      0.69       663
    surprise       0.59      0.90      0.71       486
     sadness       0.61      0.17      0.27       258
       anger       1.00      0.00      0.01       369
     disgust       0.45      0.50      0.47       101
        fear       0.19      0.04      0.06       109

    accuracy                           0.68      3558
   macro avg       0.60      0.47      0.43      3558
weighted avg       0.71      0.68      0.62      3558


RMSE for triggers: 0.6300082812412429
RMSE for emotions: 1.55397548167245


Average F1 score for emotions per dialogue: 0.520969208155141
Average F1 score for triggers per dialogue: 0.595975306323127


RMSE for emotions per dialogue: 0.20678674815689513
RMSE for triggers per dialogue: 0.049299083263471


Epoch 1
-------------------------------
Train loss: 4.233862  [    0/27764]
<ipython-input-118-feffb237d296>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  loss_fct_emo = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights_emotions).to(device))
<ipython-input-118-feffb237d296>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  loss_fct_targ = torch.nn.BCEWithLogitsLoss(weight=torch.tensor(class_weights_triggers).to(device))
Train loss: 2.480996  [ 5000/27764]
Train loss: 10.791718  [10000/27764]
Train loss: 1.372017  [15000/27764]
Train loss: 1.018855  [20000/27764]
Train loss: 0.728226  [25000/27764]

Validation loss: 2.837309.
Saving model ...
Saved PyTorch Model State to model.pth

Epoch 2
-------------------------------
Train loss: 0.426842  [    0/27764]
Train loss: 3.396687  [ 5000/27764]
Train loss: 10.043173  [10000/27764]
Train loss: 1.695473  [15000/27764]
Train loss: 0.646738  [20000/27764]
Train loss: 0.738011  [25000/27764]

Validation loss: 2.467513.
Validation loss decreased (2.83730949 --> 2.46751293).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 3
-------------------------------
Train loss: 0.246206  [    0/27764]
Train loss: 1.189431  [ 5000/27764]
Train loss: 11.719477  [10000/27764]
Train loss: 1.073714  [15000/27764]
Train loss: 0.735769  [20000/27764]
Train loss: 0.535150  [25000/27764]

Validation loss: 2.253140.
Validation loss decreased (2.46751293 --> 2.25313951).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 4
-------------------------------
Train loss: 0.283180  [    0/27764]
Train loss: 0.649207  [ 5000/27764]
Train loss: 4.086538  [10000/27764]
Train loss: 0.965904  [15000/27764]
Train loss: 0.622543  [20000/27764]
Train loss: 0.477977  [25000/27764]

Validation loss: 2.126923.
Validation loss decreased (2.25313951 --> 2.12692306).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 5
-------------------------------
Train loss: 0.229499  [    0/27764]
Train loss: 0.319368  [ 5000/27764]
Train loss: 9.165403  [10000/27764]
Train loss: 1.077696  [15000/27764]
Train loss: 0.452117  [20000/27764]
Train loss: 0.311056  [25000/27764]

Validation loss: 2.075342.
Validation loss decreased (2.12692306 --> 2.07534214).  Saving model ...
Saved PyTorch Model State to model.pth
