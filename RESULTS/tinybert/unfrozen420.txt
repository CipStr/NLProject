Threshold: 0.1
Report for triggers: 

              precision    recall  f1-score   support

           0       0.84      1.00      0.91      2961
           1       0.17      0.90      0.29       579

   micro avg       0.53      0.98      0.69      3540
   macro avg       0.50      0.95      0.60      3540
weighted avg       0.73      0.98      0.81      3540
 samples avg       0.55      0.98      0.70      3540

-------------------------------------------------------
Report for emotions: 

              precision    recall  f1-score   support

     neutral       0.79      0.80      0.79      1480
         joy       0.60      0.87      0.71       676
    surprise       0.53      0.90      0.67       469
     sadness       0.62      0.19      0.29       291
       anger       1.00      0.00      0.01       392
     disgust       0.32      0.49      0.39       100
        fear       0.57      0.03      0.06       132

    accuracy                           0.65      3540
   macro avg       0.63      0.47      0.42      3540
weighted avg       0.70      0.65      0.59      3540


RMSE for triggers: 0.6290652303001399
RMSE for emotions: 1.6267537255576885


Average F1 score for emotions per dialogue: 0.4882420825081812
Average F1 score for triggers per dialogue: 0.5958194258078356


RMSE for emotions per dialogue: 0.20674546940431426
RMSE for triggers per dialogue: 0.05912911436412715


Epoch 1
-------------------------------
Train loss: 4.495649  [    0/27846]
<ipython-input-266-feffb237d296>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  loss_fct_emo = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights_emotions).to(device))
<ipython-input-266-feffb237d296>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  loss_fct_targ = torch.nn.BCEWithLogitsLoss(weight=torch.tensor(class_weights_triggers).to(device))
Train loss: 2.512362  [ 5000/27846]
Train loss: 4.369958  [10000/27846]
Train loss: 0.827375  [15000/27846]
Train loss: 1.330996  [20000/27846]
Train loss: 0.320144  [25000/27846]

Validation loss: 3.048377.
Saving model ...
Saved PyTorch Model State to model.pth

Epoch 2
-------------------------------
Train loss: 0.409755  [    0/27846]
Train loss: 0.980953  [ 5000/27846]
Train loss: 4.280457  [10000/27846]
Train loss: 0.767683  [15000/27846]
Train loss: 0.440190  [20000/27846]
Train loss: 0.322217  [25000/27846]

Validation loss: 2.652321.
Validation loss decreased (3.04837678 --> 2.65232051).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 3
-------------------------------
Train loss: 0.257592  [    0/27846]
Train loss: 0.610189  [ 5000/27846]
Train loss: 5.272812  [10000/27846]
Train loss: 0.701139  [15000/27846]
Train loss: 0.380900  [20000/27846]
Train loss: 0.219700  [25000/27846]

Validation loss: 2.409672.
Validation loss decreased (2.65232051 --> 2.40967221).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 4
-------------------------------
Train loss: 0.278590  [    0/27846]
Train loss: 0.404238  [ 5000/27846]
Train loss: 5.572050  [10000/27846]
Train loss: 1.318685  [15000/27846]
Train loss: 0.264956  [20000/27846]
Train loss: 0.195727  [25000/27846]

Validation loss: 2.307097.
Validation loss decreased (2.40967221 --> 2.30709729).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 5
-------------------------------
Train loss: 0.213865  [    0/27846]
Train loss: 0.293108  [ 5000/27846]
Train loss: 4.667083  [10000/27846]
Train loss: 0.789499  [15000/27846]
Train loss: 0.366225  [20000/27846]
Train loss: 0.257557  [25000/27846]

Validation loss: 2.270022.
Validation loss decreased (2.30709729 --> 2.27002186).  Saving model ...
Saved PyTorch Model State to model.pth
