Threshold: 0.1
Report for triggers: 

              precision    recall  f1-score   support

           0       0.85      1.00      0.92      3027
           1       0.16      0.95      0.28       531

   micro avg       0.53      0.99      0.69      3558
   macro avg       0.51      0.98      0.60      3558
weighted avg       0.75      0.99      0.82      3558
 samples avg       0.55      0.99      0.70      3558

-------------------------------------------------------
Report for emotions: 

              precision    recall  f1-score   support

     neutral       0.82      0.81      0.82      1572
         joy       0.56      0.88      0.68       663
    surprise       0.59      0.88      0.71       486
     sadness       0.57      0.18      0.28       258
       anger       0.50      0.00      0.01       369
     disgust       0.44      0.59      0.51       101
        fear       0.08      0.01      0.02       109

    accuracy                           0.67      3558
   macro avg       0.51      0.48      0.43      3558
weighted avg       0.66      0.67      0.62      3558


RMSE for triggers: 0.626211975565135
RMSE for emotions: 1.5324850404165837


Average F1 score for emotions per dialogue: 0.5180074387690637
Average F1 score for triggers per dialogue: 0.5958067381278787


RMSE for emotions per dialogue: 0.19710330506194232
RMSE for triggers per dialogue: 0.049408068916327305



Epoch 1
-------------------------------
Train loss: 4.768682  [    0/27764]
<ipython-input-78-feffb237d296>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  loss_fct_emo = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights_emotions).to(device))
<ipython-input-78-feffb237d296>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  loss_fct_targ = torch.nn.BCEWithLogitsLoss(weight=torch.tensor(class_weights_triggers).to(device))
Train loss: 3.023544  [ 5000/27764]
Train loss: 11.104124  [10000/27764]
Train loss: 1.008803  [15000/27764]
Train loss: 1.824390  [20000/27764]
Train loss: 1.184336  [25000/27764]

Validation loss: 2.810477.
Saving model ...
Saved PyTorch Model State to model.pth

Epoch 2
-------------------------------
Train loss: 0.638891  [    0/27764]
Train loss: 2.037251  [ 5000/27764]
Train loss: 10.059638  [10000/27764]
Train loss: 1.173409  [15000/27764]
Train loss: 1.589813  [20000/27764]
Train loss: 0.987466  [25000/27764]

Validation loss: 2.467683.
Validation loss decreased (2.81047655 --> 2.46768305).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 3
-------------------------------
Train loss: 0.241509  [    0/27764]
Train loss: 1.299194  [ 5000/27764]
Train loss: 8.854705  [10000/27764]
Train loss: 2.077008  [15000/27764]
Train loss: 0.557892  [20000/27764]
Train loss: 0.516398  [25000/27764]

Validation loss: 2.236052.
Validation loss decreased (2.46768305 --> 2.23605240).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 4
-------------------------------
Train loss: 0.364550  [    0/27764]
Train loss: 0.491768  [ 5000/27764]
Train loss: 5.605629  [10000/27764]
Train loss: 1.045146  [15000/27764]
Train loss: 0.661151  [20000/27764]
Train loss: 0.481447  [25000/27764]

Validation loss: 2.126667.
Validation loss decreased (2.23605240 --> 2.12666675).  Saving model ...
Saved PyTorch Model State to model.pth

Epoch 5
-------------------------------
Train loss: 0.324866  [    0/27764]
Train loss: 0.895641  [ 5000/27764]
Train loss: 3.821995  [10000/27764]
Train loss: 1.381276  [15000/27764]
Train loss: 1.344491  [20000/27764]
Train loss: 0.385869  [25000/27764]

Validation loss: 2.073193.
Validation loss decreased (2.12666675 --> 2.07319265).  Saving model ...
Saved PyTorch Model State to model.pth
