{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\39328\\anaconda3\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\39328\\anaconda3\\lib\\site-packages (1.19.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\39328\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from matplotlib) (1.19.2)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from matplotlib) (2020.6.20)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from matplotlib) (8.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\39328\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\39328\\anaconda3\\lib\\site-packages (4.50.2)\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas \n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/199 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 199/199 [00:00<00:00, 399.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Dataframes\n",
      "0              word   pos\n",
      "0         Pierre   NNP\n",
      "...\n",
      "1              word  pos\n",
      "0        Rudolph  NNP\n",
      "1 ...\n",
      "2           word   pos\n",
      "0           A    DT\n",
      "1     ...\n",
      "3               word  pos\n",
      "0          Yields  NNS\n",
      "...\n",
      "4                 word   pos\n",
      "0              J.P. ...\n",
      "     word  pos\n",
      "0  Pierre  NNP\n",
      "1  Vinken  NNP\n",
      "2       ,    ,\n",
      "3      61   CD\n",
      "4   years  NNS\n",
      "(199, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create documents dataframe\n",
    "dp_docs = [file for file in os.listdir('dependency_treebank/') if file.endswith('.dp')]\n",
    "dataframes = []\n",
    "\n",
    "for file in tqdm(dp_docs):\n",
    "    with open('dependency_treebank/' + file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        data = [line.split('\\t') for line in lines]\n",
    "        df = pd.DataFrame(data, columns=['word', 'pos', 'head'])\n",
    "        # drop the last column\n",
    "        df = df.iloc[:, :-1]\n",
    "        dataframes.append(df)\n",
    "\n",
    "df = pd.DataFrame({'Dataframes': dataframes})\n",
    "print(df.head(5))\n",
    "print(df['Dataframes'][0][0:5])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(50,)\n",
      "(49,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataframes into train, validation and test sets\n",
    "train = df['Dataframes'][0:100]\n",
    "val = df['Dataframes'][100:150]\n",
    "test = df['Dataframes'][150:200]\n",
    "\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     word  pos\n",
      "0  pierre  NNP\n",
      "1  vinken  NNP\n",
      "2       ,    ,\n",
      "3      61   CD\n",
      "4   years  NNS\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing\n",
    "def to_lower_case(df, docs):\n",
    "    for i in range(docs, len(df)):\n",
    "        df[i]['word'] = df[i]['word'].str.lower()\n",
    "\n",
    "to_lower_case(train, 0)\n",
    "to_lower_case(val, 100)\n",
    "to_lower_case(test, 150)\n",
    "print(train[0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\39328\\anaconda3\\lib\\site-packages (4.3.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from gensim) (1.19.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from gensim) (6.4.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\39328\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:173: UserWarning: A NumPy version >=1.19.5 and <1.27.0 is required for this version of SciPy (detected version 1.19.2)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.downloader as gloader\n",
    "\n",
    "def load_embedding_model(embedding_dimension: int = 50) -> gensim.models.keyedvectors.KeyedVectors:\n",
    "    download_path = \"\"\n",
    "    download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n",
    "        \n",
    "    try:\n",
    "        emb_model = gloader.load(download_path)\n",
    "    except ValueError as e:\n",
    "        print(\"Invalid embedding model name! Check the embedding dimension:\")\n",
    "        print(\"Glove: 50, 100, 200, 300\")\n",
    "        raise e\n",
    "\n",
    "    return emb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove -> 50, 100, 200, 300\n",
    "embedding_model = load_embedding_model(embedding_dimension=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def check_OOV_terms(embedding_model: gensim.models.keyedvectors.KeyedVectors, word_listing: List[str]):\n",
    "    \n",
    "    embedding_vocabulary = set(embedding_model.key_to_index.keys())\n",
    "    oov = set(word_listing).difference(embedding_vocabulary)\n",
    "    return list(oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the word2index and index2word dictionaries\n",
    "def build_word_index(embedding_model: gensim.models.keyedvectors.KeyedVectors, \n",
    "                     word_listing: List[str]) -> Dict[str, int]:\n",
    "    \n",
    "    word2index = {}\n",
    "    index2word = {}\n",
    "    \n",
    "    for i, word in enumerate(word_listing):\n",
    "        word2index[word] = i\n",
    "        index2word[i] = word\n",
    "    \n",
    "    return word2index, index2word\n",
    "\n",
    "# Build the embedding matrix\n",
    "def build_embedding_matrix(embedding_model: gensim.models.keyedvectors.KeyedVectors, \n",
    "                           word2index: Dict[str, int], \n",
    "                           embedding_dimension: int = 50) -> np.ndarray:\n",
    "    \n",
    "    embedding_matrix = np.zeros((len(word2index), embedding_dimension))\n",
    "    \n",
    "    for word, index in word2index.items():\n",
    "        try:\n",
    "            embedding_vector = embedding_model.get_vector(word)\n",
    "            embedding_matrix[index] = embedding_vector\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    return embedding_matrix\n",
    "\n",
    "word2index, index2word = build_word_index(embedding_model, list(embedding_model.key_to_index.keys()))\n",
    "embedding_matrix = build_embedding_matrix(embedding_model, word2index, embedding_dimension=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NNP': 0, ',': 1, 'CD': 2, 'NNS': 3, 'JJ': 4, 'MD': 5, 'VB': 6, 'DT': 7, 'NN': 8, 'IN': 9, '.': 10, None: 11, 'VBZ': 12, 'VBG': 13, 'CC': 14, 'VBD': 15, 'VBN': 16, 'RB': 17, 'TO': 18, 'PRP': 19, 'RBR': 20, 'WDT': 21, 'VBP': 22, 'RP': 23, 'PRP$': 24, 'JJS': 25, 'POS': 26, '``': 27, 'EX': 28, \"''\": 29, 'WP': 30, ':': 31, 'JJR': 32, 'WRB': 33, '$': 34, 'NNPS': 35, 'WP$': 36, '-LRB-': 37, '-RRB-': 38, 'PDT': 39, 'RBS': 40, 'FW': 41, 'UH': 42, 'SYM': 43, 'LS': 44, '#': 45}\n"
     ]
    }
   ],
   "source": [
    "# Build the POS2index and index2POS dictionaries\n",
    "def build_POS_index(df):\n",
    "    pos2index = {}\n",
    "    index2pos = {}\n",
    "    for elem in df:\n",
    "        for pos in elem['pos']:\n",
    "            if pos not in pos2index:\n",
    "                pos2index[pos] = len(pos2index)\n",
    "                index2pos[len(index2pos)] = pos\n",
    "    return pos2index, index2pos\n",
    "\n",
    "pos2index, index2pos = build_POS_index(train)\n",
    "print(pos2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     word  pos\n",
      "0    5029    0\n",
      "1  173714    0\n",
      "2       1    1\n",
      "3    4978    2\n",
      "4      82    3\n"
     ]
    }
   ],
   "source": [
    "# Apply the word2index and POS2index dictionaries to the dataframes\n",
    "def apply_word2index(df, word2index):\n",
    "    for i in range(len(df)):\n",
    "        df[i]['word'] = df[i]['word'].apply(lambda x: word2index[x] if x in word2index else word2index['9999'])\n",
    "    return df\n",
    "\n",
    "def apply_POS2index(df, pos2index):\n",
    "    for i in range(len(df)):\n",
    "        df[i]['pos'] = df[i]['pos'].apply(lambda x: pos2index[x])\n",
    "    return df\n",
    "\n",
    "train_indexed = apply_word2index(train, word2index)\n",
    "train_indexed = apply_POS2index(train_indexed, pos2index)\n",
    "print(train_indexed[0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                word  pos\n",
      "0  [0.2356799989938736, 0.3963800072669983, -0.60...    0\n",
      "1  [0.08332999795675278, -0.2219800055027008, 0.3...    0\n",
      "2  [0.013441000133752823, 0.23681999742984772, -0...    1\n",
      "3  [-0.3661099970340729, 0.38075000047683716, 1.5...    2\n",
      "4  [0.16962000727653503, 0.4343999922275543, -0.0...    3\n"
     ]
    }
   ],
   "source": [
    "# Apply embeddings matrix to the dataframes\n",
    "def apply_embeddings(df, embedding_matrix):\n",
    "    for i in range(len(df)):\n",
    "        df[i]['word'] = df[i]['word'].apply(lambda x: embedding_matrix[x])\n",
    "    return df\n",
    "\n",
    "train_embedded = apply_embeddings(train, embedding_matrix)\n",
    "print(train_embedded[0][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* **Baseline**: implement a Bidirectional LSTM with a Dense layer on top.\n",
    "* You are **free** to experiment with hyper-parameters to define the baseline model.\n",
    "\n",
    "* **Model 1**: add an additional LSTM layer to the Baseline model.\n",
    "* **Model 2**: add an additional Dense layer to the Baseline model.\n",
    "\n",
    "* **Do not mix Model 1 and Model 2**. Each model has its own instructions.\n",
    "\n",
    "**Note**: if a document contains many tokens, you are **free** to split them into chunks or sentences to define your mini-batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\39328\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\39328\\anaconda3\\lib\\site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from torch) (2.11.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\39328\\anaconda3\\lib\\site-packages (from torch) (0.8.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\39328\\anaconda3\\lib\\site-packages (from torch) (1.6.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\39328\\anaconda3\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\39328\\anaconda3\\lib\\site-packages (from torch) (2.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from sympy->torch) (1.1.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from networkx->torch) (4.4.2)\n",
      "Requirement already up-to-date: torch in c:\\users\\39328\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already up-to-date: torchvision in c:\\users\\39328\\anaconda3\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in c:\\users\\39328\\anaconda3\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from torch) (2.11.2)\n",
      "Requirement already satisfied, skipping upgrade: sympy in c:\\users\\39328\\anaconda3\\lib\\site-packages (from torch) (1.6.2)\n",
      "Requirement already satisfied, skipping upgrade: networkx in c:\\users\\39328\\anaconda3\\lib\\site-packages (from torch) (2.5)\n",
      "Requirement already satisfied, skipping upgrade: filelock in c:\\users\\39328\\anaconda3\\lib\\site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied, skipping upgrade: fsspec in c:\\users\\39328\\anaconda3\\lib\\site-packages (from torch) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy in c:\\users\\39328\\anaconda3\\lib\\site-packages (from torchvision) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: requests in c:\\users\\39328\\anaconda3\\lib\\site-packages (from torchvision) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: pillow!=8.3.*,>=5.3.0 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from torchvision) (8.0.1)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: mpmath>=0.19 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from sympy->torch) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from networkx->torch) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.25.11)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\39328\\anaconda3\\lib\\site-packages (from requests->torchvision) (2020.6.20)\n",
      "Requirement already up-to-date: typing-extensions in c:\\users\\39328\\anaconda3\\lib\\site-packages (4.8.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch\n",
    "# !pip install --upgrade torch torchvision\n",
    "# !pip install --upgrade typing-extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model definition\n",
    "import torch\n",
    "\n",
    "class BaselineModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstmlayer = torch.nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.linear = torch.nn.Linear(hidden_size * 2, output_size)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstmlayer(x)\n",
    "        out = self.linear(out)\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
