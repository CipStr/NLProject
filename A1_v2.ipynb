{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas \n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install tqdm\n",
    "# !pip install seaborn\n",
    "# !pip install tensorflow\n",
    "# !pip install keras\n",
    "# !pip install scikit-learn\n",
    "# !pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create documents dataframe\n",
    "dp_docs = [file for file in os.listdir('dependency_treebank/') if file.endswith('.dp')]\n",
    "dataframes = []\n",
    "\n",
    "for file in tqdm(dp_docs):\n",
    "    with open('dependency_treebank/' + file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        data = [line.split('\\t') for line in lines]\n",
    "        df = pd.DataFrame(data, columns=['word', 'pos', 'head'])\n",
    "        # drop the last column\n",
    "        df = df.iloc[:, :-1]\n",
    "        dataframes.append(df)\n",
    "\n",
    "df = pd.DataFrame({'Dataframes': dataframes})\n",
    "print(df.head(5))\n",
    "print(df['Dataframes'][0][0:5])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframes into train, validation and test sets\n",
    "train = df['Dataframes'][0:100]\n",
    "val = df['Dataframes'][100:150]\n",
    "test = df['Dataframes'][150:200]\n",
    "\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "def to_lower_case(df, docs):\n",
    "    for i in range(docs, docs + len(df)):\n",
    "        df[i]['word'] = df[i]['word'].str.lower()\n",
    "\n",
    "to_lower_case(train, 0)\n",
    "to_lower_case(val, 100)\n",
    "to_lower_case(test, 150)\n",
    "print(train[0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing: from each doc remove newlines and empty lines\n",
    "def remove_newlines(df, docs):\n",
    "    for i in range(docs, docs + len(df)):\n",
    "        df[i] = df[i][df[i]['word'] != '\\n']\n",
    "        df[i] = df[i][df[i]['word'] != '']\n",
    "\n",
    "print(len(train[0]))\n",
    "remove_newlines(train, 0)\n",
    "remove_newlines(val, 100)\n",
    "remove_newlines(test, 150)\n",
    "print(train[0])\n",
    "print(len(train[0]))\n",
    "print(len(val[100]))\n",
    "print(len(test[150]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe that contains the single sentences\n",
    "def create_sentences(df, docs):\n",
    "    sentences = []\n",
    "    chunks = []\n",
    "    for i in range(docs, docs + len(df)):\n",
    "        for element in df[i]['word']:\n",
    "            if element != '.' and element != '!' and element != '?':\n",
    "                chunks.append(element)\n",
    "            else:\n",
    "                chunks.append(element)\n",
    "                sentences.append(chunks)\n",
    "                chunks = []\n",
    "    return sentences\n",
    "\n",
    "# Create sentences for train, val and test\n",
    "train_sentences = create_sentences(train, 0)\n",
    "val_sentences = create_sentences(val, 100)\n",
    "test_sentences = create_sentences(test, 150)\n",
    "print(len(train_sentences))\n",
    "print(len(val_sentences))\n",
    "print(len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tag_sentences(df, docs):\n",
    "    tag_sentences = []\n",
    "    chunks = []\n",
    "    for i in range(docs, docs + len(df)):\n",
    "        for element in df[i]['pos']:\n",
    "            if element != '.' and element != '!' and element != '?':\n",
    "                chunks.append(element)\n",
    "            else:\n",
    "                chunks.append(element)\n",
    "                tag_sentences.append(chunks)\n",
    "                chunks = []\n",
    "    return tag_sentences\n",
    "\n",
    "# Create tag sentences for train, val and test\n",
    "train_tag_sentences = create_tag_sentences(train, 0)\n",
    "val_tag_sentences = create_tag_sentences(val, 100)\n",
    "test_tag_sentences = create_tag_sentences(test, 150)\n",
    "print(len(train_tag_sentences))\n",
    "print(len(val_tag_sentences))\n",
    "print(len(test_tag_sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_sentences[0]))\n",
    "print(len(train_tag_sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode train sentences and tags\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sentence_tokenizer = Tokenizer(oov_token='<UNK>')\n",
    "sentence_tokenizer.fit_on_texts(train_sentences)\n",
    "encoded_train_sentences = sentence_tokenizer.texts_to_sequences(train_sentences)\n",
    "encoded_val_sentences = sentence_tokenizer.texts_to_sequences(val_sentences)\n",
    "encoded_test_sentences = sentence_tokenizer.texts_to_sequences(test_sentences)\n",
    "\n",
    "print(f'OOV token: {sentence_tokenizer.oov_token}')\n",
    "print(f'OOV index: {sentence_tokenizer.word_index[sentence_tokenizer.oov_token]}')\n",
    "print(f'Vocabulary size: {len(sentence_tokenizer.word_index)}')\n",
    "print(encoded_train_sentences[0])\n",
    "print(encoded_val_sentences[0])\n",
    "print(encoded_test_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I print and decode sentence 0\n",
    "i = 2\n",
    "print(encoded_train_sentences[i])\n",
    "print(sentence_tokenizer.sequences_to_texts(encoded_train_sentences[i:i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_tokenizer = Tokenizer(oov_token='<UNK>')\n",
    "tag_tokenizer.fit_on_texts(train_tag_sentences)\n",
    "encoded_train_tags = tag_tokenizer.texts_to_sequences(train_tag_sentences)\n",
    "encoded_val_tags = tag_tokenizer.texts_to_sequences(val_tag_sentences)\n",
    "encoded_test_tags = tag_tokenizer.texts_to_sequences(test_tag_sentences)\n",
    "\n",
    "print(f'Tag vocabulary size: {len(tag_tokenizer.word_index)}')\n",
    "print(encoded_train_tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check length of longest sentence \n",
    "lengths = [len(sentence) for sentence in encoded_train_sentences]\n",
    "print(max(lengths))\n",
    "sns.boxplot(lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad each sequence to MAX_SEQ_LENGTH using KERAS' pad_sequences() function. \n",
    "# Sentences longer than MAX_SEQ_LENGTH are truncated.\n",
    "# Sentences shorter than MAX_SEQ_LENGTH are padded with zeroes.\n",
    "\n",
    "# Truncation and padding can either be 'pre' or 'post'. \n",
    "# For padding we are using 'pre' padding type, that is, add zeroes on the left side.\n",
    "# For truncation, we are using 'post', that is, truncate a sentence from right side.\n",
    "\n",
    "MAX_SEQ_LENGTH = 100\n",
    "train_padded = pad_sequences(encoded_train_sentences, maxlen=MAX_SEQ_LENGTH, padding='pre', truncating='post')\n",
    "train_tag_padded = pad_sequences(encoded_train_tags, maxlen=MAX_SEQ_LENGTH, padding='pre', truncating='post')\n",
    "val_padded = pad_sequences(encoded_val_sentences, maxlen=MAX_SEQ_LENGTH, padding='pre', truncating='post')\n",
    "val_tag_padded = pad_sequences(encoded_val_tags, maxlen=MAX_SEQ_LENGTH, padding='pre', truncating='post')\n",
    "test_padded = pad_sequences(encoded_test_sentences, maxlen=MAX_SEQ_LENGTH, padding='pre', truncating='post')\n",
    "test_tag_padded = pad_sequences(encoded_test_tags, maxlen=MAX_SEQ_LENGTH, padding='pre', truncating='post')\n",
    "\n",
    "print(train_padded[0])\n",
    "print(train_tag_padded[0])\n",
    "print(len(train_padded[0]))\n",
    "print(len(train_tag_padded[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as gloader\n",
    "\n",
    "def load_embedding_model(embedding_dimension: int = 50) -> gensim.models.keyedvectors.KeyedVectors:\n",
    "    download_path = \"\"\n",
    "    download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n",
    "        \n",
    "    try:\n",
    "        emb_model = gloader.load(download_path)\n",
    "    except ValueError as e:\n",
    "        print(\"Invalid embedding model name! Check the embedding dimension:\")\n",
    "        print(\"Glove: 50, 100, 200, 300\")\n",
    "        raise e\n",
    "\n",
    "    return emb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove -> 50, 100, 200, 300\n",
    "embedding_model = load_embedding_model(embedding_dimension=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(embedding_model, word2id, embedding_dim):\n",
    "    vocab_size = len(word2id) + 1\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    OOV_embedding = np.random.rand(embedding_dim)\n",
    "    count_not_in_glove = 0\n",
    "    for word, i in tqdm(word2id.items()):\n",
    "        try:\n",
    "            embedding_matrix[i, :] = embedding_model[word]\n",
    "        except KeyError:\n",
    "            if word == '<UNK>':\n",
    "                # give <UNK> a static embedding\n",
    "                embedding_matrix[i, :] = OOV_embedding\n",
    "                continue\n",
    "            # If the word is not in the embedding model, it will have a random embedding vector, but check that its not already present\n",
    "            embedding_vector = np.random.rand(embedding_dim)\n",
    "            while embedding_vector in embedding_matrix:\n",
    "                embedding_vector = np.random.rand(embedding_dim)\n",
    "            embedding_matrix[i, :] = embedding_vector\n",
    "            count_not_in_glove += 1\n",
    "    print(f'Number of words that have no glove embedding: {count_not_in_glove}')\n",
    "    return embedding_matrix\n",
    "\n",
    "embedding_dim = 50\n",
    "embedding_train_matrix = create_embedding_matrix(embedding_model, sentence_tokenizer.word_index, embedding_dim)\n",
    "print(embedding_train_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tags use one-hot encoding\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "Y = to_categorical(train_tag_padded)\n",
    "print(Y.shape)\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_tag_padded.shape)\n",
    "print(train_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Embeddings shape: {}\".format(embedding_train_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, val and test sets\n",
    "X_train = train_padded\n",
    "Y_train = Y\n",
    "X_val = val_padded\n",
    "Y_val = to_categorical(val_tag_padded)\n",
    "X_test = test_padded\n",
    "# for test also consider the missing tags\n",
    "Y_test = to_categorical(test_tag_padded, num_classes=len(tag_tokenizer.word_index)+1)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_OOV_terms(X):\n",
    "    count_OOV = 0\n",
    "    for sentence in X:\n",
    "        for word in sentence:\n",
    "            if word == 1:\n",
    "                count_OOV += 1\n",
    "    print(f'Number of OOV terms: {count_OOV}')\n",
    "\n",
    "check_OOV_terms(X_train)\n",
    "check_OOV_terms(X_val)\n",
    "check_OOV_terms(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Bidirectional, TimeDistributed, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import pickle\n",
    "\n",
    "num_tags = Y_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model: LSTM + FC\n",
    "\n",
    "#HYPERPARAMETERS TUNING:\n",
    "'''\n",
    "def create_baseline_model(lstm_units, dropout_rate, recurrent_dropout_rate, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(sentence_tokenizer.word_index)+1, output_dim=embedding_dim, input_length=MAX_SEQ_LENGTH, weights=[embedding_train_matrix], trainable=True, mask_zero=True))\n",
    "    model.add(Bidirectional(LSTM(units=lstm_units, return_sequences=True, dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate)))\n",
    "    model.add(TimeDistributed(Dense(num_tags, activation='softmax')))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "hyperparameters = { 'lstm_units': [128, 256], \n",
    "                    'dropout_rate': [0.1, 0.2, 0.3],\n",
    "                    'recurrent_dropout_rate': [0.1, 0.2, 0.3],\n",
    "                    'learning_rate': [0.001, 0.01],\n",
    "                    'batch_size': [32, 64, 128]\n",
    "                  }\n",
    "# for each hyperparameter combination, train the model for 3 epochs and save the model with the best validation accuracy\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# create a list of all possible combinations of hyperparameters\n",
    "param_grid = ParameterGrid(hyperparameters)\n",
    "print(f'Number of hyperparameter combinations: {len(param_grid)}')\n",
    "\n",
    "# train the model for each hyperparameter combination\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_baseline_val_accuracy = 0\n",
    "best_baseline_model = None\n",
    "best_baseline_hyperparameters = None\n",
    "\n",
    "for params in tqdm(param_grid):\n",
    "    model = create_baseline_model(params['lstm_units'], params['dropout_rate'], params['recurrent_dropout_rate'], params['learning_rate'])\n",
    "    model.fit(X_train, Y_train, epochs=1, batch_size=params['batch_size'], verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    if val_accuracy > best_baseline_val_accuracy:\n",
    "        best_baseline_val_accuracy = val_accuracy\n",
    "        best_baseline_model = model\n",
    "        best_baseline_hyperparameters = params\n",
    "\n",
    "print(f'Best validation accuracy: {best_baseline_val_accuracy}')\n",
    "print(f'Best hyperparameters: {best_baseline_hyperparameters}') \n",
    "\n",
    "# save the hyperparameters and the model\n",
    "import pickle\n",
    "with open('best_baseline_hyperparameters.pickle', 'wb') as f:\n",
    "    pickle.dump(best_baseline_hyperparameters, f)\n",
    "best_baseline_model.save('best_baseline_model.h5')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "baseline = keras.models.load_model('best_baseline_model.h5')\n",
    "best_baseline_hyperparameters = pickle.load(open('best_baseline_hyperparameters.pickle', 'rb'))\n",
    "baseline.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_baseline = baseline.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=best_baseline_hyperparameters[\"batch_size\"], epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "plt.plot(history_baseline.history['accuracy'])\n",
    "plt.plot(history_baseline.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: LSTM + LSTM + FC\n",
    "\n",
    "#HYPERPARAMETERS TUNING:\n",
    "'''\n",
    "def create_model1(lstm_units, dropout_rate, recurrent_dropout_rate, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(sentence_tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=MAX_SEQ_LENGTH, weights=[embedding_train_matrix], trainable=True, mask_zero=True))\n",
    "    model.add(Bidirectional(LSTM(units=lstm_units, return_sequences=True, dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate)))\n",
    "    model.add(Bidirectional(LSTM(units=int(lstm_units/2), return_sequences=True, dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate)))\n",
    "    model.add(TimeDistributed(Dense(num_tags, activation='softmax')))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# use same hyperparameters as baseline model\n",
    "best_model1_val_accuracy = 0\n",
    "best_model1_model = None\n",
    "best_model1_hyperparameters = None\n",
    "\n",
    "for params in tqdm(param_grid):\n",
    "    model = create_model1(params['lstm_units'], params['dropout_rate'], params['recurrent_dropout_rate'], params['learning_rate'])\n",
    "    model.fit(X_train, Y_train, epochs=1, batch_size=params['batch_size'], verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    if val_accuracy > best_model1_val_accuracy:\n",
    "        best_model1_val_accuracy = val_accuracy\n",
    "        best_model1_model = model\n",
    "        best_model1_hyperparameters = params\n",
    "\n",
    "print(f'Best validation accuracy: {best_model1_val_accuracy}')\n",
    "print(f'Best hyperparameters: {best_model1_hyperparameters}')\n",
    "\n",
    "# save the hyperparameters and the model\n",
    "with open('best_model1_hyperparameters.pickle', 'wb') as f:\n",
    "    pickle.dump(best_model1_hyperparameters, f)\n",
    "best_model1_model.save('best_model1_model.h5')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model1 = keras.models.load_model('best_model1_model.h5')\n",
    "best_model1_hyperparameters = pickle.load(open('best_model1_hyperparameters.pickle', 'rb'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_model1 = model1.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=best_model1_hyperparameters[\"batch_size\"], epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "plt.plot(history_model1.history['accuracy'])\n",
    "plt.plot(history_model1.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: LSTM + FC + FC\n",
    "\n",
    "#HYPERPARAMETERS TUNING:\n",
    "'''\n",
    "def create_model2(lstm_units, dropout_rate, recurrent_dropout_rate, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(sentence_tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=MAX_SEQ_LENGTH, weights=[embedding_train_matrix], trainable=True, mask_zero=True))\n",
    "    model.add(Bidirectional(LSTM(units=lstm_units, return_sequences=True, dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate)))\n",
    "    model.add(TimeDistributed(Dense(num_tags*2, activation=\"softmax\")))\n",
    "    model.add(TimeDistributed(Dense(num_tags, activation=\"softmax\")))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# use same hyperparameters as baseline model\n",
    "best_model2_val_accuracy = 0\n",
    "best_model2_model = None\n",
    "best_model2_hyperparameters = None\n",
    "\n",
    "for params in tqdm(param_grid):\n",
    "    model = create_model2(params['lstm_units'], params['dropout_rate'], params['recurrent_dropout_rate'], params['learning_rate'])\n",
    "    model.fit(X_train, Y_train, epochs=1, batch_size=params['batch_size'], verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    if val_accuracy > best_model2_val_accuracy:\n",
    "        best_model2_val_accuracy = val_accuracy\n",
    "        best_model2_model = model\n",
    "        best_model2_hyperparameters = params\n",
    "    \n",
    "print(f'Best validation accuracy: {best_model2_val_accuracy}')\n",
    "print(f'Best hyperparameters: {best_model2_hyperparameters}')\n",
    "\n",
    "# save the hyperparameters and the model\n",
    "with open('best_model2_hyperparameters.pickle', 'wb') as f:\n",
    "    pickle.dump(best_model2_hyperparameters, f)\n",
    "\n",
    "best_model2_model.save('best_model2_model.h5')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model2 = keras.models.load_model('best_model2_model.h5')\n",
    "best_model2_hyperparameters = pickle.load(open('best_model2_hyperparameters.pickle', 'rb'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_model2 = model2.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=best_model2_hyperparameters[\"batch_size\"], epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "plt.plot(history_model2.history['accuracy'])\n",
    "plt.plot(history_model2.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2idx = tag_tokenizer.word_index\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "print(idx2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get y values for . , oov and pad\n",
    "print(Y_test.shape)\n",
    "print(Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all tags\n",
    "print(tag2idx)\n",
    "# print index of punctuation marks (. , ? ! \" ' - : ; )\n",
    "punctuation_tags = [',', '.', '?', '!', '\"', \"'\", '-', ':', ';' , '<UNK>', '(', ')', '[', ']', '{', '}', '<', '>']\n",
    "punctuation_tags_idx = []\n",
    "for tag in punctuation_tags:\n",
    "    try:\n",
    "        print(f'{tag}: {tag2idx[tag]}')\n",
    "        punctuation_tags_idx.append(tag2idx[tag])\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics: Macro F1 score over all tokens, do not consider punctuation\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def macro_f1(y_true, y_pred):\n",
    "    print(y_true.shape)\n",
    "    y_true = np.argmax(y_true, axis=-1)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    print(y_true.shape)\n",
    "    print(y_pred.shape)\n",
    "    # remove punctuation tags from y_true\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "    print(y_true.shape)\n",
    "    print(y_pred.shape)\n",
    "    print(y_true[38349])\n",
    "    temp = [] \n",
    "    temp_pred = []\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] not in punctuation_tags_idx and y_true[i] != 0:\n",
    "            temp.append(y_true[i])\n",
    "            temp_pred.append(y_pred[i])\n",
    "    print(len(temp))\n",
    "    print(len(temp_pred))\n",
    "    return f1_score(temp, temp_pred, average='macro')\n",
    "    # remove 0 from y_true\n",
    "    # y_true = y_true[y_true != 0]\n",
    "    # print(y_true[0:10])\n",
    "    # print(y_true.shape)\n",
    "    # print(y_pred.shape)\n",
    "    # remove pad from y_true\n",
    "    # y_true = y_true[y_true != 0]\n",
    "    # remove pad from y_pred\n",
    "    # y_pred = y_pred[y_pred != 0]\n",
    "    # print(y_true.shape)\n",
    "    # print(y_pred.shape)\n",
    "    #return f1_score(y_true, y_pred, average='macro')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models\n",
    "print(\"Baseline model\")\n",
    "print(\"Train accuracy: {}\".format(baseline.evaluate(X_train, Y_train)[1]))\n",
    "print(\"Validation accuracy: {}\".format(baseline.evaluate(X_val, Y_val)[1]))\n",
    "print(\"Test accuracy: {}\".format(baseline.evaluate(X_test, Y_test)[1]))\n",
    "print(\"Macro F1 score: {}\".format(macro_f1(Y_test, baseline.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models\n",
    "print(\"Model 1\")\n",
    "print(\"Train accuracy: {}\".format(model1.evaluate(X_train, Y_train)[1]))\n",
    "print(\"Validation accuracy: {}\".format(model1.evaluate(X_val, Y_val)[1]))\n",
    "print(\"Test accuracy: {}\".format(model1.evaluate(X_test, Y_test)[1]))\n",
    "print(\"Macro F1 score: {}\".format(macro_f1(Y_test, model1.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models\n",
    "print(\"Model 2\")\n",
    "print(\"Train accuracy: {}\".format(model2.evaluate(X_train, Y_train)[1]))\n",
    "print(\"Validation accuracy: {}\".format(model2.evaluate(X_val, Y_val)[1]))\n",
    "print(\"Test accuracy: {}\".format(model2.evaluate(X_test, Y_test)[1]))\n",
    "print(\"Macro F1 score: {}\".format(macro_f1(Y_test, model2.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
