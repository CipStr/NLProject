{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "This Jupyter Notebook document is our implementation of Assignment 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas \n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install tqdm\n",
    "# !pip install seaborn\n",
    "# !pip install tensorflow\n",
    "# !pip install keras\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data Loading and Splitting\n",
    "* **Download** the corpus.\n",
    "* **Encode** the corpus into a pandas.DataFrame object.\n",
    "* **Split** it in training, validation, and test sets.\n",
    "\n",
    "[Penn TreeBank corpus](https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/199 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 199/199 [00:01<00:00, 114.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Dataframes\n",
      "0              word   pos\n",
      "0         Pierre   NNP\n",
      "...\n",
      "1              word  pos\n",
      "0        Rudolph  NNP\n",
      "1 ...\n",
      "2           word   pos\n",
      "0           A    DT\n",
      "1     ...\n",
      "3               word  pos\n",
      "0          Yields  NNS\n",
      "...\n",
      "4                 word   pos\n",
      "0              J.P. ...\n",
      "     word  pos\n",
      "0  Pierre  NNP\n",
      "1  Vinken  NNP\n",
      "2       ,    ,\n",
      "3      61   CD\n",
      "4   years  NNS\n",
      "(199, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create documents dataframe\n",
    "dp_docs = [file for file in os.listdir('dependency_treebank/') if file.endswith('.dp')]\n",
    "dataframes = []\n",
    "\n",
    "for file in tqdm(dp_docs):\n",
    "    with open('dependency_treebank/' + file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        data = [line.split('\\t') for line in lines]\n",
    "        df = pd.DataFrame(data, columns=['word', 'pos', 'head'])\n",
    "        # drop the last column\n",
    "        df = df.iloc[:, :-1]\n",
    "        dataframes.append(df)\n",
    "\n",
    "df = pd.DataFrame({'Dataframes': dataframes})\n",
    "print(df.head(5))\n",
    "print(df['Dataframes'][0][0:5])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(50,)\n",
      "(49,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataframes into train, validation and test sets\n",
    "train = df['Dataframes'][0:100]\n",
    "val = df['Dataframes'][100:150]\n",
    "test = df['Dataframes'][150:200]\n",
    "\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     word  pos\n",
      "0  pierre  NNP\n",
      "1  vinken  NNP\n",
      "2       ,    ,\n",
      "3      61   CD\n",
      "4   years  NNS\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing\n",
    "def to_lower_case(df, docs):\n",
    "    for i in range(docs, docs + len(df)):\n",
    "        df[i]['word'] = df[i]['word'].str.lower()\n",
    "\n",
    "to_lower_case(train, 0)\n",
    "to_lower_case(val, 100)\n",
    "to_lower_case(test, 150)\n",
    "print(train[0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "            word  pos\n",
      "0         pierre  NNP\n",
      "1         vinken  NNP\n",
      "2              ,    ,\n",
      "3             61   CD\n",
      "4          years  NNS\n",
      "5            old   JJ\n",
      "6              ,    ,\n",
      "7           will   MD\n",
      "8           join   VB\n",
      "9            the   DT\n",
      "10         board   NN\n",
      "11            as   IN\n",
      "12             a   DT\n",
      "13  nonexecutive   JJ\n",
      "14      director   NN\n",
      "15          nov.  NNP\n",
      "16            29   CD\n",
      "17             .    .\n",
      "19           mr.  NNP\n",
      "20        vinken  NNP\n",
      "21            is  VBZ\n",
      "22      chairman   NN\n",
      "23            of   IN\n",
      "24      elsevier  NNP\n",
      "25          n.v.  NNP\n",
      "26             ,    ,\n",
      "27           the   DT\n",
      "28         dutch  NNP\n",
      "29    publishing  VBG\n",
      "30         group   NN\n",
      "31             .    .\n",
      "31\n",
      "827\n",
      "220\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing: from each doc remove newlines and empty lines\n",
    "def remove_newlines(df, docs):\n",
    "    for i in range(docs, docs + len(df)):\n",
    "        df[i] = df[i][df[i]['word'] != '\\n']\n",
    "        df[i] = df[i][df[i]['word'] != '']\n",
    "\n",
    "print(len(train[0]))\n",
    "remove_newlines(train, 0)\n",
    "remove_newlines(val, 100)\n",
    "remove_newlines(test, 150)\n",
    "print(train[0])\n",
    "print(len(train[0]))\n",
    "print(len(val[100]))\n",
    "print(len(test[150]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1959\n",
      "1277\n",
      "638\n"
     ]
    }
   ],
   "source": [
    "# Create new dataframe that contains the single sentences\n",
    "def create_sentences(df, docs):\n",
    "    sentences = []\n",
    "    chunks = []\n",
    "    for i in range(docs, docs + len(df)):\n",
    "        for element in df[i]['word']:\n",
    "            if element != '.' and element != '!' and element != '?':\n",
    "                chunks.append(element)\n",
    "            else:\n",
    "                chunks.append(element)\n",
    "                sentences.append(chunks)\n",
    "                chunks = []\n",
    "    return sentences\n",
    "\n",
    "# Create sentences for train, val and test\n",
    "train_sentences = create_sentences(train, 0)\n",
    "val_sentences = create_sentences(val, 100)\n",
    "test_sentences = create_sentences(test, 150)\n",
    "print(len(train_sentences))\n",
    "print(len(val_sentences))\n",
    "print(len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1959\n",
      "1277\n",
      "638\n"
     ]
    }
   ],
   "source": [
    "def create_tag_sentences(df, docs):\n",
    "    tag_sentences = []\n",
    "    chunks = []\n",
    "    for i in range(docs, docs + len(df)):\n",
    "        for element in df[i]['pos']:\n",
    "            if element != '.' and element != '!' and element != '?':\n",
    "                chunks.append(element)\n",
    "            else:\n",
    "                chunks.append(element)\n",
    "                tag_sentences.append(chunks)\n",
    "                chunks = []\n",
    "    return tag_sentences\n",
    "\n",
    "# Create tag sentences for train, val and test\n",
    "train_tag_sentences = create_tag_sentences(train, 0)\n",
    "val_tag_sentences = create_tag_sentences(val, 100)\n",
    "test_tag_sentences = create_tag_sentences(test, 150)\n",
    "print(len(train_tag_sentences))\n",
    "print(len(val_tag_sentences))\n",
    "print(len(test_tag_sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sentences[0]))\n",
    "print(len(train_tag_sentences[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Text encoding\n",
    "\n",
    "To train a neural POS tagger, you first need to encode text into numerical format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* Embed words using **GloVe embeddings**.\n",
    "* You are **free** to pick any embedding dimension.\n",
    "* [Optional] You are free to experiment with text pre-processing: **make sure you do not delete any token!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOV token: <UNK>\n",
      "OOV index: 1\n",
      "Vocabulary size: 7405\n",
      "[3427, 2309, 2, 1744, 65, 343, 2, 41, 1371, 3, 192, 24, 7, 1120, 270, 708, 2310, 4]\n",
      "[7, 1, 1033, 839, 298, 1, 5, 7, 1112, 10, 49, 55, 15, 392, 44, 8, 186, 1888, 10, 4437, 12, 1, 2348, 19, 15, 1, 44, 8, 508, 9, 1094, 1, 8, 1669, 260, 8, 1447, 5, 1, 576, 128, 9, 144, 4]\n",
      "[1, 1, 99, 2, 1349, 5229, 2, 753, 2, 17, 18, 1238, 1, 44, 140, 2, 45, 43, 560, 38, 2, 5, 30, 168, 85, 35, 34, 1, 1031, 10, 15, 1, 7, 123, 2, 45, 15, 6185, 44, 4]\n"
     ]
    }
   ],
   "source": [
    "# Encode train sentences and tags\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sentence_tokenizer = Tokenizer(oov_token='<UNK>')\n",
    "sentence_tokenizer.fit_on_texts(train_sentences)\n",
    "encoded_train_sentences = sentence_tokenizer.texts_to_sequences(train_sentences)\n",
    "encoded_val_sentences = sentence_tokenizer.texts_to_sequences(val_sentences)\n",
    "encoded_test_sentences = sentence_tokenizer.texts_to_sequences(test_sentences)\n",
    "\n",
    "print(f'OOV token: {sentence_tokenizer.oov_token}')\n",
    "print(f'OOV index: {sentence_tokenizer.word_index[sentence_tokenizer.oov_token]}')\n",
    "print(f'Vocabulary size: {len(sentence_tokenizer.word_index)}')\n",
    "print(encoded_train_sentences[0])\n",
    "print(encoded_val_sentences[0])\n",
    "print(encoded_test_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1746, 3430, 2, 959, 65, 343, 9, 497, 166, 5, 2311, 1121, 553, 1747, 2, 25, 448, 7, 1120, 270, 5, 46, 1122, 498, 3431, 4]\n",
      "['rudolph agnew , 55 years old and former chairman of consolidated gold fields plc , was named a nonexecutive director of this british industrial conglomerate .']\n"
     ]
    }
   ],
   "source": [
    "# I print and decode sentence 0\n",
    "i = 2\n",
    "print(encoded_train_sentences[i])\n",
    "print(sentence_tokenizer.sequences_to_texts(encoded_train_sentences[i:i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag vocabulary size: 46\n",
      "[3, 3, 8, 12, 6, 7, 8, 21, 13, 5, 2, 4, 5, 7, 2, 3, 12, 9]\n"
     ]
    }
   ],
   "source": [
    "tag_tokenizer = Tokenizer(oov_token='<UNK>')\n",
    "tag_tokenizer.fit_on_texts(train_tag_sentences)\n",
    "encoded_train_tags = tag_tokenizer.texts_to_sequences(train_tag_sentences)\n",
    "encoded_val_tags = tag_tokenizer.texts_to_sequences(val_tag_sentences)\n",
    "encoded_test_tags = tag_tokenizer.texts_to_sequences(test_tag_sentences)\n",
    "\n",
    "print(f'Tag vocabulary size: {len(tag_tokenizer.word_index)}')\n",
    "print(encoded_train_tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\39328\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check length of longest sentence \n",
    "lengths = [len(sentence) for sentence in encoded_train_sentences]\n",
    "print(max(lengths))\n",
    "sns.boxplot(lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0 3427 2309\n",
      "    2 1744   65  343    2   41 1371    3  192   24    7 1120  270  708\n",
      " 2310    4]\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  3  3  8 12  6  7  8 21 13  5  2  4  5  7\n",
      "  2  3 12  9]\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# Pad each sequence to MAX_SEQ_LENGTH using KERAS' pad_sequences() function. \n",
    "# Sentences longer than MAX_SEQ_LENGTH are truncated.\n",
    "# Sentences shorter than MAX_SEQ_LENGTH are padded with zeroes.\n",
    "\n",
    "# Truncation and padding can either be 'pre' or 'post'. \n",
    "# For padding we are using 'pre' padding type, that is, add zeroes on the left side.\n",
    "# For truncation, we are using 'post', that is, truncate a sentence from right side.\n",
    "\n",
    "MAX_SEQ_LENGTH = 100\n",
    "train_padded = pad_sequences(encoded_train_sentences, maxlen=MAX_SEQ_LENGTH, padding='pre', truncating='post')\n",
    "train_tag_padded = pad_sequences(encoded_train_tags, maxlen=MAX_SEQ_LENGTH, padding='pre', truncating='post')\n",
    "val_padded = pad_sequences(encoded_val_sentences, maxlen=MAX_SEQ_LENGTH, padding='pre', truncating='post')\n",
    "val_tag_padded = pad_sequences(encoded_val_tags, maxlen=MAX_SEQ_LENGTH, padding='pre', truncating='post')\n",
    "test_padded = pad_sequences(encoded_test_sentences, maxlen=MAX_SEQ_LENGTH, padding='pre', truncating='post')\n",
    "test_tag_padded = pad_sequences(encoded_test_tags, maxlen=MAX_SEQ_LENGTH, padding='pre', truncating='post')\n",
    "\n",
    "print(train_padded[0])\n",
    "print(train_tag_padded[0])\n",
    "print(len(train_padded[0]))\n",
    "print(len(train_tag_padded[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as gloader\n",
    "\n",
    "def load_embedding_model(embedding_dimension: int = 50) -> gensim.models.keyedvectors.KeyedVectors:\n",
    "    download_path = \"\"\n",
    "    download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n",
    "        \n",
    "    try:\n",
    "        emb_model = gloader.load(download_path)\n",
    "    except ValueError as e:\n",
    "        print(\"Invalid embedding model name! Check the embedding dimension:\")\n",
    "        print(\"Glove: 50, 100, 200, 300\")\n",
    "        raise e\n",
    "\n",
    "    return emb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove -> 50, 100, 200, 300\n",
    "embedding_model = load_embedding_model(embedding_dimension=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7405/7405 [00:00<00:00, 37182.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words that have no glove embedding: 359\n",
      "(7406, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_embedding_matrix(embedding_model, word2id, embedding_dim):\n",
    "    vocab_size = len(word2id) + 1\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    OOV_embedding = np.random.rand(embedding_dim)\n",
    "    count_not_in_glove = 0\n",
    "    for word, i in tqdm(word2id.items()):\n",
    "        try:\n",
    "            embedding_matrix[i, :] = embedding_model[word]\n",
    "        except KeyError:\n",
    "            if word == '<UNK>':\n",
    "                # give <UNK> a static embedding\n",
    "                embedding_matrix[i, :] = OOV_embedding\n",
    "                continue\n",
    "            # If the word is not in the embedding model, it will have a random embedding vector, but check that its not already present\n",
    "            embedding_vector = np.random.rand(embedding_dim)\n",
    "            while embedding_vector in embedding_matrix:\n",
    "                embedding_vector = np.random.rand(embedding_dim)\n",
    "            embedding_matrix[i, :] = embedding_vector\n",
    "            count_not_in_glove += 1\n",
    "    print(f'Number of words that have no glove embedding: {count_not_in_glove}')\n",
    "    return embedding_matrix\n",
    "\n",
    "embedding_dim = 50\n",
    "embedding_train_matrix = create_embedding_matrix(embedding_model, sentence_tokenizer.word_index, embedding_dim)\n",
    "print(embedding_train_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1959, 100, 47)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# For tags use one-hot encoding\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "Y = to_categorical(train_tag_padded)\n",
    "print(Y.shape)\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1959, 100)\n",
      "(1959, 100)\n"
     ]
    }
   ],
   "source": [
    "print(train_tag_padded.shape)\n",
    "print(train_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (7406, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"Embeddings shape: {}\".format(embedding_train_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1959, 100)\n",
      "(1959, 100, 47)\n",
      "(1277, 100)\n",
      "(1277, 100, 47)\n",
      "(638, 100)\n",
      "(638, 100, 47)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train, val and test sets\n",
    "X_train = train_padded\n",
    "Y_train = Y\n",
    "X_val = val_padded\n",
    "Y_val = to_categorical(val_tag_padded)\n",
    "X_test = test_padded\n",
    "# for test also consider the missing tags\n",
    "Y_test = to_categorical(test_tag_padded, num_classes=len(tag_tokenizer.word_index)+1)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of OOV terms: 0\n",
      "Number of OOV terms: 3746\n",
      "Number of OOV terms: 1969\n"
     ]
    }
   ],
   "source": [
    "def check_OOV_terms(X):\n",
    "    count_OOV = 0\n",
    "    for sentence in X:\n",
    "        for word in sentence:\n",
    "            if word == 1:\n",
    "                count_OOV += 1\n",
    "    print(f'Number of OOV terms: {count_OOV}')\n",
    "\n",
    "check_OOV_terms(X_train)\n",
    "check_OOV_terms(X_val)\n",
    "check_OOV_terms(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Model definition\n",
    "\n",
    "You are now tasked to define your neural POS tagger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* **Baseline**: implement a Bidirectional LSTM with a Dense layer on top.\n",
    "* You are **free** to experiment with hyper-parameters to define the baseline model.\n",
    "\n",
    "* **Model 1**: add an additional LSTM layer to the Baseline model.\n",
    "* **Model 2**: add an additional Dense layer to the Baseline model.\n",
    "\n",
    "* **Do not mix Model 1 and Model 2**. Each model has its own instructions.\n",
    "\n",
    "**Note**: if a document contains many tokens, you are **free** to split them into chunks or sentences to define your mini-batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Bidirectional, TimeDistributed, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import pickle\n",
    "\n",
    "num_tags = Y_train.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nhyperparameters = { 'lstm_units': [128, 256], \\n                    'dropout_rate': [0.1, 0.2, 0.3],\\n                    'recurrent_dropout_rate': [0.1, 0.2, 0.3],\\n                    'learning_rate': [0.001, 0.01],\\n                    'batch_size': [32, 64, 128]\\n                  }\\n# for each hyperparameter combination, train the model for 3 epochs and save the model with the best validation accuracy\\nfrom sklearn.model_selection import ParameterGrid\\n\\n# create a list of all possible combinations of hyperparameters\\nparam_grid = ParameterGrid(hyperparameters)\\nprint(f'Number of hyperparameter combinations: {len(param_grid)}')\\n\\n# train the model for each hyperparameter combination\\nfrom sklearn.metrics import accuracy_score\\n\\nbest_baseline_val_accuracy = 0\\nbest_baseline_model = None\\nbest_baseline_hyperparameters = None\\n\\nfor params in tqdm(param_grid):\\n    model = create_baseline_model(params['lstm_units'], params['dropout_rate'], params['recurrent_dropout_rate'], params['learning_rate'])\\n    model.fit(X_train, Y_train, epochs=1, batch_size=params['batch_size'], verbose=0)\\n    val_loss, val_accuracy = model.evaluate(X_val, Y_val, verbose=0)\\n    if val_accuracy > best_baseline_val_accuracy:\\n        best_baseline_val_accuracy = val_accuracy\\n        best_baseline_model = model\\n        best_baseline_hyperparameters = params\\n\\nprint(f'Best validation accuracy: {best_baseline_val_accuracy}')\\nprint(f'Best hyperparameters: {best_baseline_hyperparameters}') \\n\\n# save the hyperparameters and the model\\nimport pickle\\nwith open('best_baseline_hyperparameters.pickle', 'wb') as f:\\n    pickle.dump(best_baseline_hyperparameters, f)\\nbest_baseline_model.save('best_baseline_model.h5')\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model: LSTM + FC\n",
    "\n",
    "#HYPERPARAMETERS TUNING:\n",
    "\n",
    "def create_baseline_model(lstm_units, dropout_rate, recurrent_dropout_rate, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(sentence_tokenizer.word_index)+1, output_dim=embedding_dim, input_length=MAX_SEQ_LENGTH, weights=[embedding_train_matrix], trainable=True, mask_zero=True))\n",
    "    model.add(Bidirectional(LSTM(units=lstm_units, return_sequences=True, dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate)))\n",
    "    model.add(TimeDistributed(Dense(num_tags, activation='softmax')))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model\n",
    "'''\n",
    "hyperparameters = { 'lstm_units': [128, 256], \n",
    "                    'dropout_rate': [0.1, 0.2, 0.3],\n",
    "                    'recurrent_dropout_rate': [0.1, 0.2, 0.3],\n",
    "                    'learning_rate': [0.001, 0.01],\n",
    "                    'batch_size': [32, 64, 128]\n",
    "                  }\n",
    "# for each hyperparameter combination, train the model for 3 epochs and save the model with the best validation accuracy\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# create a list of all possible combinations of hyperparameters\n",
    "param_grid = ParameterGrid(hyperparameters)\n",
    "print(f'Number of hyperparameter combinations: {len(param_grid)}')\n",
    "\n",
    "# train the model for each hyperparameter combination\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_baseline_val_accuracy = 0\n",
    "best_baseline_model = None\n",
    "best_baseline_hyperparameters = None\n",
    "\n",
    "for params in tqdm(param_grid):\n",
    "    model = create_baseline_model(params['lstm_units'], params['dropout_rate'], params['recurrent_dropout_rate'], params['learning_rate'])\n",
    "    model.fit(X_train, Y_train, epochs=1, batch_size=params['batch_size'], verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    if val_accuracy > best_baseline_val_accuracy:\n",
    "        best_baseline_val_accuracy = val_accuracy\n",
    "        best_baseline_model = model\n",
    "        best_baseline_hyperparameters = params\n",
    "\n",
    "print(f'Best validation accuracy: {best_baseline_val_accuracy}')\n",
    "print(f'Best hyperparameters: {best_baseline_hyperparameters}') \n",
    "\n",
    "# save the hyperparameters and the model\n",
    "import pickle\n",
    "with open('best_baseline_hyperparameters.pickle', 'wb') as f:\n",
    "    pickle.dump(best_baseline_hyperparameters, f)\n",
    "best_baseline_model.save('best_baseline_model.h5')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 50)           370300    \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 100, 512)          628736    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 100, 47)           24111     \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1023147 (3.90 MB)\n",
      "Trainable params: 1023147 (3.90 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "#baseline = keras.models.load_model('best_baseline_model.h5')\n",
    "best_baseline_hyperparameters = pickle.load(open('best_baseline_hyperparameters.pickle', 'rb'))\n",
    "baseline = create_baseline_model(best_baseline_hyperparameters['lstm_units'], best_baseline_hyperparameters['dropout_rate'], best_baseline_hyperparameters['recurrent_dropout_rate'], best_baseline_hyperparameters['learning_rate'])\n",
    "baseline.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# use same hyperparameters as baseline model\\nbest_model1_val_accuracy = 0\\nbest_model1_model = None\\nbest_model1_hyperparameters = None\\n\\nfor params in tqdm(param_grid):\\n    model = create_model1(params['lstm_units'], params['dropout_rate'], params['recurrent_dropout_rate'], params['learning_rate'])\\n    model.fit(X_train, Y_train, epochs=1, batch_size=params['batch_size'], verbose=0)\\n    val_loss, val_accuracy = model.evaluate(X_val, Y_val, verbose=0)\\n    if val_accuracy > best_model1_val_accuracy:\\n        best_model1_val_accuracy = val_accuracy\\n        best_model1_model = model\\n        best_model1_hyperparameters = params\\n\\nprint(f'Best validation accuracy: {best_model1_val_accuracy}')\\nprint(f'Best hyperparameters: {best_model1_hyperparameters}')\\n\\n# save the hyperparameters and the model\\nwith open('best_model1_hyperparameters.pickle', 'wb') as f:\\n    pickle.dump(best_model1_hyperparameters, f)\\nbest_model1_model.save('best_model1_model.h5')\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 1: LSTM + LSTM + FC\n",
    "\n",
    "#HYPERPARAMETERS TUNING:\n",
    "\n",
    "def create_model1(lstm_units, dropout_rate, recurrent_dropout_rate, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(sentence_tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=MAX_SEQ_LENGTH, weights=[embedding_train_matrix], trainable=True, mask_zero=True))\n",
    "    model.add(Bidirectional(LSTM(units=lstm_units, return_sequences=True, dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate)))\n",
    "    model.add(Bidirectional(LSTM(units=int(lstm_units/2), return_sequences=True, dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate)))\n",
    "    model.add(TimeDistributed(Dense(num_tags, activation='softmax')))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model\n",
    "'''\n",
    "# use same hyperparameters as baseline model\n",
    "best_model1_val_accuracy = 0\n",
    "best_model1_model = None\n",
    "best_model1_hyperparameters = None\n",
    "\n",
    "for params in tqdm(param_grid):\n",
    "    model = create_model1(params['lstm_units'], params['dropout_rate'], params['recurrent_dropout_rate'], params['learning_rate'])\n",
    "    model.fit(X_train, Y_train, epochs=1, batch_size=params['batch_size'], verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    if val_accuracy > best_model1_val_accuracy:\n",
    "        best_model1_val_accuracy = val_accuracy\n",
    "        best_model1_model = model\n",
    "        best_model1_hyperparameters = params\n",
    "\n",
    "print(f'Best validation accuracy: {best_model1_val_accuracy}')\n",
    "print(f'Best hyperparameters: {best_model1_hyperparameters}')\n",
    "\n",
    "# save the hyperparameters and the model\n",
    "with open('best_model1_hyperparameters.pickle', 'wb') as f:\n",
    "    pickle.dump(best_model1_hyperparameters, f)\n",
    "best_model1_model.save('best_model1_model.h5')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 50)           370300    \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 100, 512)          628736    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  (None, 100, 256)          656384    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 100, 47)           12079     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1667499 (6.36 MB)\n",
      "Trainable params: 1667499 (6.36 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "best_model1_hyperparameters = pickle.load(open('best_model1_hyperparameters.pickle', 'rb'))\n",
    "model1 = create_model1(best_model1_hyperparameters['lstm_units'], best_model1_hyperparameters['dropout_rate'], best_model1_hyperparameters['recurrent_dropout_rate'], best_model1_hyperparameters['learning_rate'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# use same hyperparameters as baseline model\\nbest_model2_val_accuracy = 0\\nbest_model2_model = None\\nbest_model2_hyperparameters = None\\n\\nfor params in tqdm(param_grid):\\n    model = create_model2(params['lstm_units'], params['dropout_rate'], params['recurrent_dropout_rate'], params['learning_rate'])\\n    model.fit(X_train, Y_train, epochs=1, batch_size=params['batch_size'], verbose=0)\\n    val_loss, val_accuracy = model.evaluate(X_val, Y_val, verbose=0)\\n    if val_accuracy > best_model2_val_accuracy:\\n        best_model2_val_accuracy = val_accuracy\\n        best_model2_model = model\\n        best_model2_hyperparameters = params\\n    \\nprint(f'Best validation accuracy: {best_model2_val_accuracy}')\\nprint(f'Best hyperparameters: {best_model2_hyperparameters}')\\n\\n# save the hyperparameters and the model\\nwith open('best_model2_hyperparameters.pickle', 'wb') as f:\\n    pickle.dump(best_model2_hyperparameters, f)\\n\\nbest_model2_model.save('best_model2_model.h5')\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 2: LSTM + FC + FC\n",
    "\n",
    "#HYPERPARAMETERS TUNING:\n",
    "\n",
    "def create_model2(lstm_units, dropout_rate, recurrent_dropout_rate, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(sentence_tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=MAX_SEQ_LENGTH, weights=[embedding_train_matrix], trainable=True, mask_zero=True))\n",
    "    model.add(Bidirectional(LSTM(units=lstm_units, return_sequences=True, dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate)))\n",
    "    model.add(TimeDistributed(Dense(num_tags*2, activation=\"softmax\")))\n",
    "    model.add(TimeDistributed(Dense(num_tags, activation=\"softmax\")))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model\n",
    "'''\n",
    "# use same hyperparameters as baseline model\n",
    "best_model2_val_accuracy = 0\n",
    "best_model2_model = None\n",
    "best_model2_hyperparameters = None\n",
    "\n",
    "for params in tqdm(param_grid):\n",
    "    model = create_model2(params['lstm_units'], params['dropout_rate'], params['recurrent_dropout_rate'], params['learning_rate'])\n",
    "    model.fit(X_train, Y_train, epochs=1, batch_size=params['batch_size'], verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    if val_accuracy > best_model2_val_accuracy:\n",
    "        best_model2_val_accuracy = val_accuracy\n",
    "        best_model2_model = model\n",
    "        best_model2_hyperparameters = params\n",
    "    \n",
    "print(f'Best validation accuracy: {best_model2_val_accuracy}')\n",
    "print(f'Best hyperparameters: {best_model2_hyperparameters}')\n",
    "\n",
    "# save the hyperparameters and the model\n",
    "with open('best_model2_hyperparameters.pickle', 'wb') as f:\n",
    "    pickle.dump(best_model2_hyperparameters, f)\n",
    "\n",
    "best_model2_model.save('best_model2_model.h5')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 50)           370300    \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirecti  (None, 100, 256)          183296    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDi  (None, 100, 94)           24158     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDi  (None, 100, 47)           4465      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 582219 (2.22 MB)\n",
      "Trainable params: 582219 (2.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "best_model2_hyperparameters = pickle.load(open('best_model2_hyperparameters.pickle', 'rb'))\n",
    "model2 = create_model2(best_model2_hyperparameters['lstm_units'], best_model2_hyperparameters['dropout_rate'], best_model2_hyperparameters['recurrent_dropout_rate'], best_model2_hyperparameters['learning_rate'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Metrics\n",
    "\n",
    "Before training the models, you are tasked to define the evaluation metrics for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* Evaluate your models using macro F1-score, compute over **all** tokens.\n",
    "* **Concatenate** all tokens in a data split to compute the F1-score. (**Hint**: accumulate FP, TP, FN, TN iteratively) \n",
    "* **Do not consider punctuation and symbol classes** $\\rightarrow$ [What is punctuation?](https://en.wikipedia.org/wiki/English_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: What about OOV tokens?\n",
    "   * All the tokens in the **training** set that are not in GloVe are **not** considered as OOV\n",
    "   * For the remaining tokens (i.e., OOV in the validation and test sets), you have to assign them a **static** embedding.\n",
    "   * You are **free** to define the static embedding using any strategy (e.g., random, neighbourhood, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: '<UNK>', 2: 'nn', 3: 'nnp', 4: 'in', 5: 'dt', 6: 'nns', 7: 'jj', 8: ',', 9: '.', 10: 'vbd', 11: 'rb', 12: 'cd', 13: 'vb', 14: 'cc', 15: 'vbz', 16: 'vbn', 17: 'to', 18: 'prp', 19: 'vbg', 20: 'vbp', 21: 'md', 22: 'prp$', 23: '``', 24: 'pos', 25: \"''\", 26: '$', 27: ':', 28: 'wdt', 29: 'jjr', 30: 'wp', 31: 'rp', 32: 'nnps', 33: 'jjs', 34: 'wrb', 35: 'rbr', 36: '-rrb-', 37: '-lrb-', 38: 'ex', 39: 'rbs', 40: 'ls', 41: 'pdt', 42: 'wp$', 43: 'fw', 44: 'uh', 45: 'sym', 46: '#'}\n"
     ]
    }
   ],
   "source": [
    "tag2idx = tag_tokenizer.word_index\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "print(idx2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(638, 100, 47)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# get y values for . , oov and pad\n",
    "print(Y_test.shape)\n",
    "print(Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<UNK>': 1, 'nn': 2, 'nnp': 3, 'in': 4, 'dt': 5, 'nns': 6, 'jj': 7, ',': 8, '.': 9, 'vbd': 10, 'rb': 11, 'cd': 12, 'vb': 13, 'cc': 14, 'vbz': 15, 'vbn': 16, 'to': 17, 'prp': 18, 'vbg': 19, 'vbp': 20, 'md': 21, 'prp$': 22, '``': 23, 'pos': 24, \"''\": 25, '$': 26, ':': 27, 'wdt': 28, 'jjr': 29, 'wp': 30, 'rp': 31, 'nnps': 32, 'jjs': 33, 'wrb': 34, 'rbr': 35, '-rrb-': 36, '-lrb-': 37, 'ex': 38, 'rbs': 39, 'ls': 40, 'pdt': 41, 'wp$': 42, 'fw': 43, 'uh': 44, 'sym': 45, '#': 46}\n",
      ",: 8\n",
      ".: 9\n",
      ":: 27\n",
      "<UNK>: 1\n"
     ]
    }
   ],
   "source": [
    "# print all tags\n",
    "print(tag2idx)\n",
    "# print index of punctuation marks (. , ? ! \" ' - : ; )\n",
    "punctuation_tags = [',', '.', '?', '!', '\"', \"'\", '-', ':', ';' , '<UNK>', '(', ')', '[', ']', '{', '}', '<', '>']\n",
    "punctuation_tags_idx = []\n",
    "for tag in punctuation_tags:\n",
    "    try:\n",
    "        print(f'{tag}: {tag2idx[tag]}')\n",
    "        punctuation_tags_idx.append(tag2idx[tag])\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics: Macro F1 score over all tokens, do not consider punctuation\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def macro_f1(y_true, y_pred):\n",
    "    print(y_true.shape)\n",
    "    y_true = np.argmax(y_true, axis=-1)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    print(y_true.shape)\n",
    "    print(y_pred.shape)\n",
    "    # remove punctuation tags from y_true\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "    print(y_true.shape)\n",
    "    print(y_pred.shape)\n",
    "    print(y_true[38349])\n",
    "    temp = [] \n",
    "    temp_pred = []\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] not in punctuation_tags_idx and y_true[i] != 0:\n",
    "            temp.append(y_true[i])\n",
    "            temp_pred.append(y_pred[i])\n",
    "    print(len(temp))\n",
    "    print(len(temp_pred))\n",
    "    return f1_score(temp, temp_pred, average='macro')\n",
    "    # remove 0 from y_true\n",
    "    # y_true = y_true[y_true != 0]\n",
    "    # print(y_true[0:10])\n",
    "    # print(y_true.shape)\n",
    "    # print(y_pred.shape)\n",
    "    # remove pad from y_true\n",
    "    # y_true = y_true[y_true != 0]\n",
    "    # remove pad from y_pred\n",
    "    # y_pred = y_pred[y_pred != 0]\n",
    "    # print(y_true.shape)\n",
    "    # print(y_pred.shape)\n",
    "    #return f1_score(y_true, y_pred, average='macro')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Training and Evaluation\n",
    "\n",
    "You are now tasked to train and evaluate the Baseline, Model 1, and Model 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* Train **all** models on the train set.\n",
    "* Evaluate **all** models on the validation set.\n",
    "* Compute metrics on the validation set.\n",
    "* Pick **at least** three seeds for robust estimation.\n",
    "* Pick the **best** performing model according to the observed validation set performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "seed = 42\n",
    "#seed = 69\n",
    "#seed = 420\n",
    "\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "62/62 [==============================] - 135s 2s/step - loss: 1.1021 - accuracy: 0.6979 - val_loss: 0.5397 - val_accuracy: 0.8502\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 139s 2s/step - loss: 0.2238 - accuracy: 0.9351 - val_loss: 0.4260 - val_accuracy: 0.8849\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 162s 3s/step - loss: 0.1092 - accuracy: 0.9679 - val_loss: 0.4295 - val_accuracy: 0.8910\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 213s 3s/step - loss: 0.0626 - accuracy: 0.9818 - val_loss: 0.4728 - val_accuracy: 0.8890\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 190s 3s/step - loss: 0.0407 - accuracy: 0.9884 - val_loss: 0.4861 - val_accuracy: 0.8907\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 268s 4s/step - loss: 0.0263 - accuracy: 0.9928 - val_loss: 0.5342 - val_accuracy: 0.8901\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 257s 4s/step - loss: 0.0179 - accuracy: 0.9954 - val_loss: 0.5720 - val_accuracy: 0.8896\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 207s 3s/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.5660 - val_accuracy: 0.8890\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 201s 3s/step - loss: 0.0096 - accuracy: 0.9979 - val_loss: 0.6027 - val_accuracy: 0.8895\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 185s 3s/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.5984 - val_accuracy: 0.8883\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 178s 3s/step - loss: 0.0084 - accuracy: 0.9980 - val_loss: 0.6306 - val_accuracy: 0.8878\n",
      "Epoch 12/20\n",
      "30/62 [=============>................] - ETA: 6:57 - loss: 0.0057 - accuracy: 0.9989"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-7bb2875e28ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory_baseline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbest_baseline_hyperparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"batch_size\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\39328\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\39328\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                         ):\n\u001b[0;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1743\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\39328\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\39328\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 825\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\39328\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    855\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 857\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    858\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\39328\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m       (concrete_function,\n\u001b[0;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[1;33m     return concrete_function._call_flat(\n\u001b[0m\u001b[0;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\39328\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1348\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1349\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\39328\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\39328\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mcall_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1457\u001b[1;33m       outputs = execute.execute(\n\u001b[0m\u001b[0;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\39328\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_baseline = baseline.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=best_baseline_hyperparameters[\"batch_size\"], epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_baseline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-ff8a14ff6a0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# plot results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_baseline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_baseline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history_baseline' is not defined"
     ]
    }
   ],
   "source": [
    "# plot results\n",
    "plt.plot(history_baseline.history['accuracy'])\n",
    "plt.plot(history_baseline.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model\n",
      "62/62 [==============================] - 6s 90ms/step - loss: 0.0019 - accuracy: 0.9999\n",
      "Train accuracy: 0.9999152421951294\n",
      "40/40 [==============================] - 4s 91ms/step - loss: 0.6651 - accuracy: 0.8786\n",
      "Validation accuracy: 0.8786197900772095\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models\n",
    "print(\"Baseline model\")\n",
    "print(\"Train accuracy: {}\".format(baseline.evaluate(X_train, Y_train)[1]))\n",
    "print(\"Validation accuracy: {}\".format(baseline.evaluate(X_val, Y_val)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "62/62 [==============================] - 82s 1s/step - loss: 1.3851 - accuracy: 0.6102 - val_loss: 0.6259 - val_accuracy: 0.8253\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 77s 1s/step - loss: 0.2847 - accuracy: 0.9188 - val_loss: 0.4539 - val_accuracy: 0.8740\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 79s 1s/step - loss: 0.1420 - accuracy: 0.9584 - val_loss: 0.4495 - val_accuracy: 0.8776\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 77s 1s/step - loss: 0.0886 - accuracy: 0.9735 - val_loss: 0.4779 - val_accuracy: 0.8795\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 79s 1s/step - loss: 0.0641 - accuracy: 0.9808 - val_loss: 0.4935 - val_accuracy: 0.8839\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 80s 1s/step - loss: 0.0495 - accuracy: 0.9850 - val_loss: 0.5119 - val_accuracy: 0.8826\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 78s 1s/step - loss: 0.0380 - accuracy: 0.9877 - val_loss: 0.6083 - val_accuracy: 0.8742\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 79s 1s/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.6149 - val_accuracy: 0.8765\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 81s 1s/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.6061 - val_accuracy: 0.8815\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 92s 1s/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.6360 - val_accuracy: 0.8775\n"
     ]
    }
   ],
   "source": [
    "history_model1 = model1.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=best_model1_hyperparameters[\"batch_size\"], epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot results\n",
    "plt.plot(history_model1.history['accuracy'])\n",
    "plt.plot(history_model1.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1896 - accuracy: 0.9571\n",
      "Train accuracy: 0.9570801854133606\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.5018 - accuracy: 0.8662\n",
      "Validation accuracy: 0.8662091493606567\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.4311 - accuracy: 0.8782\n",
      "Test accuracy: 0.8782244920730591\n",
      "20/20 [==============================] - 2s 43ms/step\n",
      "(638, 100, 47)\n",
      "(638, 100)\n",
      "(638, 100)\n",
      "(63800,)\n",
      "(63800,)\n",
      "0\n",
      "14064\n",
      "14064\n",
      "Macro F1 score: 0.7096058528931841\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models\n",
    "print(\"Model 1\")\n",
    "print(\"Train accuracy: {}\".format(model1.evaluate(X_train, Y_train)[1]))\n",
    "print(\"Validation accuracy: {}\".format(model1.evaluate(X_val, Y_val)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "62/62 [==============================] - 14s 230ms/step - loss: 0.1951 - accuracy: 0.9604 - val_loss: 0.9470 - val_accuracy: 0.8274\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.1904 - accuracy: 0.9609 - val_loss: 0.9062 - val_accuracy: 0.8304\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 14s 223ms/step - loss: 0.1844 - accuracy: 0.9618 - val_loss: 0.9190 - val_accuracy: 0.8288\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.1774 - accuracy: 0.9626 - val_loss: 0.9267 - val_accuracy: 0.8279\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 14s 228ms/step - loss: 0.1732 - accuracy: 0.9630 - val_loss: 0.9006 - val_accuracy: 0.8308\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.1683 - accuracy: 0.9634 - val_loss: 0.9603 - val_accuracy: 0.8253\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 14s 222ms/step - loss: 0.1643 - accuracy: 0.9641 - val_loss: 0.9336 - val_accuracy: 0.8307\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 14s 221ms/step - loss: 0.1628 - accuracy: 0.9642 - val_loss: 0.9341 - val_accuracy: 0.8318\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.1572 - accuracy: 0.9644 - val_loss: 0.9437 - val_accuracy: 0.8311\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1531 - accuracy: 0.9657 - val_loss: 0.9563 - val_accuracy: 0.8314\n"
     ]
    }
   ],
   "source": [
    "history_model2 = model2.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=best_model2_hyperparameters[\"batch_size\"], epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot results\n",
    "plt.plot(history_model2.history['accuracy'])\n",
    "plt.plot(history_model2.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.1417 - accuracy: 0.9693\n",
      "Train accuracy: 0.9692673087120056\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.9563 - accuracy: 0.8314\n",
      "Validation accuracy: 0.831446647644043\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models\n",
    "print(\"Model 2\")\n",
    "print(\"Train accuracy: {}\".format(model2.evaluate(X_train, Y_train)[1]))\n",
    "print(\"Validation accuracy: {}\".format(model2.evaluate(X_val, Y_val)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6: Error Analysis\n",
    "\n",
    "You are tasked to evaluate your best performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* Compare the errors made on the validation and test sets.\n",
    "* Aggregate model errors into categories (if possible) \n",
    "* Comment the about errors and propose possible solutions on how to address them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 40ms/step - loss: 0.1896 - accuracy: 0.9571\n",
      "Train accuracy: 0.9570801854133606\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.5018 - accuracy: 0.8662\n",
      "Validation accuracy: 0.8662091493606567\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4311 - accuracy: 0.8782\n",
      "Test accuracy: 0.8782244920730591\n",
      "20/20 [==============================] - 1s 40ms/step\n",
      "(638, 100, 47)\n",
      "(638, 100)\n",
      "(638, 100)\n",
      "(63800,)\n",
      "(63800,)\n",
      "0\n",
      "14064\n",
      "14064\n",
      "Macro F1 score: 0.7096058528931841\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: {}\".format(model1.evaluate(X_train, Y_train)[1]))\n",
    "print(\"Validation accuracy: {}\".format(model1.evaluate(X_val, Y_val)[1]))\n",
    "print(\"Test accuracy: {}\".format(model1.evaluate(X_test, Y_test)[1]))\n",
    "print(\"Macro F1 score: {}\".format(macro_f1(Y_test, model1.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 4s 201ms/step\n",
      "(638, 100, 47)\n",
      "Score for the tag nn is: 0.05712001279283601\n",
      "Score for the tag nnp is: 0.07594402219809386\n",
      "Score for the tag in is: 0.141261963842609\n",
      "Score for the tag dt is: 0.19909706546275394\n",
      "Score for the tag nns is: 0.0715909090909091\n",
      "Score for the tag jj is: 0.08694581280788177\n",
      "Score for the tag vbd is: 0.06603659275415\n",
      "Score for the tag rb is: 0.06543385490753911\n",
      "Score for the tag cd is: 0.1965619442797866\n",
      "Score for the tag vb is: 0.12776797961983147\n",
      "Score for the tag cc is: 0.49931600547195626\n",
      "Score for the tag vbz is: 0.11866791744840526\n",
      "Score for the tag vbn is: 0.08097560975609755\n",
      "Score for the tag to is: 1.0\n",
      "Score for the tag prp is: 0.49869451697127937\n",
      "Score for the tag vbg is: 0.07409212771143066\n",
      "Score for the tag vbp is: 0.09280000000000001\n",
      "Score for the tag md is: 1.0\n",
      "Score for the tag prp$ is: 1.0\n",
      "Score for the tag `` is: 1.0\n",
      "Score for the tag pos is: 0.4966887417218543\n",
      "Score for the tag '' is: 1.0\n",
      "Score for the tag $ is: 1.0\n",
      "Score for the tag wdt is: 0.48466257668711654\n",
      "Score for the tag jjr is: 0.1488095238095238\n",
      "Score for the tag wp is: 1.0\n",
      "Score for the tag rp is: 0.22666666666666666\n",
      "Score for the tag nnps is: 0.02553191489361702\n",
      "Score for the tag jjs is: 1.0\n",
      "Score for the tag wrb is: 0.48936170212765956\n",
      "Score for the tag rbr is: 0.4444444444444445\n",
      "Score for the tag -rrb- is: 1.0\n",
      "Score for the tag -lrb- is: 1.0\n",
      "Score for the tag ex is: 1.0\n",
      "Score for the tag rbs is: 0.4\n",
      "Score for the tag pdt is: 0.3333333333333333\n",
      "Score for the tag wp$ is: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_true = Y_test\n",
    "y_pred = model1.predict(X_test)\n",
    "\n",
    "print(y_true.shape)\n",
    "y_true = np.argmax(y_true, axis=-1)\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "y_true = y_true.flatten()\n",
    "y_pred = y_pred.flatten()\n",
    "temp = [] \n",
    "temp_pred = []\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i] not in punctuation_tags_idx and y_true[i] != 0:\n",
    "        temp.append(y_true[i])\n",
    "        temp_pred.append(y_pred[i])\n",
    "tag_true = []\n",
    "tag_pred = []\n",
    "res = {}\n",
    "for el in tag2idx.keys():\n",
    "    tag_true = []\n",
    "    tag_pred = []\n",
    "    for i in range(len(temp)):\n",
    "        if temp[i] == tag2idx.get(el) and tag2idx.get(el) not in punctuation_tags_idx:\n",
    "            tag_true.append(temp[i])\n",
    "            tag_pred.append(temp_pred[i])\n",
    "    if len(tag_pred) != 0 and len(tag_true) != 0:\n",
    "        \n",
    "        print(f\"Score for the tag {el} is: {f1_score(tag_true, tag_pred, average='macro')}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I print X_test as a sentence, decoded\n",
    "i = 0\n",
    "#print(test_sentences[i])\n",
    "#print(sentence_tokenizer.sequences_to_texts(X_test[i:i+1]))\n",
    "#print(test[150][0:30])\n",
    "print(\"Original sentence: \", test_sentences[0])\n",
    "print(\"Its label: \", test_tag_sentences[0])\n",
    "\n",
    "y_pred = model1.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "n_sentences = y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['inc  san antonio  texas  said it bought million shares  or about 18 %  of its common stock from an shareholder for $ a share  or $ 99 million ']\n",
      "['nns', 'vb', 'wdt', 'wdt', 'wdt', 'wdt', 'wdt', 'wdt', 'wdt', 'wdt', 'wdt', 'wdt', 'wdt', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'md', 'prp', 'prp', 'prp', 'prp', 'prp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp']\n",
      "['nnp', 'nnp', 'nnp', ',', 'nnp', 'nnp', ',', 'nnp', ',', 'vbd', 'prp', 'vbd', 'cd', 'cd', 'nns', ',', 'cc', 'in', 'cd', 'nn', ',', 'in', 'prp$', 'jj', 'nn', 'in', 'dt', 'jj', 'nn', 'in', '$', 'cd', 'dt', 'nn', ',', 'cc', '$', 'cd', 'cd', '.']\n",
      "\n",
      "['the move boosts chairman s stake to 20 % from % and may help prevent martin from making a run at the concern ']\n",
      "['ex', 'ex', 'vbz', 'wdt', 'wdt', 'wdt', 'wdt', 'wdt', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'rp', 'rp', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'rp', '#', 'rp', 'rp', 'rp']\n",
      "['dt', 'nn', 'vbz', 'nnp', 'nnp', 'nnp', 'nnp', 'pos', 'nn', 'to', 'cd', 'nn', 'in', 'cd', 'nn', 'cc', 'md', 'vb', 'vb', 'nnp', 'nnp', 'in', 'vbg', 'dt', 'nn', 'in', 'dt', 'nns', 'nn', '.']\n",
      "\n",
      "['mr already is seeking to mr as chairman of corp  an affiliate ']\n",
      "['pos', 'vbz', 'vbz', 'vbz', 'vbz', 'vbz', 'vbz', 'vbz', 'vbz', 'wdt', 'wdt', 'rp', 'wdt', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp']\n",
      "['nnp', 'nnp', 'rb', 'vbz', 'vbg', 'to', 'vb', 'nnp', 'nnp', 'in', 'nn', 'in', 'nnp', 'nnp', ',', 'dt', 'nnp', 'nn', '.']\n",
      "\n",
      "['the action followed by one day an announcement that it will retain an investment banker to alternatives `` to shareholder value   including the possible sale of the company ']\n",
      "['prp', 'wp$', 'prp', 'prp', 'cd', 'cd', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'vbz', 'vbz', 'vbz', 'vbz', 'vbz', 'cd', 'cd', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', '#']\n",
      "['dt', 'nn', 'vbn', 'in', 'cd', 'nn', 'dt', 'nnp', 'nn', 'in', 'prp', 'md', 'vb', 'dt', 'nn', 'nn', 'to', 'vb', 'nns', '``', 'to', 'vb', 'nn', 'nn', ',', \"''\", 'vbg', 'dt', 'jj', 'nn', 'in', 'dt', 'nn', '.']\n",
      "\n",
      "['in new york stock exchange composite trading yesterday  shares rose 375 cents to close at $ ']\n",
      "['prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp']\n",
      "['in', 'nnp', 'nnp', 'nnp', 'nnp', 'jj', 'nn', 'nn', ',', 'nnp', 'nns', 'vbd', 'cd', 'nns', 'to', 'vb', 'in', '$', 'cd', '.']\n",
      "\n",
      "['mr declined to what prompted the recent moves  saying they are meant only to shareholders when `` the company is on a roll ']\n",
      "['cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'wp$', 'wp$', 'wp$', 'wp$', 'wp$', 'wp$', 'wp$', '#', '#', '#', 'prp', 'prp', '#', 'prp', 'prp', 'prp', 'prp', '#', '#', '#', '#']\n",
      "['nnp', 'nnp', 'vbd', 'to', 'vb', 'wp', 'vbd', 'dt', 'jj', 'nns', ',', 'vbg', 'prp', 'vbp', 'vbn', 'rb', 'to', 'vb', 'nns', 'wrb', '``', 'dt', 'nn', 'vbz', 'in', 'dt', 'nn', '.']\n",
      "\n",
      "[' he added  `` this has nothing to do with marty and it is not designed  particularly  to take the company private ']\n",
      "['cd', 'wp$', 'wp$', 'wp$', 'wp$', 'wp$', 'wp$', 'wp$', 'wp$', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'prp', '#', 'prp', 'rp', '#']\n",
      "[\"''\", 'prp', 'vbd', ',', '``', 'dt', 'vbz', 'nn', 'to', 'vb', 'in', 'nnp', 'nnp', 'cc', 'prp', 'vbz', 'rb', 'vbn', ',', 'rb', ',', 'to', 'vb', 'dt', 'nn', 'jj', '.']\n",
      "\n",
      "[' but mr said the buyback  and the price paid  prove that mr is running scared ']\n",
      "['``', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'vbz', 'vbz', 'vbz', 'vbz', 'vbz', 'vbz', 'prp', 'prp', 'prp', 'prp']\n",
      "[\"''\", 'cc', 'nnp', 'nnp', 'vbd', 'dt', 'nn', ',', 'cc', 'dt', 'jj', 'nn', 'vbn', ',', 'vbp', 'in', 'nnp', 'nnp', 'vbz', 'vbg', 'jj', '.']\n",
      "\n",
      "['dow jones & co said it extended its $ offer for inc common stock until 5 nov 9 ']\n",
      "['prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'rp', 'rp']\n",
      "['nnp', 'nnp', 'cc', 'nnp', 'vbd', 'prp', 'vbd', 'prp$', '$', 'jj', 'nn', 'in', 'nnp', 'nnp', 'jj', 'nn', 'in', 'cd', 'nn', 'nnp', 'nnp', 'cd', '.']\n",
      "\n",
      "['the offer  valued at about $ million for the 33 % of that dow jones does nt already own  had been set to expire nov 6 ']\n",
      "['nns', 'vbp', 'uh', 'vbp', 'wdt', 'wdt', 'wdt', 'wdt', 'rp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'cd', 'cd', 'cd', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp']\n",
      "['dt', 'nn', ',', 'vbn', 'in', 'in', '$', 'cd', 'cd', 'in', 'dt', 'cd', 'nn', 'in', 'nnp', 'in', 'nnp', 'nnp', 'vbz', 'rb', 'rb', 'vbn', ',', 'vbd', 'vbn', 'vbn', 'to', 'vb', 'nnp', 'cd', '.']\n",
      "\n",
      "['dow jones  which owns about 64 million of s million common shares outstanding  said that about shares have been under its offer ']\n",
      "['prp', 'vb', 'vb', 'wdt', 'wdt', 'wdt', 'wdt', 'wdt', 'prp', 'prp', 'prp', 'prp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp']\n",
      "['nnp', 'nnp', ',', 'wdt', 'vbz', 'in', 'cd', 'cd', 'in', 'nnp', 'pos', 'cd', 'cd', 'jj', 'nns', 'jj', ',', 'vbd', 'in', 'in', 'cd', 'nns', 'vbp', 'vbn', 'vbn', 'in', 'prp$', 'nn', '.']\n",
      "\n",
      "['s two independent directors have rejected the offer as inadequate ']\n",
      "['cd', 'wp$', 'wp$', 'wp$', 'wp$', 'wp$', 'wp$', 'rp', 'rp', 'rp', 'rp', '#']\n",
      "['nnp', 'pos', 'cd', 'jj', 'nns', 'vbp', 'vbn', 'dt', 'nn', 'in', 'jj', '.']\n",
      "\n",
      "['in composite trading on the new york stock exchange  shares closed at $  up 125 cents ']\n",
      "['prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'wdt', 'wdt', 'rp', 'rp', 'rp', 'rp', 'rp', 'rp']\n",
      "['in', 'jj', 'nn', 'in', 'dt', 'nnp', 'nnp', 'nnp', 'nnp', ',', 'nnp', 'nns', 'vbd', 'in', '$', 'cd', ',', 'rb', 'cd', 'nns', '.']\n",
      "\n",
      "['provides an electronic financial information network ']\n",
      "[\"''\", 'nnp', 'nnp', 'nnp', 'nnp', 'nnp', 'rp', 'rp']\n",
      "['nnp', 'vbz', 'dt', 'jj', 'jj', 'nn', 'nn', '.']\n",
      "\n",
      "['dow jones publishes the wall street journal  s magazine  and community newspapers and operates financial news services and computer data bases ']\n",
      "['prp', 'prp', 'cd', 'cd', 'cd', 'prp', 'cd', 'cd', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'rp', 'rp', 'rp']\n",
      "['nnp', 'nnp', 'vbz', 'nnp', 'nnp', 'nnp', 'nnp', ',', 'nnp', 'pos', 'nn', ',', 'cc', 'nn', 'nns', 'cc', 'vbz', 'jj', 'nn', 'nns', 'cc', 'nn', 'nns', 'nns', '.']\n",
      "\n",
      "['rockwell international corp reported flat operating earnings for the fourth quarter ended sept 30 ']\n",
      "['prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'rp']\n",
      "['nnp', 'nnp', 'nnp', 'vbd', 'jj', 'nn', 'nns', 'in', 'dt', 'jj', 'nn', 'vbd', 'nnp', 'cd', '.']\n",
      "\n",
      "['the aerospace  automotive supply  electronics and concern also indicated that the first half of fiscal 1990 could be rough ']\n",
      "['prp', 'prp', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'wp$', 'wp$', 'wp$', '#', '#', '#', '#', '#', '#', '#']\n",
      "['dt', 'nn', ',', 'jj', 'nn', ',', 'nns', 'cc', 'nn', 'nn', 'rb', 'vbd', 'in', 'dt', 'jj', 'dt', 'in', 'jj', 'cd', 'md', 'vb', 'jj', '.']\n",
      "\n",
      "['in an interview  donald  chairman  said profit certainly would the past year s  primarily because of weakness in the and markets ']\n",
      "['cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'ex', 'cd', 'cd', 'wp$', 'wp$', 'wp$', 'wp$', '#', '#', '#', '#', '#', '#', 'prp', 'prp', 'prp', 'prp', '#']\n",
      "['in', 'dt', 'nn', ',', 'nnp', 'nnp', ',', 'nn', ',', 'vbd', 'jj', 'nn', 'rb', 'md', 'vb', 'dt', 'jj', 'nn', 'pos', ',', 'rb', 'in', 'in', 'nn', 'in', 'dt', 'nn', 'cc', 'nn', 'nns', '.']\n",
      "\n",
      "['still  he added  if the industrial sector remains relatively stable  rockwell should be able to in the second half and about equal fiscal 1989 s operating profit of $ million ']\n",
      "['cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'cd', 'prp', 'prp', 'prp', 'prp', 'prp', 'cd', 'cd', 'prp', 'nns', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'md', 'md', 'md', 'md', 'md', 'prp', 'prp', 'prp', 'prp', 'rp', 'rp', 'rp', 'rp']\n",
      "['rb', ',', 'prp', 'vbd', ',', 'in', 'dt', 'jj', 'nn', 'vbz', 'rb', 'jj', ',', 'nnp', 'md', 'vb', 'jj', 'to', 'vb', 'in', 'dt', 'jj', 'dt', 'cc', 'in', 'jj', 'jj', 'cd', 'pos', 'nn', 'nn', 'in', '$', 'cd', 'cd', '.']\n",
      "\n",
      "['for fiscal 1989 s fourth quarter  rockwell s net income totaled $ million  or 50 cents a share ']\n",
      "['jjs', 'jjs', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'prp', 'rp', 'rp', 'rp', 'rp']\n",
      "['in', 'jj', 'cd', 'pos', 'jj', 'nn', ',', 'nnp', 'pos', 'jj', 'nn', 'vbd', '$', 'cd', 'cd', ',', 'cc', 'cd', 'nns', 'dt', 'nn', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for i in range(n_sentences):\n",
    "for i in range(20):\n",
    "    sentence = str(sentence_tokenizer.sequences_to_texts(X_test[i:i+1])[0])\n",
    "    sentence = sentence.replace('<UNK> ', '')\n",
    "    for el in punctuation_tags:\n",
    "        sentence = sentence.replace(el, '')\n",
    "    print([sentence])\n",
    "    print([idx2tag[idx] for idx in y_pred[i] if idx != 0])\n",
    "    print([idx2tag[idx] for idx in np.argmax(Y_test[i], axis=-1) if idx != 0])\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
