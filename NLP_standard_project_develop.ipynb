{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Standard Project:\n",
    "\n",
    "- Students: **Matteo Belletti**, **Alessandro Pasi**, **Stricescu Razvan Ciprian**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import pandas as pd\n",
    "import json\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AutoModel, AutoTokenizer, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 4000\n",
      "Example of a sample: {'episode': 'utterance_0', 'speakers': ['Chandler', 'The Interviewer', 'Chandler', 'The Interviewer', 'Chandler'], 'emotions': ['neutral', 'neutral', 'neutral', 'neutral', 'surprise'], 'utterances': [\"also I was the point person on my company's transition from the KL-5 to GR-6 system.\", \"You must've had your hands full.\", 'That I did. That I did.', \"So let's talk a little bit about your duties.\", 'My duties?  All right.'], 'triggers': [0.0, 0.0, 0.0, 1.0, 0.0]}\n"
     ]
    }
   ],
   "source": [
    "# open json in project_data_MELD folder\n",
    "with open('project_data_MELD/MELD_train_efr.json') as f:\n",
    "    data = json.load(f)\n",
    "print(f\"Number of samples: {len(data)}\")\n",
    "print(f\"Example of a sample: {data[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (4000, 4)\n",
      "Dataframe columns: Index(['speakers', 'emotions', 'utterances', 'triggers'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Convert data to pandas dataframe\n",
    "df = pd.DataFrame(data)\n",
    "# drop episode and speakers columns\n",
    "df = df.drop(columns=['episode'])\n",
    "print(f\"Dataframe shape: {df.shape}\")\n",
    "print(f\"Dataframe columns: {df.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing nan values to zeros in order to avoid errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"triggers\"] = df[\"triggers\"].apply(lambda x: [0 if elem != 1 and elem != 0 else elem for elem in x])\n",
    "df[\"triggers\"][3359]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into train, validation and test sets with a 80-10-10 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, temp = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_val, df_test = train_test_split(temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3200, 4)\n",
      "Val shape: (400, 4)\n",
      "Test shape: (400, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train shape: {df_train.shape}\")\n",
    "print(f\"Val shape: {df_val.shape}\")\n",
    "print(f\"Test shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As baselines models we need to implement a random model and a majority class model for emotions and triggers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neutral': 12066, 'joy': 4986, 'surprise': 3664, 'anger': 3203, 'sadness': 2108, 'fear': 889, 'disgust': 848}\n"
     ]
    }
   ],
   "source": [
    "# first we create a dictionary of all emotions with their corresponding occurences\n",
    "emotions_dict = {}\n",
    "for emotions in df_train[\"emotions\"]:\n",
    "    for emotion in emotions:\n",
    "        if emotion in emotions_dict:\n",
    "            emotions_dict[emotion] += 1\n",
    "        else:\n",
    "            emotions_dict[emotion] = 1\n",
    "\n",
    "# then we sort the dictionary by occurences\n",
    "emotions_dict = {k: v for k, v in sorted(emotions_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "print(emotions_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the distribution of emotions could also be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the emotions distribution as histogram\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(emotions_dict.keys(), emotions_dict.values(), color='blue')\n",
    "plt.title(\"Emotions distribution in the training set\")\n",
    "plt.xlabel(\"Emotions\")\n",
    "plt.ylabel(\"Number of occurences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also implement some text processing techniques such as stemming, lemmatization, stop words removal, etc. \n",
    "\n",
    "In this case we will use nltk library for lemmatization and stop words removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Matteo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Matteo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Matteo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Matteo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "#stop_words = set(stopwords.words('english'))\n",
    "bad_symbols = re.compile('[^a-z ]')\n",
    "punct = string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to use lower case because we are going to use bert uncased models further on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = bad_symbols.sub('', text)\n",
    "    text = word_tokenize(text)\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train, val and test sets after preprocessing: \n",
      "Train shape: (3200, 4)\n",
      "Val shape: (400, 4)\n",
      "Test shape: (400, 4)\n"
     ]
    }
   ],
   "source": [
    "baseline_train = df_train.copy()\n",
    "baseline_train[\"utterances\"] = baseline_train[\"utterances\"].apply(lambda x: [preprocess_text(elem) for elem in x])\n",
    "baseline_test = df_test.copy()\n",
    "baseline_test[\"utterances\"] = baseline_test[\"utterances\"].apply(lambda x: [preprocess_text(elem) for elem in x])\n",
    "baseline_val = df_val.copy()\n",
    "baseline_val[\"utterances\"] = baseline_val[\"utterances\"].apply(lambda x: [preprocess_text(elem) for elem in x])\n",
    "print(\"Shape of train, val and test sets after preprocessing: \")\n",
    "print(f\"Train shape: {baseline_train.shape}\")\n",
    "print(f\"Val shape: {baseline_val.shape}\")\n",
    "print(f\"Test shape: {baseline_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the TF-IDF vectorizer we need to split the utterances into single sentences, likewise the emotions and triggers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(df, y_label):\n",
    "    X = []\n",
    "    y = []\n",
    "    for index, row in df.iterrows():\n",
    "        for i in range(len(row[\"utterances\"])):\n",
    "            X.append(row[\"utterances\"][i])\n",
    "            y.append(row[y_label][i])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape after splitting: 27764\n",
      "Val shape after splitting: 3678\n",
      "Test shape after splitting: 3558\n"
     ]
    }
   ],
   "source": [
    "# Emotions baseline\n",
    "x_train_base, y_train_emotions = splitter(baseline_train, \"emotions\")\n",
    "x_val_base, y_val_emotions = splitter(baseline_val, \"emotions\")\n",
    "x_test_base, y_test_emotions = splitter(baseline_test, \"emotions\")\n",
    "\n",
    "# Triggers baseline\n",
    "_ , y_train_triggers = splitter(baseline_train, \"triggers\")\n",
    "_ , y_val_triggers = splitter(baseline_val, \"triggers\")\n",
    "_ , y_test_triggers = splitter(baseline_test, \"triggers\")\n",
    "\n",
    "print(f\"Train shape after splitting: {len(x_train_base)}\")\n",
    "print(f\"Val shape after splitting: {len(x_val_base)}\")\n",
    "print(f\"Test shape after splitting: {len(x_test_base)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a tokenizer we use TfidfVectorizer from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape after vectorization: (27764, 5142)\n",
      "Val shape after vectorization: (3678, 5142)\n",
      "Test shape after vectorization: (3558, 5142)\n",
      "Size of the vocabulary: 5142\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "x_train_base = vectorizer.fit_transform(x_train_base)\n",
    "x_val_base = vectorizer.transform(x_val_base)\n",
    "x_test_base = vectorizer.transform(x_test_base)\n",
    "\n",
    "print(f\"Train shape after vectorization: {x_train_base.shape}\")\n",
    "print(f\"Val shape after vectorization: {x_val_base.shape}\")\n",
    "print(f\"Test shape after vectorization: {x_test_base.shape}\")\n",
    "\n",
    "print(f\"Size of the vocabulary: {len(vectorizer.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation function that returns the classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(Y_test, Y_pred):\n",
    "    report = classification_report(Y_test, Y_pred, zero_division=0)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the dummy classifier for emotions and triggers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf_majority_emotions = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf_random_emotions = DummyClassifier(strategy=\"uniform\")\n",
    "\n",
    "dummy_clf_majority_triggers = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf_random_triggers = DummyClassifier(strategy=\"uniform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and evaluation of the classifiers fitted on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority classifier for emotions: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00       369\n",
      "     disgust       0.00      0.00      0.00       101\n",
      "        fear       0.00      0.00      0.00       109\n",
      "         joy       0.00      0.00      0.00       663\n",
      "     neutral       0.44      1.00      0.61      1572\n",
      "     sadness       0.00      0.00      0.00       258\n",
      "    surprise       0.00      0.00      0.00       486\n",
      "\n",
      "    accuracy                           0.44      3558\n",
      "   macro avg       0.06      0.14      0.09      3558\n",
      "weighted avg       0.20      0.44      0.27      3558\n",
      "\n",
      "-------------------------------------------------------\n",
      "Random classifier for emotions: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.09      0.12      0.11       369\n",
      "     disgust       0.03      0.15      0.05       101\n",
      "        fear       0.02      0.10      0.04       109\n",
      "         joy       0.22      0.18      0.20       663\n",
      "     neutral       0.46      0.14      0.22      1572\n",
      "     sadness       0.07      0.14      0.09       258\n",
      "    surprise       0.17      0.19      0.18       486\n",
      "\n",
      "    accuracy                           0.15      3558\n",
      "   macro avg       0.15      0.15      0.13      3558\n",
      "weighted avg       0.28      0.15      0.18      3558\n",
      "\n",
      "-------------------------------------------------------\n",
      "Majority classifier for triggers: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3027\n",
      "         1.0       0.00      0.00      0.00       531\n",
      "\n",
      "    accuracy                           0.85      3558\n",
      "   macro avg       0.43      0.50      0.46      3558\n",
      "weighted avg       0.72      0.85      0.78      3558\n",
      "\n",
      "-------------------------------------------------------\n",
      "Random classifier for triggers: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.50      0.63      3027\n",
      "         1.0       0.15      0.52      0.24       531\n",
      "\n",
      "    accuracy                           0.50      3558\n",
      "   macro avg       0.51      0.51      0.44      3558\n",
      "weighted avg       0.75      0.50      0.57      3558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Emotions baseline\n",
    "dummy_clf_majority_emotions.fit(x_train_base, y_train_emotions)\n",
    "dummy_clf_random_emotions.fit(x_train_base, y_train_emotions)\n",
    "\n",
    "y_pred_majority_emotions = dummy_clf_majority_emotions.predict(x_test_base)\n",
    "y_pred_random_emotions = dummy_clf_random_emotions.predict(x_test_base)\n",
    "print(\"Majority classifier for emotions: \\n\")\n",
    "print(evaluate(y_test_emotions, y_pred_majority_emotions))\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"Random classifier for emotions: \\n\")\n",
    "print(evaluate(y_test_emotions, y_pred_random_emotions))\n",
    "print(\"-------------------------------------------------------\")\n",
    "\n",
    "# Triggers baseline\n",
    "dummy_clf_majority_triggers.fit(x_train_base, y_train_triggers)\n",
    "dummy_clf_random_triggers.fit(x_train_base, y_train_triggers)\n",
    "\n",
    "y_pred_majority_triggers = dummy_clf_majority_triggers.predict(x_test_base)\n",
    "y_pred_random_triggers = dummy_clf_random_triggers.predict(x_test_base)\n",
    "print(\"Majority classifier for triggers: \\n\")\n",
    "print(evaluate(y_test_triggers, y_pred_majority_triggers))\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"Random classifier for triggers: \\n\")\n",
    "print(evaluate(y_test_triggers, y_pred_random_triggers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences distribution: [9, 2, 3, 14, 4, 10, 8, 10, 19, 17, 4, 4, 6, 8, 10, 3, 9, 8, 22, 7, 9, 9, 12, 11, 7, 8, 4, 4, 8, 8, 5, 7, 14, 12, 7, 3, 8, 4, 13, 10, 13, 9, 3, 4, 14, 16, 5, 3, 11, 11, 3, 6, 5, 3, 15, 4, 6, 13, 7, 10, 7, 3, 4, 5, 22, 19, 8, 9, 8, 8, 3, 15, 6, 9, 6, 12, 3, 6, 19, 5, 7, 11, 6, 5, 4, 17, 6, 3, 3, 6, 12, 14, 4, 14, 5, 14, 14, 6, 4, 8, 4, 12, 18, 3, 5, 4, 4, 14, 12, 4, 5, 3, 11, 3, 10, 5, 13, 8, 5, 10, 10, 9, 6, 3, 9, 14, 9, 7, 5, 15, 16, 3, 9, 21, 4, 17, 6, 12, 9, 6, 10, 12, 2, 6, 9, 17, 17, 8, 15, 12, 24, 4, 16, 14, 19, 4, 4, 11, 4, 4, 8, 9, 19, 16, 6, 8, 4, 2, 8, 4, 8, 9, 15, 18, 19, 5, 18, 5, 14, 11, 5, 6, 5, 11, 3, 16, 5, 16, 10, 8, 3, 16, 8, 11, 20, 8, 10, 5, 4, 11, 16, 4, 9, 14, 8, 14, 8, 13, 4, 2, 10, 7, 14, 5, 6, 5, 6, 11, 15, 11, 5, 3, 6, 9, 3, 7, 6, 8, 8, 19, 6, 8, 3, 9, 6, 4, 4, 3, 9, 5, 8, 5, 8, 8, 7, 12, 16, 9, 9, 3, 4, 5, 9, 7, 18, 3, 3, 14, 10, 5, 4, 2, 4, 6, 3, 10, 8, 7, 6, 3, 5, 5, 8, 3, 8, 7, 5, 12, 7, 21, 6, 16, 10, 15, 4, 13, 12, 8, 8, 13, 16, 8, 9, 10, 4, 13, 11, 14, 6, 11, 7, 14, 3, 3, 3, 5, 8, 3, 5, 3, 7, 8, 7, 6, 13, 6, 8, 5, 14, 5, 6, 19, 9, 5, 3, 8, 9, 8, 18, 13, 3, 14, 8, 20, 12, 12, 16, 9, 4, 15, 12, 7, 11, 8, 12, 12, 7, 7, 20, 7, 7, 15, 13, 5, 6, 11, 3, 3, 4, 16, 8, 5, 11, 11, 8, 15, 9, 9, 10, 4, 3, 4, 14, 5, 19, 13, 11, 2, 5, 9, 3, 9, 9, 7, 16, 11, 3, 5, 19, 11, 6, 3, 12, 6, 9, 4, 5, 10, 14, 15, 7, 4, 8, 5, 10, 5, 10, 10, 3, 6, 5, 7, 7, 10, 2, 4, 6, 10, 4, 12, 7, 13, 5, 14, 12, 14, 11, 21, 8, 7, 10, 8, 17, 19, 2, 6, 3, 6, 10, 3, 10, 8, 16, 8, 2, 5, 12, 15, 11, 13, 7, 5, 6, 2, 9, 5, 19, 10, 12, 9, 12, 3, 7, 6, 5, 5, 13, 15, 12, 4, 9, 6, 15, 9, 7, 10, 6, 16, 12, 3, 6, 6, 9, 9, 6, 14, 12, 16, 10, 4, 6, 12, 18, 19, 4, 8, 4, 6, 7, 13, 5, 4, 8, 8, 14, 5, 18, 12, 21, 6, 5, 7, 10, 4, 5, 13, 6, 6, 3, 6, 5, 6, 18, 2, 3, 14, 9, 4, 2, 14, 15, 7, 13, 7, 8, 3, 4, 5, 5, 5, 12, 7, 10, 5, 5, 5, 3, 11, 12, 9, 4, 10, 6, 11, 11, 5, 13, 9, 17, 7, 4, 7, 3, 10, 6, 3, 7, 16, 5, 5, 3, 8, 7, 8, 5, 3, 13, 18, 6, 13, 15, 10, 13, 11, 12, 6, 7, 7, 10, 3, 6, 6, 6, 12, 22, 6, 16, 10, 8, 10, 9, 3, 8, 8, 3, 11, 5, 11, 8, 8, 3, 12, 15, 4, 4, 3, 12, 9, 8, 9, 2, 7, 6, 6, 9, 7, 5, 9, 7, 6, 11, 3, 14, 5, 17, 9, 7, 14, 4, 6, 8, 6, 3, 4, 11, 8, 6, 7, 21, 6, 15, 3, 8, 9, 11, 11, 5, 16, 5, 2, 12, 4, 10, 12, 8, 6, 13, 17, 4, 6, 9, 6, 19, 6, 9, 7, 10, 11, 9, 3, 15, 7, 12, 8, 11, 22, 14, 11, 6, 3, 11, 5, 4, 7, 12, 3, 10, 11, 14, 13, 2, 10, 4, 6, 5, 11, 15, 3, 10, 7, 14, 8, 10, 6, 4, 7, 15, 9, 3, 6, 4, 8, 11, 6, 12, 7, 9, 11, 7, 4, 12, 13, 14, 6, 4, 12, 6, 3, 7, 11, 11, 3, 4, 10, 2, 7, 8, 13, 10, 4, 3, 8, 12, 7, 11, 9, 14, 11, 8, 3, 10, 4, 4, 9, 3, 5, 10, 5, 20, 8, 13, 15, 10, 12, 5, 4, 7, 8, 3, 7, 10, 7, 16, 7, 5, 9, 10, 4, 3, 19, 19, 8, 6, 16, 3, 6, 6, 9, 6, 8, 6, 8, 4, 3, 9, 4, 14, 10, 10, 7, 6, 5, 16, 3, 8, 12, 10, 6, 7, 15, 4, 14, 3, 5, 11, 11, 8, 4, 4, 11, 9, 7, 17, 10, 10, 9, 6, 7, 4, 11, 5, 12, 5, 18, 8, 5, 7, 6, 8, 6, 7, 18, 8, 6, 15, 8, 8, 4, 10, 12, 7, 4, 4, 4, 12, 10, 8, 10, 13, 22, 16, 11, 3, 2, 3, 6, 9, 3, 12, 12, 3, 14, 3, 11, 4, 6, 3, 16, 18, 8, 5, 16, 7, 4, 7, 6, 13, 18, 7, 17, 9, 18, 9, 11, 13, 14, 5, 9, 9, 5, 21, 3, 3, 9, 8, 11, 13, 4, 15, 14, 20, 4, 8, 12, 8, 3, 9, 9, 4, 19, 8, 3, 6, 10, 11, 13, 6, 4, 6, 9, 3, 6, 15, 6, 3, 3, 4, 4, 4, 17, 7, 16, 3, 9, 15, 21, 15, 18, 10, 14, 6, 10, 18, 4, 10, 6, 6, 3, 8, 6, 14, 7, 6, 2, 6, 10, 3, 5, 6, 5, 8, 10, 11, 5, 7, 13, 13, 4, 16, 11, 12, 6, 5, 6, 6, 13, 6, 11, 11, 15, 6, 6, 7, 8, 9, 5, 9, 4, 7, 5, 4, 17, 9, 10, 12, 3, 8, 4, 3, 15, 6, 9, 6, 8, 4, 12, 3, 8, 16, 2, 11, 9, 4, 5, 2, 6, 15, 9, 5, 3, 7, 8, 9, 8, 5, 6, 6, 8, 12, 4, 5, 13, 10, 11, 16, 18, 10, 4, 11, 8, 5, 9, 9, 4, 13, 4, 3, 7, 14, 19, 8, 10, 18, 4, 8, 3, 14, 3, 8, 20, 6, 3, 7, 7, 16, 14, 8, 7, 8, 9, 6, 5, 5, 13, 7, 10, 6, 4, 4, 8, 10, 4, 4, 6, 10, 16, 6, 8, 4, 19, 3, 2, 2, 4, 12, 5, 7, 4, 20, 16, 10, 4, 6, 8, 16, 9, 7, 10, 9, 9, 11, 17, 17, 11, 4, 3, 17, 7, 3, 10, 2, 4, 7, 10, 14, 6, 6, 4, 5, 9, 5, 12, 8, 12, 11, 7, 6, 6, 4, 8, 3, 6, 3, 3, 9, 3, 5, 8, 6, 12, 5, 10, 6, 15, 12, 14, 17, 14, 17, 17, 22, 12, 8, 14, 10, 17, 19, 4, 12, 7, 8, 2, 10, 17, 4, 6, 4, 8, 6, 23, 9, 6, 9, 3, 4, 11, 5, 9, 9, 10, 11, 18, 9, 6, 5, 17, 12, 9, 20, 20, 3, 6, 19, 14, 11, 15, 4, 9, 6, 4, 20, 9, 15, 5, 6, 8, 8, 8, 23, 10, 8, 7, 11, 10, 12, 9, 12, 13, 4, 8, 6, 11, 11, 14, 16, 9, 10, 4, 4, 7, 12, 5, 9, 8, 7, 9, 6, 3, 3, 17, 14, 7, 20, 7, 6, 11, 4, 6, 14, 13, 7, 9, 3, 4, 4, 15, 4, 4, 3, 10, 5, 10, 3, 6, 5, 9, 7, 3, 4, 6, 4, 4, 4, 3, 7, 13, 6, 4, 4, 5, 7, 3, 10, 10, 9, 9, 7, 6, 5, 11, 10, 11, 8, 6, 12, 10, 4, 4, 8, 9, 14, 21, 11, 4, 7, 3, 7, 15, 3, 6, 14, 5, 19, 7, 5, 4, 8, 13, 6, 14, 22, 5, 3, 11, 4, 3, 14, 5, 17, 6, 8, 5, 9, 4, 6, 16, 3, 3, 10, 21, 10, 17, 17, 6, 13, 4, 4, 10, 4, 12, 12, 7, 13, 15, 12, 7, 6, 14, 7, 2, 7, 5, 14, 6, 3, 4, 5, 6, 7, 6, 16, 9, 4, 9, 7, 12, 5, 5, 4, 8, 13, 4, 15, 7, 11, 6, 17, 3, 12, 9, 14, 11, 15, 11, 10, 7, 13, 11, 4, 3, 7, 7, 4, 21, 5, 10, 4, 16, 5, 9, 13, 4, 14, 7, 5, 5, 10, 10, 2, 6, 11, 4, 6, 15, 14, 9, 13, 8, 7, 3, 4, 13, 7, 5, 3, 8, 3, 11, 16, 10, 18, 13, 8, 12, 8, 5, 3, 11, 2, 11, 9, 5, 15, 11, 2, 13, 4, 12, 11, 12, 9, 9, 15, 7, 7, 16, 8, 5, 9, 10, 3, 4, 5, 6, 16, 3, 6, 14, 9, 6, 5, 9, 9, 3, 11, 5, 6, 8, 5, 7, 7, 4, 15, 5, 9, 21, 9, 8, 9, 6, 3, 3, 10, 3, 11, 5, 6, 8, 5, 18, 3, 9, 16, 10, 7, 11, 19, 4, 7, 9, 13, 15, 14, 6, 15, 10, 2, 12, 12, 7, 5, 11, 5, 5, 12, 4, 18, 13, 5, 3, 4, 17, 3, 5, 13, 7, 6, 5, 6, 9, 17, 3, 7, 3, 12, 14, 12, 4, 3, 8, 4, 4, 4, 15, 6, 11, 8, 5, 9, 18, 9, 10, 9, 14, 15, 3, 12, 6, 15, 10, 7, 4, 15, 11, 4, 9, 20, 6, 13, 6, 8, 8, 17, 4, 21, 5, 7, 2, 9, 10, 2, 7, 9, 6, 4, 5, 5, 6, 6, 4, 13, 14, 17, 6, 14, 17, 7, 8, 18, 8, 16, 4, 9, 9, 10, 21, 11, 15, 3, 11, 18, 10, 6, 2, 6, 6, 7, 10, 3, 6, 11, 5, 5, 9, 3, 6, 6, 7, 6, 7, 10, 3, 5, 9, 9, 11, 4, 3, 4, 9, 7, 11, 13, 4, 11, 5, 5, 4, 10, 3, 13, 7, 14, 13, 6, 5, 8, 7, 15, 4, 3, 7, 6, 10, 6, 7, 6, 12, 12, 3, 6, 4, 17, 12, 13, 9, 7, 4, 6, 10, 14, 8, 11, 10, 6, 6, 3, 15, 7, 4, 10, 4, 16, 3, 18, 5, 10, 9, 3, 16, 11, 9, 9, 12, 18, 11, 10, 11, 7, 10, 9, 10, 6, 14, 4, 5, 12, 3, 15, 12, 3, 8, 3, 16, 14, 18, 12, 7, 8, 14, 5, 5, 16, 4, 4, 9, 4, 7, 6, 4, 12, 6, 7, 5, 8, 10, 5, 12, 11, 2, 8, 5, 11, 5, 3, 9, 3, 12, 5, 5, 20, 3, 15, 4, 18, 2, 14, 12, 7, 17, 8, 16, 11, 5, 5, 4, 7, 8, 7, 2, 2, 9, 10, 13, 8, 7, 5, 11, 3, 11, 13, 3, 4, 10, 13, 11, 7, 3, 14, 13, 7, 10, 2, 4, 4, 17, 13, 3, 5, 14, 13, 11, 8, 8, 14, 5, 10, 3, 9, 16, 9, 9, 16, 12, 8, 14, 13, 3, 3, 10, 8, 10, 6, 5, 5, 16, 5, 9, 7, 12, 7, 5, 12, 18, 5, 12, 10, 3, 14, 10, 10, 11, 17, 4, 13, 9, 6, 10, 19, 15, 17, 6, 18, 3, 9, 3, 6, 12, 6, 9, 3, 9, 9, 10, 11, 4, 15, 5, 12, 13, 8, 7, 9, 14, 3, 9, 21, 3, 5, 21, 4, 4, 12, 4, 3, 5, 18, 10, 8, 13, 6, 12, 6, 14, 6, 8, 5, 3, 19, 5, 9, 5, 12, 7, 16, 8, 13, 5, 13, 7, 8, 8, 7, 11, 21, 7, 3, 5, 10, 6, 3, 11, 16, 6, 3, 15, 7, 6, 9, 7, 7, 9, 17, 9, 8, 13, 4, 6, 5, 4, 10, 8, 4, 14, 11, 5, 4, 14, 4, 7, 10, 3, 3, 3, 10, 10, 3, 3, 9, 5, 13, 6, 9, 11, 3, 4, 10, 5, 9, 6, 8, 11, 9, 8, 4, 8, 10, 5, 4, 5, 9, 8, 12, 17, 15, 20, 15, 7, 9, 3, 7, 11, 5, 18, 3, 10, 5, 8, 13, 10, 3, 17, 5, 3, 7, 10, 2, 5, 11, 11, 10, 4, 22, 9, 8, 5, 4, 7, 6, 8, 4, 5, 16, 9, 15, 11, 4, 14, 12, 11, 6, 7, 9, 7, 8, 7, 8, 15, 5, 9, 9, 3, 7, 5, 10, 21, 15, 12, 11, 3, 6, 16, 12, 13, 7, 15, 2, 4, 16, 14, 10, 18, 7, 16, 4, 13, 13, 7, 3, 5, 3, 13, 2, 6, 6, 4, 22, 8, 8, 14, 5, 5, 3, 8, 3, 2, 12, 6, 3, 8, 6, 5, 20, 19, 4, 6, 8, 4, 6, 8, 3, 3, 15, 5, 14, 5, 8, 11, 11, 16, 5, 6, 11, 12, 20, 6, 5, 16, 4, 13, 15, 3, 11, 5, 12, 5, 5, 19, 9, 13, 11, 5, 19, 4, 16, 13, 4, 24, 16, 10, 14, 3, 10, 13, 8, 3, 6, 11, 16, 5, 4, 10, 10, 13, 6, 8, 8, 5, 17, 12, 5, 4, 12, 3, 6, 2, 4, 12, 13, 4, 11, 8, 2, 15, 15, 3, 18, 12, 5, 6, 6, 6, 3, 3, 8, 11, 11, 9, 16, 7, 4, 4, 13, 7, 2, 10, 8, 9, 7, 10, 8, 2, 10, 7, 6, 11, 11, 2, 11, 5, 7, 14, 7, 13, 3, 6, 6, 2, 4, 9, 7, 18, 7, 3, 13, 11, 7, 8, 5, 7, 21, 8, 4, 4, 3, 12, 14, 5, 8, 9, 13, 6, 3, 6, 9, 12, 5, 3, 6, 17, 10, 10, 11, 5, 9, 7, 14, 14, 8, 10, 5, 5, 9, 6, 2, 3, 13, 13, 7, 12, 17, 8, 12, 7, 4, 10, 5, 4, 2, 9, 11, 3, 4, 15, 4, 6, 14, 10, 12, 12, 9, 12, 22, 6, 8, 4, 11, 16, 3, 7, 16, 18, 19, 11, 5, 12, 10, 10, 18, 9, 16, 10, 10, 18, 5, 16, 8, 3, 12, 6, 8, 18, 13, 18, 22, 6, 14, 17, 4, 4, 15, 24, 9, 5, 4, 6, 7, 7, 18, 6, 3, 5, 11, 6, 4, 4, 6, 5, 15, 8, 9, 14, 2, 6, 9, 11, 6, 18, 9, 3, 16, 5, 8, 4, 8, 10, 6, 18, 4, 5, 3, 4, 5, 9, 6, 8, 13, 4, 8, 8, 10, 10, 6, 8, 8, 6, 8, 3, 8, 11, 3, 4, 3, 7, 3, 14, 7, 16, 4, 13, 5, 12, 4, 17, 8, 15, 15, 3, 3, 9, 3, 12, 11, 11, 7, 4, 5, 15, 11, 2, 17, 17, 5, 4, 9, 3, 3, 7, 17, 20, 6, 18, 18, 6, 15, 19, 17, 4, 19, 12, 7, 18, 11, 3, 8, 3, 9, 5, 4, 6, 7, 5, 13, 6, 6, 4, 8, 7, 7, 3, 5, 12, 9, 6, 4, 8, 8, 8, 3, 17, 3, 11, 5, 8, 12, 5, 14, 8, 7, 5, 7, 10, 9, 6, 3, 6, 5, 3, 13, 9, 8, 6, 12, 12, 9, 7, 10, 8, 3, 7, 7, 21, 6, 14, 9, 16, 11, 17, 7, 10, 2, 8, 6, 12, 4, 6, 9, 11, 20, 15, 5, 9, 7, 7, 10, 16, 12, 7, 5, 11, 11, 5, 11, 7, 18, 4, 17, 15, 6, 8, 6, 3, 18, 7, 9, 6, 7, 8, 7, 12, 4, 18, 16, 8, 18, 3, 10, 8, 4, 16, 11, 9, 6, 5, 6, 4, 8, 3, 19, 9, 6, 2, 13, 6, 7, 9, 14, 11, 11, 4, 11, 3, 7, 4, 6, 4, 8, 6, 3, 17, 11, 4, 12, 15, 8, 14, 4, 9, 17, 15, 7, 10, 4, 9, 6, 5, 12, 9, 13, 16, 7, 14, 16, 3, 6, 5, 16, 8, 6, 4, 7, 5, 3, 14, 11, 4, 7, 4, 6, 4, 9, 16, 11, 4, 6, 18, 14, 6, 7, 21, 6, 8, 4, 16, 4, 12, 6, 5, 4, 13, 7, 12, 6, 4, 7, 8, 9, 12, 11, 6, 11, 6, 15, 4, 11, 8, 13, 9, 12, 5, 19, 5, 4, 3, 7, 20, 5, 2, 4, 3, 3, 4, 13, 8, 3, 11, 5, 15, 12, 13, 7, 9, 3, 7, 14, 9, 7, 5, 7, 4, 6, 9, 9, 15, 7, 4, 17, 5, 7, 5, 4, 9, 13, 17, 15, 20, 6, 4, 6, 7, 7, 7, 12, 9, 4, 14, 3, 11, 7, 17, 3, 8, 15, 6, 5, 8, 10, 9, 6, 5, 12, 15, 13, 4, 5, 4, 21, 7, 8, 13, 3, 3, 5, 7, 6, 7, 11, 15, 6, 5, 12, 4, 5, 12, 7, 11, 3, 3, 12, 6, 5, 9, 3, 10, 5, 9, 6, 4, 14, 5, 3, 7, 4, 11, 5, 8, 3, 3, 4, 4, 13, 10, 8, 7, 6, 20, 3, 4, 3, 11, 9, 12, 3, 9, 4, 12, 3, 21, 3, 9, 10, 11, 9, 10, 8, 3, 4, 17, 10, 4, 11, 20, 13, 16, 17, 8, 17, 5, 6, 11, 10, 11, 10, 3, 10, 15, 12, 4, 19, 6, 20, 10, 9, 8, 6, 13, 9, 4, 4, 8, 14, 19, 9, 5, 5, 14, 11, 4, 8, 10, 10, 8, 7, 13, 7, 13, 3, 12, 6, 10, 10, 17, 4, 6, 8, 11, 15, 6, 9, 3, 9, 10, 13, 3, 10, 13, 6, 9, 4, 3, 4, 4, 4, 11, 11, 9, 15, 10, 5, 16, 7, 13, 3, 13, 6, 4, 3, 22, 5, 8, 15, 3, 11, 4, 23, 12, 3, 7, 11, 6, 7, 6, 12, 19, 12, 9, 12, 16, 13, 6, 5, 6, 8, 9, 3, 6, 16, 8, 17, 2, 10, 8, 6, 8, 6, 5, 3, 10, 8, 7, 6, 6, 18, 16, 6, 5, 7, 9, 5, 9, 4, 14, 7, 5, 16, 15, 7, 6, 16, 3, 15, 6, 16, 11, 7, 11, 13, 5, 2, 19, 5, 9, 6, 9, 10, 4, 7, 8, 10, 3, 12, 3, 15, 11, 9, 5, 11, 8, 4, 8, 7, 6, 7, 8, 13, 4, 5, 3, 17, 6, 22, 7, 3, 13, 19, 17, 11, 3, 4, 14, 9, 7, 8, 12, 11, 4, 10, 7, 8, 4, 7, 15, 11, 16, 10, 2, 5, 6, 5, 7, 14, 3, 10, 7, 5, 3, 4, 6, 7, 17, 5, 4, 21, 5, 17, 15, 4, 10, 6, 8, 5, 7, 5, 17, 6, 3, 13, 3, 3, 10, 4, 5, 13, 7, 19, 3, 3, 11, 8, 7, 14, 14, 10, 7, 12, 7, 10, 5, 13, 16, 7, 3, 17, 3, 2, 13, 6, 12, 14, 3, 6, 7, 12, 7, 3, 9, 10, 14, 7, 14, 12, 23, 3, 6, 8, 6, 11, 8, 15, 10, 10, 13, 9, 11, 10, 6, 4, 2, 6, 16, 18, 13, 10, 3, 8, 5, 16, 3, 10, 5]\n",
      "Max number of sentences: 24\n"
     ]
    }
   ],
   "source": [
    "# get number of sentencese distribution\n",
    "num_sentences = []\n",
    "for index, row in df_train.iterrows():\n",
    "    num_sentences.append(len(row[\"utterances\"]))\n",
    "print(f\"Number of sentences distribution: {num_sentences}\")\n",
    "print(f\"Max number of sentences: {max(num_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the emotions \n",
    "emotions_one_hot_dict = {\n",
    "    \"neutral\": [1, 0, 0, 0, 0, 0, 0],\n",
    "    \"joy\": [0, 1, 0, 0, 0, 0, 0],\n",
    "    \"surprise\": [0, 0, 1, 0, 0, 0, 0],\n",
    "    \"sadness\": [0, 0, 0, 1, 0, 0, 0],\n",
    "    \"anger\": [0, 0, 0, 0, 1, 0, 0],\n",
    "    \"disgust\": [0, 0, 0, 0, 0, 1, 0],\n",
    "    \"fear\": [0, 0, 0, 0, 0, 0, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train = df_train.copy()\n",
    "bert_val = df_val.copy()\n",
    "bert_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speakers</th>\n",
       "      <th>emotions</th>\n",
       "      <th>utterances</th>\n",
       "      <th>triggers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
       "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
       "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               speakers  \\\n",
       "3994  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
       "\n",
       "                                               emotions  \\\n",
       "3994  [neutral, joy, neutral, neutral, surprise, dis...   \n",
       "\n",
       "                                             utterances  \\\n",
       "3994  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
       "\n",
       "                                           triggers  \n",
       "3994  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the new dataframe: (27764, 4)\n",
      "                                            speakers  \\\n",
      "0  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
      "1  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
      "2  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
      "3  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
      "4  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
      "\n",
      "                                     emotions  \\\n",
      "0                                   [neutral]   \n",
      "1                              [neutral, joy]   \n",
      "2                     [neutral, joy, neutral]   \n",
      "3            [neutral, joy, neutral, neutral]   \n",
      "4  [neutral, joy, neutral, neutral, surprise]   \n",
      "\n",
      "                                          utterances  \\\n",
      "0  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
      "1  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
      "2  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
      "3  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
      "4  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
      "\n",
      "                    triggers  \n",
      "0                      [0.0]  \n",
      "1                 [0.0, 0.0]  \n",
      "2            [0.0, 0.0, 0.0]  \n",
      "3       [0.0, 0.0, 0.0, 0.0]  \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0]  \n"
     ]
    }
   ],
   "source": [
    "extended_dataset = None\n",
    "columns = [\"speakers\", \"emotions\", \"utterances\", \"triggers\"]\n",
    "extended_dataset = pd.DataFrame(columns=columns)\n",
    "\n",
    "for i in range(bert_train.shape[0]):\n",
    "  for j, _ in enumerate(bert_train.iloc[i]['speakers']):\n",
    "    new_row = pd.DataFrame({'speakers': [bert_train.iloc[i]['speakers']],\n",
    "                        'emotions': [bert_train.iloc[i]['emotions'][:j+1]],\n",
    "                        'utterances': [bert_train.iloc[i]['utterances']],\n",
    "                        'triggers': [bert_train.iloc[i]['triggers'][:j+1]]})\n",
    "    extended_dataset = pd.concat([extended_dataset, new_row], ignore_index=True)\n",
    "extended_dataset\n",
    "\n",
    "print(f\"Shape of the new dataframe: {extended_dataset.shape}\")\n",
    "print(extended_dataset.head())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,10))\n",
    "# plt.hist(temp[\"utterances\"].apply(lambda x: len(x.split())), bins=100)\n",
    "# plt.title(\"Utterances length distribution\")\n",
    "# plt.xlabel(\"Utterances length\")\n",
    "# plt.ylabel(\"Number of utterances\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(temp_train[\"utterances\"].apply(lambda x: len(x.split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model settings and Bert import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|| 285/285 [00:00<00:00, 284kB/s]\n",
      "C:\\Users\\Matteo\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Matteo\\.cache\\huggingface\\hub\\models--prajjwal1--bert-tiny. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "vocab.txt: 100%|| 232k/232k [00:00<00:00, 818kB/s]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'prajjwal1/bert-tiny' #'bert-base-uncased'\n",
    "\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 2e-05\n",
    "OUT_CHANNELS = 768 if \"base\" in  MODEL_NAME else 1024\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.speakers = data.speakers\n",
    "        self.text = data.utterances\n",
    "        self.emotions = data.emotions\n",
    "        self.triggers = data.triggers\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        speakers = row[\"speakers\"]\n",
    "        text = row[\"utterances\"]\n",
    "        emotions = row[\"emotions\"]\n",
    "        triggers = row[\"triggers\"]\n",
    "        target = emotions_one_hot_dict[emotions[-1]]\n",
    "\n",
    "        text = \" \"\n",
    "        for i, d in enumerate(speakers):\n",
    "            text += f\" {d}: {row['utterances'][i]}\"\n",
    "\n",
    "        # We add emotions and triggers to the prompt to give the model information about the other sentences, except for the last which needs to be labeled\n",
    "\n",
    "        text = text + ' emotions: '\n",
    "        for i in range(len(emotions)-1):\n",
    "          text = text + f'{emotions[i]},'\n",
    "\n",
    "        text = text + ' triggers: '\n",
    "        for i in range(len(triggers)-1):\n",
    "          text = text + f'{triggers[i]} '\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'length': torch.tensor(len(speakers), dtype=torch.long),\n",
    "            'target': torch.tensor(target, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43memotions_one_hot_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mextended_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memotions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "emotions_one_hot_dict[extended_dataset.emotions[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = CustomDataset(extended_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self,model):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = transformers.AutoModel.from_pretrained(model, return_dict=False)\n",
    "        self.l2 = torch.nn.Dropout(p=0.3)\n",
    "        self.l3 = torch.nn.Linear(OUT_CHANNELS, 24)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
    "        output_2 = self.l2(output_1)\n",
    "        output = self.l3(output_2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODELETE we don't have to pad them as we will label one sentence at a time and always ask the model for 8 outputs (one for each emotion and the last for trigger)\n",
    "\n",
    "# pad emotions to max length = 24\n",
    "# def pad_emotions(emotions):\n",
    "#     emotions = np.pad(emotions, (0, 24 - len(emotions)), 'constant', constant_values=(0, 0))\n",
    "#     return emotions\n",
    "\n",
    "# bert_train[\"emotions\"] = bert_train[\"emotions\"].apply(lambda x: pad_emotions(x))\n",
    "# bert_val[\"emotions\"] = bert_val[\"emotions\"].apply(lambda x: pad_emotions(x))\n",
    "# bert_test[\"emotions\"] = bert_test[\"emotions\"].apply(lambda x: pad_emotions(x))\n",
    "\n",
    "# bert_train[\"emotions\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training dataset: 3200\n",
      "Shape of the validation dataset: 400\n",
      "Shape of the test dataset: 400\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomDataset(bert_train[\"utterances\"].values, bert_train[\"emotions\"].values, tokenizer, MAX_LEN)\n",
    "val_dataset = CustomDataset(bert_val[\"utterances\"].values, bert_val[\"emotions\"].values, tokenizer, MAX_LEN)\n",
    "test_dataset = CustomDataset(bert_test[\"utterances\"].values, bert_test[\"emotions\"].values, tokenizer, MAX_LEN)\n",
    "\n",
    "\n",
    "print(f\"Shape of the training dataset: {len(train_dataset)}\")\n",
    "print(f\"Shape of the validation dataset: {len(val_dataset)}\")\n",
    "print(f\"Shape of the test dataset: {len(test_dataset)}\")\n",
    "\n",
    "# Definiition of the Dataloader that will feed the data in batches to the neural network for suitable training and processing.\n",
    "training_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "testing_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (l2): Dropout(p=0.3, inplace=False)\n",
       "  (l3): Linear(in_features=768, out_features=24, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERTClass(MODEL_NAME)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(training_loader)*EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    size = len(training_loader.dataset)\n",
    "    model.train()\n",
    "    for batch,data in enumerate(training_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if batch%100==0:\n",
    "            current =  batch * len(data['ids'])\n",
    "            print(f\"Train loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch, val_loss_min_input):\n",
    "    size = len(testing_loader.dataset)\n",
    "    num_batches = len(testing_loader)\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    #fin_targets=[]\n",
    "    #fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            val_loss += loss_fn(outputs, targets).item()\n",
    "        \n",
    "        val_loss /= num_batches\n",
    "        #outputs, targets = fin_outputs, fin_targets\n",
    "        print(f\"\\nValidation loss: {val_loss:>8f}.\")\n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if val_loss <= val_loss_min_input:\n",
    "            #create checkpoint variable and add important data\n",
    "            if epoch > 0: \n",
    "                print('Validation loss decreased ({:.8f} --> {:.8f}).  Saving model ...'.format(val_loss_min_input, val_loss))\n",
    "            else: print('Saving model ...')   \n",
    "            # save best moel\n",
    "            torch.save(model.state_dict(), \"model.pth\")\n",
    "            print(\"Saved PyTorch Model State to model.pth\\n\")\n",
    "            val_loss_min_input = val_loss\n",
    "    \n",
    "    return val_loss_min_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.705146  [    0/ 3200]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     val_loss_min \u001b[38;5;241m=\u001b[39m validation(epoch, val_loss_min)\n",
      "Cell \u001b[1;32mIn[33], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m token_type_ids \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m      8\u001b[0m targets \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, targets)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[27], line 9\u001b[0m, in \u001b[0;36mBERTClass.forward\u001b[1;34m(self, ids, mask, token_type_ids)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, ids, mask, token_type_ids):\n\u001b[1;32m----> 9\u001b[0m     _, output_1\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     output_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml2(output_1)\n\u001b[0;32m     11\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml3(output_2)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1007\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1008\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1012\u001b[0m )\n\u001b[1;32m-> 1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    598\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m         output_attentions,\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    487\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    419\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    425\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 427\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    437\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:308\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    306\u001b[0m     value_layer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([past_key_value[\u001b[38;5;241m1\u001b[39m], value_layer], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 308\u001b[0m     key_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    309\u001b[0m     value_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue(hidden_states))\n\u001b[0;32m    311\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(mixed_query_layer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "val_loss_min = np.inf\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train()\n",
    "    val_loss_min = validation(epoch, val_loss_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
